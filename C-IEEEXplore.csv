Document Title;Authors;Author Affiliations;Publication Title;Date Added To Xplore;Publication Year;Volume;Issue;Start Page;End Page;Abstract;ISSN;ISBNs;DOI;Funding Information;PDF Link;Author Keywords;IEEE Terms;INSPEC Controlled Terms;INSPEC Non-Controlled Terms;Mesh_Terms;Article Citation Count;Patent Citation Count;Reference Count;License;Online Date;Issue Date;Meeting Date;Publisher;Document Identifier
Novel Coronavirus (COVID-19) Prediction using Deep Learning Model with Improved Meta-Heuristic Optimization Approach;J. M. Rao, B. H. Narayan;Pacific Academy of Higher Education and Research University,Faculty of Computer Engineering,Udaipur, Pacific Academy of Higher Education and Research University,Faculty of Computer Engineering,Udaipur;2022 4th International Conference on Smart Systems and Inventive Technology (ICSSIT);25-feb-22;2022;;;935;943;This research develops a deep learning-based covid-19 prediction model by going through four essential phases. The obtained raw data is first submitted to the pre-processing phase to enhance the data quality and improvement in prediction accuracy of the proposed model. The data normalization and data cleaning are undergone in the pre-processing phase. The most important aspects, such as statistical features (Mean, Median, Min-Max and Standard Deviation), Exponential Moving Average (EMA), and Relative Strength Index (RSI), are retrieved from the pre-processed data. Self Improved Standard Spider Monkey Optimization algorithm (SI-SMO) is used to select the most optimal features. Following that, a new improved deep learning model, the optimized Deep Belief Network, is used to simulate the covid-19 prediction phase (DBN). DBN's weight is fine-tuned by the proposed SI-SMO algorithm. This parametric tuning of the model enriches its performance in predicting the disease. The outcome from optimized DBN portrays about the presence/ absence of covid-19. Accordingly, the accuracy value accomplished by the proposed model is 0.951001582 at LP=60, which is 16.6%,19%,15.4%,14%, 2.6% and 5.3% better than the traditional models like SVM, RF, CNN, NB, WOA+DBN, EHO+DBN, MFO+DBN and SMO+DBN, respectively.;;978-1-6654-0118-0;10.1109/ICSSIT53264.2022.9716478;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9716478;Covid-19 Detection,Multi-Feature Extraction,DBN,SI-SMOmodel;COVID-19,Deep learning,Support vector machines,Measurement uncertainty,Predictive models,Prediction algorithms,Feature extraction;;;;;;43;;25-feb-22;;;IEEE;IEEE Conferences
A New CNN-Based Method for Short-term Forecasting of Electrical Energy Consumption in the Covid-19 Period: The Case of Turkey;I. Atik;Department of Electrical and Electronics Engineering, Gaziantep Islam Science and Technology University, Gaziantep, 27000, Turkey.;IEEE Access;;2022;PP;99;1;1;This study proposes a new convolutional neural network (CNN) method with an input-signal decomposition algorithm. With the proposed CNN architecture, hourly electricity consumption data for the Covid-19 period in Turkey were used as input data, and the short-term electricity consumption was forecasted. The input data were decomposed into its subcomponents using a signal decomposition process called Empirical Mode Decomposition (EMD). To extract the deep features, all input data were transformed into 2D feature maps and fed into the CNN. The obtained results were compared with the pre-trained models GoogleNet, AlexNet, SqueezeNet, and ResNet18. Model-wise comparisons showed that the proposed method had the highest correlation coefficient (R) and lowest root mean square error (RMSE) and mean absolute error (MAE) values for 1-h, 2-h, and 3-h. The mean R-values of the proposed method were 95.6%, 95.2%, and 94.0% for 1h, 2h and 3h ahead, respectively. The mean RMSE values were 8.2%, 8.7%, and 10.2% for 1h, 2h and 3h ahead, respectively. The experimental results confirm that the proposed method outperforms other pretrained methods despite its simpler structure.;2169-3536;;10.1109/ACCESS.2022.3154044;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9720942;Energy consumption,demand forecasting,machine learning,Empirical Mode Decomposition (EMD),Neural networks;Convolutional neural networks,Forecasting,COVID-19,Predictive models,Feature extraction,Support vector machines,Empirical mode decomposition;;;;;;;CCBY;24-feb-22;;;IEEE;IEEE Early Access Articles
Research on Intrusion Detection Based on Neural Network Optimized by Genetic Algorithm;Y. Li, A. Li, A. Wen, X. Xie;School of Computer Science and Technology, Dong Hua University,Shang Hai,China, School of Computer Science and Technology, Dong Hua University,Shang Hai,China, School of Computer Science and Technology, Dong Hua University,Shang Hai,China, School of Computer Science and Technology, Dong Hua University,Shang Hai,China;2022 2nd International Conference on Consumer Electronics and Computer Engineering (ICCECE);21-feb-22;2022;;;921;924;With the development of 5G and the emergence of the COVID-19 epidemic, network traffic has surged, and network security has once again become a key concern. Intrusion detection system is an important means to protect network security. It can find abnormal conditions in the early stage of cyber attack. Intrusion detection is also a kind of abnormal detection in a broad sense. To improve the performance of the intrusion detection system, a cyber-attack detection method combining Borderline SMOTE and improved BP neural network (Back-Propagation neural network) is proposed. It mainly uses one-hot encoding, Borderline SMOTE data oversampling and other technologies to preprocess the data, and uses the BP neural network improved by genetic algorithm to predict cyber attacks. Finally, the model is compared with other traditional machine learning models through the core indicator recall and auxiliary indicators precision, roc curve, etc. The results show that the hybrid detection model proposed in this study has higher recall and lower running time, and performs better in intrusion detection.;;978-1-6654-0886-8;10.1109/ICCECE54139.2022.9712731;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9712731;component,intrusion detection,borderline SMOTE,BP neural network, genetic algorithm, machine learning;Machine learning algorithms,Neural networks,Intrusion detection,Machine learning,Telecommunication traffic,Network security,Predictive models;;;;;;12;;21-feb-22;;;IEEE;IEEE Conferences
Predicting the Epidemics Trend of COVID-19 Using Epidemiological-based Generative Adversarial Networks;H. Wang, G. Tao, J. Ma, S. Jia, L. Chi, H. Yang, Z. Zhao, J. Tao;Zhejiang University, 12377 Hangzhou, Zhejiang, China, Shanghai, China, Tianjin, China, Tianjin, China, Com, La Trobe University, 2080 Bundoora, Victoria, Australia, 3086, Sydney, Australia, Tianjin, China, Chinese Academy of Sciences, National Laboratory of Pattern Recognition, Chinese Academy of Sciences, Beijing, Beijing, China, 100190;IEEE Journal of Selected Topics in Signal Processing;;2022;PP;99;1;1;The Coronavirus disease 2019 (COVID-19) is a respiratory illness that can spread from person to person. Since the COVID-19 pandemic is spreading rapidly over the world and its outbreak has affected different people in different ways, it is significant to study or predict the evolution of its epidemic trend. However, most of the studies focused solely on either classical epidemiological models or machine learning models for COVID-19 pandemic forecasting, which either suffer from the limitation of the generalization ability and scalability or the lack of surveillance data. In this work, we propose T-SIRGAN that integrates the strengths of the epidemiological theories and deep learning models to be able to represent complex epidemic processes and model the non-linear relationship for more accurate prediction of the growth of COVID-19. T-SIRGAN first adopts the SusceptibleInfectiousRecovered (SIR) model to generate epidemiological-based simulation data, which are then fed into a generative adversarial network (GAN) as adversarial examples for data augmentation. Then, Transformers are used to predict the future trends of COVID-19 based on the generated synthetic data. Extensive experiments on real-world datasets demonstrate the superiority of our method. We also discuss the effectiveness of vaccine based on the difference between the predicted and the reported number of COVID-19 cases.;1941-0484;;10.1109/JSTSP.2022.3152375;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9716798;COVID-19,Generative Adversarial Networks,Time Series Prediction,SIR Simulation;COVID-19,Predictive models,Mathematical models,Data models,Pandemics,Market research,Biological system modeling;;;;;;;IEEE;18-feb-22;;;IEEE;IEEE Early Access Articles
Predicting Meeting Success With Nuanced Emotions;K. Zhou, M. Constantinides, S. Joglekar, D. Quercia;Nokia Bell Labs, Cambridge U.K. University of Nottingham, Nottingham NG7 2RD U.K., Nokia Bell Labs, Cambridge CB3 0FA U.K., Nokia Bell Labs, Cambridge CB3 0FA U.K., Nokia Bell Labs, Cambridge U.K. King’s College, London WC2R 2LS U.K.;IEEE Pervasive Computing;;2022;PP;99;1;9;While current meeting tools are able to capture key analytics (e.g., transcript and summarization), they do not often capture nuanced emotions (e.g., disappointment and feeling impressed). Given the high number of meetings that were held online during the COVID-19 pandemic, we had an unprecedented opportunity to record extensive meeting data with a newly developed meeting companion application. We analyzed 72 h of conversations from 85 real-world virtual meetings and 256 self-reported meeting success scores. We did so by developing a deep-learning framework that can extract 32 nuanced emotions from meeting transcripts, and by then testing a variety of models predicting meeting success from the extracted emotions. We found that rare emotions (e.g., disappointment and excitement) were generally more predictive of success than more common emotions. This demonstrates the importance of quantifying nuanced emotions to further improve productivity analytics, and, in the long term, employee well-being.;1558-2590;;10.1109/MPRV.2022.3145047;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9715794;;Predictive models,Psychology,Training,Linguistics,Task analysis,Standards,Principal component analysis;;;;;;;IEEE;17-feb-22;;;IEEE;IEEE Early Access Articles
Artificial Intelligence for Detecting COVID-19 with the Aid of Human Cough, Breathing and Speech Signals: Scoping Review;M. Husain, A. Simpkin, C. Gibbons, T. Talkar, D. M. Low, P. Bonato, S. Ghosh, T. Quatieri, D. T. OKeeffe;Health Innovation Via Engineering (HIVE) Lab, Curam, Lero, School of Medicine, Lambe Institute for Translational Research, National University of Ireland Galway, Galway, Galway, Ireland,, National University of Ireland Galway School of Mathematics Statistics and Applied Mathematics, 200220 Galway, Galway, Ireland,, Health Innovation Via Engineering (HIVE) Lab, Curam, Lero, School of Medicine, Lambe Institute for Translational Research, National University of Ireland Galway, Galway, Galway, Ireland,, Human Health and Performance, MIT Lincoln Laboratory, Lexington, Massachusetts, United States, 02421, Program in Speech and Hearing Bioscience and Technology, Harvard Medical School, Boston, MA, Boston, United States,, Department of Physical Medicine and Rehabilitation, Harvard Medical School, 1811 Boston, Massachusetts, United States,, MIT McGovern Institute for Brain Research, Cambridge, MA, Cambridge, Massachusetts, United States,, Human Health and Performance, MIT Lincoln Laboratory, Lexington, Massachusetts, United States,, Health Innovation Via Engineering (HIVE) Lab, Curam, Lero, School of Medicine, Lambe Institute for Translational Research, National University of Ireland Galway, Galway, Ireland,;IEEE Open Journal of Engineering in Medicine and Biology;;2022;PP;99;1;1;Background: Official tests for COVID-19 are time consuming, costly, can produce high false negatives, use up vital chemicals and may violate social distancing laws. Therefore, a fast and reliable additional solution using recordings of cough, breathing and speech data for preliminary screening may help alleviate these issues. Objective: This scoping review explores how Artificial Intelligence (AI) technology aims to detect COVID-19 disease by using cough, breathing and speech recordings, as reported in the literature. Here, we describe and summarize attributes of the identified AI techniques and datasets used for their implementation. Methods: A scoping review was conducted following the guidelines of PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping Reviews). Electronic databases (Google Scholar, Science Direct, and IEEE Xplore) were searched between 1st April 2020 and 1st August 2021. Terms were selected based on the target intervention (i.e. AI), the target disease (i.e., COVID-19) and acoustic correlates of the disease (i.e. speech, breathing and cough). A narrative approach was used to summarize the extracted data. Results: 21 studies and 8 Apps out of the 83 retrieved studies met the inclusion criteria. Half of the publications and Apps were from the USA. The most prominent AI architecture used was a convolutional neural network, followed by a recurrent neural network. AI models were mainly trained, tested and run on websites and personal computers, rather than on phone apps. More than half of the included studies reported area-under-the-curve performance of greater than 0.90 on symptomatic and negative datasets while one study achieved 100% sensitivity in predicting asymptomatic COVID-19 for cough-, breathing- or speech-based acoustic features. Conclusions: The included studies show that AI has the potential to help detect COVID-19 using cough, breathing and speech samples. However, the proposed methods have not been tested clinically, understood neurophysiologicallly, nor validated with broad training and testing datasets.;2644-1276;;10.1109/OJEMB.2022.3143688;European Regional Development Fund ERDF(grant numbers:20/COV/0225), Science Foundation Ireland(grant numbers:13/RC/2073, 13/RC/2094_P2), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9713955;COVID-19,Artificial Intelligence,Machine Learning,Cough,Speech Signals,Acoustics,Breathing;Artificial intelligence,COVID-19,Feature extraction,Data mining,Machine learning algorithms,Hospitals,Computer architecture;;;;;;;CCBY;14-feb-22;;;IEEE;IEEE Early Access Articles
Epidemic Exposure Tracking With Wearables: A Machine Learning Approach to Contact Tracing;P. C. Ng, P. Spachos, S. Gregori, K. N. Plataniotis;School of Engineering, University of Guelph, Guelph, ON, Canada, School of Engineering, University of Guelph, Guelph, ON, Canada, School of Engineering, University of Guelph, Guelph, ON, Canada, Department of Electrical and Computer Engineering, University of Toronto, Toronto, ON, Canada;IEEE Access;8-feb-22;2022;10;;14134;14148;The recent pandemic revealed weaknesses in several areas, including the limited capacity of public health systems for efficient case tracking and reporting. In the post-pandemic era, it is essential to be ready and provide not only preventive measures, but also effective digital strategies and solutions to protect our population from future outbreaks. This work presents a contact tracing solution based on wearable devices to track epidemic exposure. Our proximity-based privacy-preserving contact tracing (P3CT) integrates: 1) the Bluetooth Low Energy (BLE) technology for reliable proximity sensing, 2) a machine-learning approach to classify the exposure risk of a user, and 3) an ambient signature protocol for preserving the user’s identity. Proximity sensing exploits the signals emitted from a smartwatch to estimate users’ interaction, in terms of distance and duration. Supervised learning is then used to train four classification models to identify the exposure risk of a user with respect to a patient diagnosed with an infectious disease. Finally, our proposed P3CT protocol uses ambient signatures to anonymize the infected patient’s identity. Extensive experiments demonstrate the feasibility of our proposed solution for real-world contact tracing problems. The large-scale dataset consisting of the signal information collected from the smartwatch is available online. According to experimental results, wearable devices along with machine learning models are a promising approach for epidemic exposure notification and tracking.;2169-3536;;10.1109/ACCESS.2022.3148051;Natural Sciences and Engineering Research Council of Canada (NSERC) through the NSERC Alliance COVID-19 grant(grant numbers:#401656), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9698092;Bluetooth low energy,contact tracing,disease outbreak,physical distancing,smartwatch,wearables,COVID-19,proximity sensing,pandemic,artificial intelligence,supervised learning,neural network;Sensors,COVID-19,Machine learning,Temperature measurement,Coronaviruses,Wearable computers,Protocols;;;;;;47;CCBY;31-jan-22;;;IEEE;IEEE Journals
Energy Consumption in Commercial Buildings in a Post-COVID-19 World;O. Jogunola, C. Morley, I. J. Akpan, Y. Tsado, B. Adebisi, L. Yao;Electrical Engineering, Manchester Metropolitan University, 5289 Manchester, LANCS, United Kingdom of Great Britain and Northern Ireland, M6 8NZ (e-mail: o.jogunola@mmu.ac.uk), Bruntwood Limited, Manchester, United Kingdom of Great Britain and Northern Ireland, (e-mail: craig.morley@bruntwood.co.uk), Kent State University, 4229 Kent, Ohio, United States, (e-mail: iakpan@kent.edu), Electrical Engineering, Manchester Metropolitan University, 5289 Manchester, LANCS, United Kingdom of Great Britain and Northern Ireland, (e-mail: y.tsado@mmu.ac.uk), Electrical Engineering, Manchester Metropolitan University, 5289 Manchester, LANCS, United Kingdom of Great Britain and Northern Ireland, (e-mail: b.adebisi@mmu.ac.uk), Qbots energy, Manchester, United Kingdom of Great Britain and Northern Ireland, (e-mail: li.yao@qbots.ai);IEEE Engineering Management Review;;2022;PP;99;1;1;The ripple effects of the pandemic have resulted in an unprecedented shift in sectoral energy consumption as the workforce predominantly stays and works from home. Quantifying the impact of these restrictions on energy consumption offers a new direction towards intelligent energy services in a post coronavirus (post-COVID-19) world, especially for commercial buildings. Thus, utilising actual power consumption data, the study evaluates how energy usage in commercial buildings can change in a post-COVID-19 world, whilst examining the impact of digitalisation to identifying potential new opportunities. The paper analyses the changes in energy demand with occupancy rate based on data from 126 commercial businesses with varied classes across Manchester, United Kingdom. The results show that the reduction in energy demand is not proportionate to the occupancy level, resulting in high energy costs. For instance, an average footfall for February 2021 is 10% of 2020, while the costs of electricity only fall to 80% of 2020. Although most of the energy demand is from appliances, the absence of energy efficiency increases energy consumption, highlighting the urgent need for optimised energy efficiency measures to include the time of use and scheduled use of energy across people and processes.;1937-4178;;10.1109/EMR.2022.3146591;Department of Business Energy and Industrial Strategy(grant numbers:7454460), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9695315;COVID-19,pandemic,hybrid deep learning,energy consumption prediction,energy transitions,energy efficiency;COVID-19,Pandemics,Buildings,Energy consumption,Business,Uncertainty,Energy measurement;;;;;;;IEEE;27-jan-22;;;IEEE;IEEE Early Access Articles
Respiratory Rate Estimation using U-Net-Based Cascaded Framework from Electrocardiogram and Seismocardiogram Signals;M. Chan, V. Ganti, O. Inan;Biomedical Engineering, Georgia Institute of Technology, 1372 Atlanta, Georgia, United States, (e-mail: mchan81@gatech.edu), Electrical and Computer Engineering, Georgia Institute of Technology, 1372 Atlanta, Georgia, United States, 30313 (e-mail: vganti6@gatech.edu), Electrical and Computer Engineering, Georgia Institute of Technology, 1372 Atlanta, Georgia, United States, 30308 (e-mail: omer.inan@ece.gatech.edu);IEEE Journal of Biomedical and Health Informatics;;2022;PP;99;1;1;Objective: At-home monitoring of respiration is of critical urgency especially in the era of the global pandemic due to COVID-19. Electrocardiogram (ECG) and seismocardiogram (SCG) signalsmeasured in less cumbersome contact form factors than the conventional sealed mask that measures respiratory air floware promising solutions for respiratory monitoring. In particular, respiratory rates (RR) can be estimated from ECG-derived respiratory signal (EDR) and SCG-derived respiratory (SDR) signals. Yet, non-respiratory artifacts might still be present in these surrogates of respiratory signals, hindering the accuracy of the RRs estimated. Methods: In this paper, we propose a novel U-Net-based cascaded framework to address this problem. The EDR and SDR signals were transformed to the spectro-temporal domain and subsequently denoised by a 2D U-Net to reduce the non-respiratory artifacts. Major Results: We have shown that the U-Net that fused an EDR input and an SDR input achieved a low mean absolute error of 0.82 breaths per minute (bpm) and a coefficient of determination (R2) of 0.89 using data collected from our chest-worn wearable patch. We also qualitatively provided insights on the complementariness between EDR and SDR and demonstrated the generalizability of the proposed framework. Conclusion: ECG and SCG collected from a chest-worn wearable patch can complement each other and yield reliable RR estimation using the proposed cascaded framework. Significance: We anticipate that convenient and comfortable ECG and SCG measurement systems can be augmented with this framework to facilitate pervasive and accurate RR measurement.;2168-2208;;10.1109/JBHI.2022.3144990;The Centers for Disease and Control and Prevention CDC(grant numbers:75D30120C09558), The National Institutes of Health National Heart Lung and Blood Institute(grant numbers:1R01HL130619), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9691785;Respiratory monitoring,wearable sensors,deep learning,sensor fusion;Electrocardiography,Biomedical monitoring,Monitoring,Estimation,Seismic measurements,Physiology,Noise reduction;;;;;;;USGov;25-jan-22;;;IEEE;IEEE Early Access Articles
Decomposition-Residuals Neural Networks: Hybrid system identification applied to electricity demand forecasting;K. Theodorakos, O. M. Agudelo, M. Espinoza, B. De Moor;KU Leuven, Department of Electrical Engineering (ESAT), STADIUS Center for Dynamical Systems, Signal Processing and Data Analytics, Kasteelpark Arenberg 10, box 2446, 3001 Leuven, Belgium. (e-mail: konstantinos.theodorakos@esat.kuleuven.be), KU Leuven, Department of Electrical Engineering (ESAT), STADIUS Center for Dynamical Systems, Signal Processing and Data Analytics, Kasteelpark Arenberg 10, box 2446, 3001 Leuven, Belgium., KU Leuven, Department of Electrical Engineering (ESAT), STADIUS Center for Dynamical Systems, Signal Processing and Data Analytics, Kasteelpark Arenberg 10, box 2446, 3001 Leuven, Belgium., KU Leuven, Department of Electrical Engineering (ESAT), STADIUS Center for Dynamical Systems, Signal Processing and Data Analytics, Kasteelpark Arenberg 10, box 2446, 3001 Leuven, Belgium.;IEEE Open Access Journal of Power and Energy;;2022;PP;99;1;1;Day-ahead energy forecasting systems struggle to provide accurate demand predictions due to pandemic mitigation measures. Decomposition-Residuals Deep Neural Networks (DR-DNN) are hybrid point-forecasting models that can provide more accurate electricity demand predictions than single models within the COVID-19 era. DR-DNN is a novel two-layer hybrid architecture with: a decomposition and a nonlinear layer. Based on statistical tests, decomposition applies robust signal extraction and filtering of input data into: trend, seasonal and residuals signals. Utilizing calendar information, temporal signals are added: sinusoidal day/night cycles, weekend/weekday, etc. The nonlinear layer learns unknown complex patterns from all those signals, with the usage of well-established deep neural networks. DR-DNN outperformed baselines and state-of-the-art deep neural networks on next-day electricity forecasts within the COVID-19 era (from September 2020 to February 2021), both with fixed and Bayesian optimized hyperparameters. Additionally, model interpretability is improved, by indicating which endogenous or exogenous inputs contribute the most to specific hour-ahead forecasts. Residual signals are very important on the first hour ahead, whereas seasonal patterns on the 24th. Some calendar features also ranked high: whether it is day or night, weekend or weekday and the hour of the day. Temperature was the most important exogenous factor.;2687-7910;;10.1109/OAJPE.2022.3145520;Other funding(grant numbers:'Kom op tegen Kanker',CM (Christelijke Mutualiteit)), Flemish Government Agencies(grant numbers:Baekeland PhD (HBC.20192204),EWI: the Flanders AI Research Program,Innovation mandate (HBC.2019.2209),VLAIO: CSBO (HBC.2021.0076)), KU Leuven Research Fund(grant numbers:Project C16/15/059,Project C24/18/022,Project C3/19/053,Project C3/20/117,Project C3I-21-00316), KU Leuven Industrial Research Fund(grant numbers:Fellowship 13-0260,Fellowship IOFm/16/004,Fellowship IOFm/20/002,Several Leuven Research and Development bilateral), European Commission European Research Council under the European Union(grant numbers:European Union?s Horizon 2020 research,ERC Adv. Grant grant agreement No 885682), Flemish Government Agencies FWO(grant numbers:EOS Project no G0F6718N (SeLMA),Infrastructure project I013218N,PhD Grants (SB/1SA1319N, SB/1S93918, SB/1S1319N),SBO project S005319N,TBM Project T001919N), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9690165;electricity demand forecasting,signal decomposition,deep neural networks,system identification,COVID-19;Predictive models,Load modeling,Neural networks,Forecasting,Time series analysis,Deep learning,Market research;;;;;;;CCBY;21-jan-22;;;IEEE;IEEE Early Access Articles
Forecasting COVID-19 Outbreak Through Fusion of Internet Search, Social Media, and Air Quality Data: A Retrospective Study in Indian Context;S. Chatterjee, K. Ghosh, A. Banerjee, S. Banerjee;Department of Computer Science and Technology, University of Engineering& Management, Kolkata 700160, India (e-mail: chatterjeesankhadeep.cu@gmail.com), Department of Computer Science and Engineering, University of Engineering & Management, Kolkata 700160, India., Department of Computer Science and Engineering, University of Engineering & Management, Kolkata 700160, India., Department of Electronics and Communication Engineering, University of Engineering & Management, Kolkata 711103, India.;IEEE Transactions on Computational Social Systems;;2022;PP;99;1;12;This article proposes a machine learning augmented technique to predict the coronavirus disease (COVID-19) outbreak in India by combining Internet search trends along with social media data retrieved from Twitter. A comprehensive list of suitable search words has been used to select a large collection of Tweets, and the Internet search trends of the same keywords have been fetched. First, a lag correlation analysis is conducted to find the number of days, ahead of the current time, required to make an accurate prediction of COVID-19 cases. Second, both shallow and deep learning methods are engaged to predict the number of COVID-19 cases in a specific geospatial location in India. Thereafter, statewise air pollution data collected from the Central Pollution Control Board, Government of India, are amalgamated to understand the effect of air pollution in spreading of COVID-19 disease. The air pollution monitoring parameters have been combined to understand their effects in the prediction of COVID-19 cases in the Indian context. Experimental results reveal that accurate predictions can be made 85 days ahead of the current time using the proposed method (r > 0.85), thereby establishing its ingenuity in the prediction of COVID-19 spread in advance.;2329-924X;;10.1109/TCSS.2022.3140320;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9682428;Air quality,coronavirus disease (COVID-19),Internet search,SARS-CoV-2,social media.;COVID-19,Social networking (online),Market research,Pandemics,Internet,Coronaviruses,Blogs;;;;;;;IEEE;14-jan-22;;;IEEE;IEEE Early Access Articles
Covid-19 Impact and Implications on Traffic: Smart Predictive Analytics for Mobility Navigation;J. Nidamanuri, A. Rohith, S. Pranjal, H. Venkataraman;Indian Institute of Information Technology,Smart Transportation Research Group,Sri City,India,517646, Indian Institute of Information Technology,Smart Transportation Research Group,Sri City,India,517646, Indian Institute of Information Technology,Smart Transportation Research Group,Sri City,India,517646, Indian Institute of Information Technology,Smart Transportation Research Group,Sri City,India,517646;2022 14th International Conference on COMmunication Systems & NETworkS (COMSNETS);13-jan-22;2022;;;812;817;Traffic prediction and analysis is an essential task towards intelligent mobility, particularly for path planning and navigation. When the traffic flow starts after the COVID-19 pandemic is subsided, the mobility patterns changes and may become unpredictable or challenging. This problem may be crucial, particularly if many people hurry to single occupancy transport mode. Notably, the rapid development in machine learning with new methods and the emergence of new data sources make it possible to evaluate and predict traffic conditions in smart cities more quickly and precisely. The proposed work is modeled in two-fold manner to investigate the impact of COVID shift in regular urban traffic movements given the particular period of the pre, during, and post lockdown phases. Firstly, the investigation is carried out for time series analysis considering the three phases of lockdown. Secondly, the real-time spatial information is analyzed for different time zones in a day. Notably, this requires a detailed analysis of the heterogeneous and complex input traffic data. Machine learning and advanced deep learning methodologies such as regression models, RNN, variants of LSTM, and GRU is used for analysis in this proposed traffic modeling. Significantly, the least error scores with Root Mean Square Error (RMSE) loss of 1.82 is observed for the RNN and GRU models, and 0.058 with the Gradient Boosting regression analysis, respectively.;2155-2509;978-1-6654-2104-1;10.1109/COMSNETS53615.2022.9668404;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9668404;Covid-19,Deep Learning,LSTM,Machine Learning,Regression Analysis,RNN,Smart Mobility,Traffic prediction;COVID-19,Training,Analytical models,Navigation,Time series analysis,Predictive models,Spatial databases;;;;;;12;;13-jan-22;;;IEEE;IEEE Conferences
Hybrid Modeling of Regional COVID-19 Transmission Dynamics in the U.S.;Y. Bai, A. Safikhani, G. Michailidis;Statistics, University of Florida, 3463 Gainesville, Florida, United States, (e-mail: baiyue@ufl.edu), Statistics, University of Florida, 3463 Gainesville, Florida, United States, 32611-7011 (e-mail: a.safikhani@ufl.edu), Statistics, University of Florida, 3463 Gainesville, Florida, United States, (e-mail: gmichail@ufl.edu);IEEE Journal of Selected Topics in Signal Processing;;2022;PP;99;1;1;The fast transmission rate of COVID-19 worldwide has made this virus the most important challenge of year 2020. Many mitigation policies have been imposed by the governments at different regional levels (country, state, county, and city) to stop the spread of this virus. Quantifying the effect of such mitigation strategies on the transmission and recovery rates, and predicting the rate of new daily cases are two crucial tasks. In this paper, we propose a hybrid modeling framework which not only accounts for such policies but also utilizes the spatial and temporal information to characterize the pattern of COVID-19 progression. Specifically, a piecewise susceptible-infected-recovered (SIR) model is developed while the dates at which the transmission/recover rates change significantly are defined as break points'' in this model. A novel and data-driven algorithm is designed to locate the break points using ideas from fused lasso and thresholding. In order to enhance the forecasting power and to describe additional temporal dependence among the daily number of cases, this model is further coupled with spatial smoothing covariates and vector auto-regressive (VAR) model. The proposed model is applied to several U.S. states and counties, and the results confirm the effect of stay-at-home orders'' and some states' early re-openings'' by detecting break points close to such events. Further, the model performed satisfactorily short-term forecasts of the number of new daily cases at regional levels by utilizing the estimated spatio-temporal covariance structures. They were also better or on par with other proposed models in the literature, including flexible deep learning ones. Finally, some theoretical results and empirical performance of the proposed methodology on synthetic data are reported which justify the good performance of the proposed method.;1941-0484;;10.1109/JSTSP.2022.3140703;UF Informatics Institute(grant numbers:COVID-19 SEED Fund), Directorate for Mathematical and Physical Sciences(grant numbers:1821220), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9670745;COVID-19,break point detection,spatiotemporal model,short-term forecast;COVID-19,Predictive models,Mathematical models,Forecasting,Data models,Coronaviruses,Heuristic algorithms;;;;;;;IEEE;5-jan-22;;;IEEE;IEEE Early Access Articles
Weighted Graph-Based Signal Temporal Logic Inference Using Neural Networks;N. Baharisangari, K. Hirota, R. Yan, A. Julius, Z. Xu;School for Engineering of Matter, Transport and Energy, Arizona State University, Tempe, AZ, USA, Walker Department of Mechanical Engineering, The University of Texas at Austin, Austin, TX, USA, Department of Electrical, Computer, and Systems Engineering, Rensselaer Polytechnic Institute, Troy, NY, USA, Department of Electrical, Computer, and Systems Engineering, Rensselaer Polytechnic Institute, Troy, NY, USA, School for Engineering of Matter, Transport and Energy, Arizona State University, Tempe, AZ, USA;IEEE Control Systems Letters;6-jan-22;2022;6;;2096;2101;Extracting spatial-temporal knowledge from data is useful in many applications. It is important that the obtained knowledge is human-interpretable and amenable to formal analysis. In this letter, we propose a method that trains neural networks to learn spatial-temporal properties in the form of <italic>weighted graph-based signal temporal logic</italic> (w-GSTL) formulas. For learning w-GSTL formulas, we introduce a <italic>flexible</italic> w-GSTL <italic>formula structure</italic> in which the user’s preference can be applied in the inferred w-GSTL formulas. In the proposed framework, each neuron of the neural networks corresponds to a subformula in a <italic>flexible</italic> w-GSTL <italic>formula structure</italic>. We initially train a neural network to learn the w-GSTL operators, and then train a second neural network to learn the parameters in a <italic>flexible</italic> w-GSTL <italic>formula structure</italic>. We use a COVID-19 dataset and a rain prediction dataset to evaluate the performance of the proposed framework and algorithms. We compare the performance of the proposed framework with three baseline classification methods including K-nearest neighbors, decision trees, support vector machine, and artificial neural networks. The classification accuracy obtained by the proposed framework is comparable with the baseline classification methods.;2475-1456;;10.1109/LCSYS.2021.3138059;Defense Advanced Research Projects Agency (DARPA)(grant numbers:HR001120C0032), NSF(grant numbers:1936578), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9662049;Neural networks,weighted graph-based signal temporal logic;Biological neural networks,Trajectory,Task analysis,Syntactics,Semantics,Support vector machines,Standards;;;;;;20;IEEE;23-dec-21;;;IEEE;IEEE Journals
Forecasting of Individuals’ Movement in Society After Corona Pandemic Using RNNs with LSTM and GRUs;N. S. Abass, N. M. Sahib, A. Alkhayyat;University of Diyala,College of Science,Dept. of Computer Science,Diyala,Iraq, University of Diyala,College of Science,Dept. of Computer Science,Diyala,Iraq, The Islamic University,College of Technical Engineering,Dept. of Computer Technical Engineering,Najaf,Iraq;2021 4th International Iraqi Conference on Engineering Technology and Their Applications (IICETA);25-feb-22;2021;;;117;122;The health crisis that attributed to the quick spread of the COVID-19 has impacted the globe negatively in terms of economy, education, and transport and led to the global lockdown. The risk of the COVID-19 infection has been increased due to a lack of a successful cure for the disease. Thus, social distancing is considered the most appropriate precaution measure to control the viral spread throughout the world. In this study, a model was proposed for deep learning capable of predicting the movement of people in the pandemic in the short term (one day) to take precautions and control the COVID-19 infection. The proposed model consists of four phases: data collection, pre-processing phase, prediction stage, and evaluation and Comparison phase. The dataset is obtained from 428 mobility reports, collected based on data from users that have been selected for their Google Account location history for a country such as Iraq for 428 days. A deep learning algorithm such as Long Short-Term Memory (LSTM), Gated Recurrent Unit (GRU), and hybrid model (GRU & LSTM) is applied to pre-processed data to predict the movement of people. They are compared using statistical measures: Mean absolute error (MAE) and root mean square error (RMSE) for performance measurement of these machine learning algorithms. The results of the GRU are the sum of MAE 0.4277 and sum of RMSE 0.6470 for predict person path and movement with training time equal to 33.189 sec, while the results of the hybrid model are the sum of MAE 0.4355 and sum of RMSE 0.6563 for prediction and the training time equal to 53.144 sec, and the results of the LSTM are the sum of MAE 0.4395 and sum of RMSE 0.6612 for prediction and the training time equal to 100.752 sec. These statistical measurement values indicate proposed model GRU outperformed all other models, it showed a solid performance to predict person path and movement in coronavirus pandemic and took little time to train compared to other algorithms, while the hybrid algorithm showed good performance and a short period in training compared with the LSTM model.;;978-1-6654-9461-8;10.1109/IICETA51758.2021.9717561;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9717561;Covid-19,RNN,LSTM,GRU,DL;COVID-19,Training,Deep learning,Solid modeling,Machine learning algorithms,Pandemics,Predictive models;;;;;;19;;25-feb-22;;;IEEE;IEEE Conferences
A Study on Predicting Customer Willingness to Order Food Online During Covid-19 Pandemic Using Machine Learning Algorithms;K. Aditya Sobika, S. N. Vivek Raj;KCT Business School, Kumaraguru College of Technology,Coimbatore,India, KCT Business School, Kumaraguru College of Technology,Coimbatore,India;2021 4th International Conference on Computing and Communications Technologies (ICCCT);18-feb-22;2021;;;236;241;Online food delivery has become the one of the prominent services during COVID-19 pandemic. After facing deceleration in early COVID-19 phase, online food delivery is slowly gaining momentum in India due to relaxations given by the government and support of the consumers. Online food delivery services need an improved understanding of the complexities of customer behavior which have shifted during this health crisis period of COVID-19 pandemic. The Study is undertaken to predict the customer willingness to order food using online services aftermath of COVID-19 pandemic using Machine Learning algorithms. Primary data collection is done through online survey distributed among public. 415 responses were received out of which 369 people prefer to order through online food delivery services. Using different machine learning models, it is inferred that the Affective and instrumental belief, Perceived benefits (variables of health belief model) are the significant predictors of the customers willingness to order food online. Demographic variables like hours utilized in mobile, frequency of ordering during COVID, Convenience of using food delivery application, number of members in family, age, education qualification and occupation are also found to be significant in determining order opinion.;;978-1-6654-1447-0;10.1109/ICCCT53315.2021.9711904;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9711904;Online food delivery services,willingness,order opinion,prediction,covid-19 pandemic,machine learning algorithms,Health belief model,ANN,logistic regression,sentimental analysis,decision tree;COVID-19,Analytical models,Machine learning algorithms,Pandemics,Instruments,Computational modeling,Machine learning;;;;;;17;IEEE;18-feb-22;;;IEEE;IEEE Conferences
An Adaptive Approach to Detect Face Mask in Real Time using Convolutional NeuralNetwork (CNN) Model;A. N. Rajath, B. M. Shruthi, K. Ambareen, C. M. Shree Lakshmi;GSSS Institute of Engineering and Technology For Women College,Department of Computer Science and Engineering,Mysuru,Karnataka,India, GSSS Institute of Engineering and Technology For Women College,Department of Computer Science and Engineering,Mysuru,Karnataka,India, GSSS Institute of Engineering and Technology For Women College,Department of Computer Science and Engineering,Mysuru,Karnataka,India, GSSS Institute of Engineering and Technology For Women College,Department of Computer Science and Engineering,Mysuru,Karnataka,India;2021 5th International Conference on Electrical, Electronics, Communication, Computer Technologies and Optimization Techniques (ICEECCOT);16-feb-22;2021;;;826;831;The corona virus diseases are sparkling an astonishing level of scientific collaboration around the world. Artificial intelligence (AI) association with machine learning and deep learning could greatly assist in fighting corona virus in a number of paths. Machine learning allows research scholar, researchers and clinicians to make assessment on various amounts of datasets to foresee the spread of corona virus, which serve as an early warning mechanism for potential epidemics. In many countries, people are required by protocol to wear a mask in public. These rules and laws are designed as measures to exponentially increase the number of diseases count and death cases in many regions. However, the procedure of observing many people is becoming increasingly difficult. Here, we present a model for mask face detection based on deep learning and computer vision. The proposed model can be embedded with a surveillance camera to block the spread of corona diseases, detecting people wearing masks but not face masks. This model integrates deep learning and classic machine learning methods using open computer vision, tensor flow and keras.;;978-1-6654-3272-6;10.1109/ICEECCOT52851.2021.9708046;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9708046;Deep Learning,Computer Vision,Convolutional Neural Networks (CNNs),TensorFlow,OpenCV,COVID-19,Keras;COVID-19,Deep learning,Adaptation models,Tensors,Computational modeling,Surveillance,Streaming media;;;;;;6;IEEE;16-feb-22;;;IEEE;IEEE Conferences
Comorbidity Based Risk Prediction System for ARDS in COVID-19 Patients;N. Rajesh, V. T. Poulose, P. L. Umesh, R. M. Daniel;Rajagiri School of Engineering and Technology,Department of Computer Science & Engineering,Kakkanad,Kerala,India, Rajagiri School of Engineering and Technology,Department of Computer Science & Engineering,Kakkanad,Kerala,India, Rajagiri School of Engineering and Technology,Department of Computer Science & Engineering,Kakkanad,Kerala,India, Rajagiri School of Engineering and Technology,Department of Computer Science & Engineering,Kakkanad,Kerala,India;2021 International Conference on Advances in Computing and Communications (ICACC);15-feb-22;2021;;;1;5;The Coronavirus disease is an acute respiratory disease that has been designated as a pandemic by the WHO(World Health Organization).The rapid increase in the number of illnesses and death rates has put enormous strain on public health services. Hence, its critical to recognize the comorbidities in COVID-19 patients that led to ARDS(Acute Respiratory Distress Syndrome). In this paper, we use machine learning and deep learning methods to classify high risk COVID-19 patients with accurate results. This paper might speed up decisions made in public health services for predicting medical resources as well as early classification of high risk COVID-19 patients.;;978-1-6654-3919-0;10.1109/ICACC-202152719.2021.9708206;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9708206;COVID-19,ARDS (Acute Respiratory Distress Syndrome),XGBOOST,Artificial Neural Network,Gradient Boosted Trees,Support Vector Machine,ADABOOST,KNN,Random Forest;COVID-19,Support vector machines,Pandemics,Pulmonary diseases,Resource management,History,Public healthcare;;;;;;11;IEEE;15-feb-22;;;IEEE;IEEE Conferences
Importance of Artificial Intelligence and Machine Learning in fighting with COVID-19 Epidemic;V. Solanki, U. Solanki, A. Baliyan, V. Kukreja, V. Lamba, B. Kumar Sahoo;Chitkara University,Chitkara University Institute of Engineering and Technology,Punjab,India, Manipal University Jaipur,TAPMI School of Business,Jaipur,Rajastan,India, Chitkara University,Chitkara University Institute of Engineering and Technology,Punjab,India, Chitkara University,Chitkara University Institute of Engineering and Technology,Punjab,India, Chitkara University,Chitkara University Institute of Engineering and Technology,Punjab,India, Chitkara University,Chitkara University Institute of Engineering and Technology,Punjab,India;2021 5th International Conference on Information Systems and Computer Networks (ISCON);14-feb-22;2021;;;1;8;Novel coronavirus known as COVID-19 is spreading continuously with exponential rate in the world and till date we have no any proper treatment to fight and treat corona positive patients. The economy and employment of entire world lay down and collapsed due to COVID-19. As per WHO guidelines the entire world followed some precautionary measures only and therefore there is no cure mechanism and treatment to treat the COVID-19 patients. Entire health community treats the COVID-19 patient symptotically. The spreading momentum of COVID-19 is exponentially but fortunately the death rate of COVID-19 patient is very low. In such situation, Deep Learning (DL), Data Science, Machine Learning (ML) and Artificial Intelligence (AI) play vital role in cope up and deal with the COVID-19 patients. This paper focuses on predictions, challenges and dealing methods to fight COVID-19 patents with AI, ML and data science for lay hold of precautions and discover the vaccine and treatment. This paper also shows that how AI/ML should be engaged researchers, and governments to ensure the most effective responses and actions are taken.;;978-1-6654-0341-2;10.1109/ISCON52037.2021.9702316;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9702316;COVID-19,AI,ML,DL,Pandemic,Epidemic,Outbreak,Coronavirus,Healthcare;COVID-19,Deep learning,Patents,Pandemics,Surveillance,Data science,Vaccines;;;;;;56;IEEE;14-feb-22;;;IEEE;IEEE Conferences
Predictive Analytics in Healthcare: The Use of Machine Learning for Diagnoses;Z. E. Rasjid;Binus University,School Of Computer Science,Computer Science Department,Jakarta,Indonesia;2021 International Conference on Electrical, Computer and Energy Technologies (ICECET);11-feb-22;2021;;;1;6;Currently with COVID19 pandemic, health becomes an important factor in our daily life. There are many diseases, some are treatable, some are lethal. Predictive analytics is a method to predict an outcome based on historical data and has been used in many sectors including healthcare. In healthcare, all data are kept in an Electronic Health Record, and therefore can be used to predict healthcare issues including diseases. Machine Learning is a method can be used to select and train the data to make a decision. Different methods in machine learning have been used to predict diseases such as heart and lung diseases, cancer and many more. This paper discusses different methods such as Support Vector Machine, Neural Network with Decision Trees, Random Forest, K-Nearest Neighbor, and variations of those algorithms that have been used for prediction in the field of health and healthcare. The different methods are compared in terms of the accuracy. In conclusion, the accuracy of the predictions is acceptable, however some are still low. The challenges are to improve the accuracy using different machine learning algorithms or hybrid algorithms.;;978-1-6654-4231-2;10.1109/ICECET52533.2021.9698508;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9698508;Predictive Analytics,Health,Machine Learning;Support vector machines,Heart,Machine learning algorithms,Pandemics,Neural networks,Lung cancer,Medical services;;;;;;30;IEEE;11-feb-22;;;IEEE;IEEE Conferences
Predicting the COVID-19 in the Metropolitan Region (Chile) using a GCN-LSTM neural network;S. Reid, O. Nicolis, B. Peralta;Estudiante de Magister de Ciencias de Computación de Universidad Andrés Bello,Santiago,Chile,7500971, Universidad Andrés Bello,Profesora Titular de Departamento de Ciencias de Ingeniería,Santiago,Chile,7500971, Universidad Andrés Bello,Profesor Investigador de Departamento de Ciencias de Ingeniería,Santiago,Chile,7500971;2021 IEEE CHILEAN Conference on Electrical, Electronics Engineering, Information and Communication Technologies (CHILECON);11-feb-22;2021;;;1;6;COVID-19 is considered one of the largest pandemics in recent times. Predicting the number of future COVID-19 cases is extremely important for governments in order to make decisions about mobility restrictions, and for hospitals to be able to manage medical supplies, as well as health staff. Most of the predictions of COVID-19 cases are based on mathematical-epidemiological models such as the SEIR and SIR models. In our work, we propose a model of neural networks GCN-LSTM (Graph Convolutional Network - Long Short Term Memory) to predict the spatio-temporal rate incidence of COVID-19 in the Metropolitana Region, Chile. While the GCN network incorporates the spatial correlation in the nearby municipalities, the LSTM network considers the temporal correlation for the prediction over time. To interpolate the missing daily data for the network input, the use of the GAM (Generalized Additive Model) model is proposed. The results show better predictions for some municipalities with higher habitat density.;;978-1-6654-0873-8;10.1109/CHILECON54041.2021.9702969;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9702969;Neural networks,GCN-LSTM,Spatio-temporal models;COVID-19,Correlation,Pandemics,Hospitals,Neural networks,Predictive models,Mathematical models;;;;;;0;IEEE;11-feb-22;;;IEEE;IEEE Conferences
Design of a 3D convolutional neural network model to forecast PM<inf>2.5</inf> and O<inf>3</inf> concentrations in Colombia;A. Casallas, C. Ferro, N. Celis, C. Mogollon-Sotelo, L. C. Belalcazar;Sergio Arboleda University,School of Exact Science and Engineering,Bogota,Colombia, Institute of Environmental Studies and Services (IDEASA), Sergio Arboleda University,Bogotá,Colombia, Institute of Environmental Studies and Services (IDEASA), Sergio Arboleda University,Bogotá,Colombia, Sergio Arboleda University,School of Exact Science and Engineering,Bogota,Colombia, National University of Colombia,Bogotá,Colombia;2021 Congreso Colombiano y Conferencia Internacional de Calidad de Aire y Salud Pública (CASAP);10-feb-22;2021;;;1;5;Here a 3D convolutional recurrent neural network performance to forecast PM<inf>2.5</inf> and O<inf>3</inf> at the different stages of the lockdown in Colombia are presented. The network makes a 24 hours forecast and is evaluated using 4 statistical parameters that are then averaged for every lockdown period to quantify the change in the model precision due to lockdown policies. For Colombia, PM<inf>2.5</inf> predictions are better for partial and full lockdown, due to the high values produced by biomass burning (pre-lockdown) that are sub-estimated by the network. This does not happen for O<inf>3</inf> where the model is fairly similar for the three periods, but in the full lockdown, the model has a slightly worst performance, probably because O<inf>3</inf> in full-lockdown have an abnormal growth that leads to a sub estimation of its magnitude, even though the behavior is well represented by the model.On the other hand, the model is more precise for PM<inf>2.5</inf> in the full and partial lockdowns possibly due to the biomass burning in pre-lockdown that produces abnormal increases of the pollutant. In terms of the ozone, the pre and partial lockdown have better performance since in the full lockdown the O<inf>3</inf> rises to higher values than usual, which has not happened before, so the model was not able to learn this behavior in a precise manner. The topography and the pressure levels seem to be the principal source of uncertainty for the model (apart from the biomass burning).;;978-1-6654-7959-2;10.1109/CASAP54985.2021.9703414;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9703414;Convolutional Network,Pollutants,COVID-19,Colombia;Solid modeling,Three-dimensional displays,Uncertainty,Recurrent neural networks,Biological system modeling,Surfaces,Predictive models;;;;;;12;IEEE;10-feb-22;;;IEEE;IEEE Conferences
A Study of People Movement Index in Indonesia During Lebaran 2021;A. F. Ihsan, M. R. R. Nugraha, N. Nuraini;Telkom University,School of Computing,Bandung,Indonesia, Institut Teknologi Bandung,Mathematics Department,Bandung,Indonesia, Institut Teknologi Bandung,Mathematics Department,Bandung,Indonesia;2021 International Conference Advancement in Data Science, E-learning and Information Systems (ICADEIS);9-feb-22;2021;;;1;6;Eid al-Fitr or Lebaran is one of the biggest national holidays in Indonesia. It is a day in a year where most people, usually urban citizens, goes back to their parents or childhood home. In normal condition, this high mobility culture has many positive social and economic aspects, but in pandemic situation, it is the opposite. Mobility reduction is a key in controlling emerging Covid-19. Unfortunately, big events or big holidays tend to overcome the pandemic crisis in terms of people’s mobility. In this study, we use movement range index data to analyze the dynamics of people’s mobility in Indonesia around national holidays, especially Lebaran 2021. A deep learning approach is applied to create prediction of people’s mobility based on past behavior and other variables such as Covid-19 daily cases and government regulation. It is shown that Eid al-Fitr effect on people’s desire to move surpasses pandemic condition or even government regulation.;;978-1-6654-3709-7;10.1109/ICADEIS52521.2021.9701957;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9701957;Lebaran,mobility,time series,neural network;COVID-19,Pandemics,Government,Neural networks,Predictive models,Market research,Regulation;;;;;;24;;9-feb-22;;;IEEE;IEEE Conferences
Campus Safety and Hygiene Detection System using Computer Vision;N. Raote, M. S. Khan, Z. Siddique, A. K. Tripathy, P. Shaikh;Don Bosco Institute of Technology,Department of Computer Engineering,Mumbai,India, Don Bosco Institute of Technology,Department of Computer Engineering,Mumbai,India, Don Bosco Institute of Technology,Department of Computer Engineering,Mumbai,India, Don Bosco Institute of Technology,Department of Computer Engineering,Mumbai,India, Don Bosco Institute of Technology,Department of Computer Engineering,Mumbai,India;2021 International Conference on Advances in Computing, Communication, and Control (ICAC3);7-feb-22;2021;;;1;7;The recent spread of severe acute respiratory syndrome coronavirus 2 and its associated coronavirus disease has caused extensive public health concerns. University campuses are at higher risks since a lot of students are present inside the campus at a given point of time. Places where there are a lot of chances of spread of the infection in the campus include the entrance gate, canteen, library, photocopy center, seminar hall, etc. Strict actions must be taken against the violations of the covid-19 protocols which will ensure health safety and maintain hygiene in the campus. Doing this manually will be a tedious task. Owing to this problem, an attempt has been made to design a system to tackle the problem of following all the protocols and making everyone aware about the situation in the campus. This work proposes a system which will continuously monitor all these activities with the help of Computer Vision and Deep Learning. The collected CCTV cameras data has been checked in the real time mode using various object detection and object tracking models to identify and track the objects visible in the frame. This approach uses MobileNet and SSD Architecture along with the objection detection models to predict the desired output. Finally, based on the output the system checks for any violations and if encountered then it sends a text alert to the concerned authority.;;978-1-6654-2634-3;10.1109/ICAC353642.2021.9697148;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9697148;Deep Learning,Computer Vision,Object Detection,Hygiene;COVID-19,Seminars,Computer vision,Protocols,Computational modeling,Object detection,Cameras;;;;;;17;;7-feb-22;;;IEEE;IEEE Conferences
COVID-19 Prediction and analysis using Neural Network and Pearson Correlation;S. S. Sawant, A. Agrawal, K. Tewari;Vivekanand Education Society’s Institute of Technology,Department of Electronics Engineering,Mumbai,India, Vivekanand Education Society’s Institute of Technology,Department of Electronics Engineering,Mumbai,India, Vivekanand Education Society’s Institute of Technology,Department of Electronics Engineering,Mumbai,India;2021 International Conference on Advances in Computing, Communication, and Control (ICAC3);7-feb-22;2021;;;1;8;In the present study, a neural network-based predictive model has been used to predict the trend of the second wave of COVID-19 in a few countries, namely the US, UK, Brazil, South Africa, and India. The Neural Network model was trained for the rise of first-wave and refined predicting and comparing the predictions with the observed trends of the second waves in these countries. As the US has seen a clear-cut arrival of third-wave, the methodused was a neural network tool on Matlab software to predict the covid-19 wave pattern and later used to have a prediction of third-wave in India. Pearson correlation coefficient between the covid first wave and second wave for five countries was also computed and results were rationalized in terms of the extent of population vaccinated in these countries.;;978-1-6654-2634-3;10.1109/ICAC353642.2021.9697225;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9697225;Covid-19,Education,Mean,Pearson Coefficient,Prediction,Matlab software,Standard Deviation;COVID-19,Correlation coefficient,Correlation,Sociology,Neural networks,Predictive models,Market research;;;;;;19;;7-feb-22;;;IEEE;IEEE Conferences
Deep Learning Enabling Analysis of Exhaled Breath Using Fourier Transform Spectroscopy in the Mid-Infrared;A. Hesham, L. Zeyad, F. ElZahraa, A. ElGamal, P. Mohammed, M. Sakr, Y. M. Sabry;Ain Shams University,Computer and Systems Engineering,Cairo,Egypt, Ain Shams University,Computer and Systems Engineering,Cairo,Egypt, Ain Shams University,Computer and Systems Engineering,Cairo,Egypt, Karlsruhe School of Optics & Photonics,Karlsruhe,Germany, Karlsruhe School of Optics & Photonics,Karlsruhe,Germany, Ain Shams University,Electronics and Communications Engineering,Cairo,Egypt, Ain Shams University,Computer and Systems Engineering,Cairo,Egypt;2021 Tenth International Conference on Intelligent Computing and Information Systems (ICICIS);3-feb-22;2021;;;124;129;Exhaled breath analysis is a promising noninvasive method for rapid diagnosis of diseases by detecting different types of volatile organic compounds (VOCs) that are used as biomarkers for early detection of various diseases such as lung cancer, diabetes, anemias, etc... and more recently COVID-19. Infrared spectroscopy seems to be a promising method for VOCs detection due to its ease of use, selectivity, and existence of compact low-cost devices. In this work, the use of Fourier transforms infrared (FTIR) spectrometer to analyze breath samples contained in a gas cell is investigated using deep learning and taking into account the practical performance limits of the spectrometer. Synthetic spectra are generated using infrared gas spectra databases to emulate real spectra resulted from a breath sample and train the neural network model (NNM). The dataset is generated in the spectral range of 2000 cm<sup>-1</sup> to 6500 cm<sup>-1</sup> and assuming a light-gas interaction length of 5 meters. The FTIR device performance is assumed with a signal-to-noise ratio (SNR) of 20,000:1 and a spectral resolution of 40 cm<sup>-1</sup>. The proposed NNM contains a locally connected and 4 fully connected layers. The concentrations of 9 biomarker gases in the exhaled breath are predicted with r<sup>2</sup> score higher than 0.93, including carbon dioxide, water vapor, acetone, ethene, ammonia, methane, carbonyl sulfide, carbon monoxide and acetaldehyde demonstrating the possibility of detection.;;978-1-6654-4076-9;10.1109/ICICIS52592.2021.9694262;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9694262;exhaled breath analysis,FT-IR spectroscopy,artificial neural networks,machine learning,locally connected layer;Performance evaluation,Methane,Meters,Deep learning,Gases,Spectroscopy,Fourier transforms;;;;;;17;;3-feb-22;;;IEEE;IEEE Conferences
Computer Vision-based Social Distancing Surveillance with Automated Camera Calibration for Large-scale Deployment;S. Das, A. Nag, D. Adhikary, R. J. Ram, B. Aravind, S. K. Ojha, G. Hegde;Engineering Data Sciences Robert Bosch Engineering and Business Solutions Private Limited,Bengaluru,India, Engineering Data Sciences Robert Bosch Engineering and Business Solutions Private Limited,Bengaluru,India, Engineering Data Sciences Robert Bosch Engineering and Business Solutions Private Limited,Bengaluru,India, Engineering Data Sciences Robert Bosch Engineering and Business Solutions Private Limited,Bengaluru,India, Engineering Data Sciences Robert Bosch Engineering and Business Solutions Private Limited,Bengaluru,India, Engineering Data Sciences Robert Bosch Engineering and Business Solutions Private Limited,Bengaluru,India, Research & Technology Centre Robert Bosch Engineering and Business Solutions Private Limited,Bengaluru,India;2021 IEEE 18th India Council International Conference (INDICON);1-feb-22;2021;;;1;6;Social distancing has been suggested as one of the effective measures to break the chain of viral transmission in the ongoing COVID-19 pandemic. We herein describe a computer vision-based AI-assisted solution to aid compliance with social distancing norms. The solution consists of modules to detect and track people, and to identify distance violations. It provides the flexibility to choose between a tool-based mode requiring user input or a fully automated mode of camera calibration (devised in-house), making the latter suitable for large-scale deployments. We also outline a strategy to estimate the number of video feeds which can be supported in parallel for scalability. Finally, we discuss different metrics to assess the risk associated with social distancing violations, including the use of “violation clusters”, and how we can differentiate between transient or persistent violations. Our proposed solution performs satisfactorily under different test scenarios, processes video feed at real-time speed, as well as addresses data privacy regulations by blurring faces of detected people, making it ideal for deployments.;2325-9418;978-1-6654-4175-9;10.1109/INDICON52576.2021.9691485;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9691485;Social distancing surveillance,computer vision,deep learning,camera calibration,person detection,tracking;Surveillance,Human factors,Streaming media,Cameras,Social factors,Real-time systems,Calibration;;;;;;29;;1-feb-22;;;IEEE;IEEE Conferences
Forecasting Inflation in Indonesia using Long Short Term Memory;F. F. Savitri, R. Febrianti Siregar, F. Y. Harianto, H. Napitupulu;Universitas Padjadjaran,Department of Statistics,Sumedang,Indonesia, Universitas Padjadjaran,Research Center for Artificial Intelligence and Big Data,Sumedang,Indonesia, Universitas Padjadjaran,Research Center for Artificial Intelligence and Big Data,Sumedang,Indonesia, Universitas Padjadjaran,Research Center for Artificial Intelligence and Big Data,Sumedang,Indonesia;2021 International Conference on Artificial Intelligence and Big Data Analytics;1-feb-22;2021;;;43;49;The problem of inflation has always been a macro problem that occurs in developing countries, especially Indonesia. Observation of the inflation rate cannot be done by observing only certain years because the problem of inflation is a long-term problem. The case of inflation in Indonesia has become quite important to note since Indonesia adopted the inflation target system. Modeling and forecasting the inflation rate is needed and considered important because it is related to poverty alleviation where people with low incomes or still are required to be able to meet their needs with high prices of goods. One of the forecasting models that can be used is the Long Short Term Memory (LSTM). This model is a development of the previous model Recurrent Neural Network (RNN). The results showed that the best model is the model with 5 nodes in hidden layer, Adam optimizer and 0.01 learning rate. Forecasting results show that until September 2022 Indonesia's inflation rate condition will increase but not significantly increase so that it remains stable below 2% until September 2022 and still classified as mild inflation.;;978-1-6654-0890-5;10.1109/ICAIBDA53487.2021.9689700;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9689700;Inflation Rate,LSTM,RNN;Training,COVID-19,Recurrent neural networks,Pandemics,Government,Predictive models,Data models;;;;;;15;;1-feb-22;;;IEEE;IEEE Conferences
Forecasting Inflation in Indonesia using Long Short Term Memory;F. F. Savitri, R. F. Siregar, F. Y. Harianto, H. Napitupulu;Universitas Padjadjaran,Department of Statistics,Sumedang,Indonesia, Universitas Padjadjaran,Research Center for Artificial Intelligence and Big Data,Sumedang,Indonesia, Universitas Padjadjaran,Research Center for Artificial Intelligence and Big Data,Sumedang,Indonesia, Universitas Padjadjaran,Research Center for Artificial Intelligence and Big Data,Sumedang,Indonesia;2021 International Conference on Artificial Intelligence and Big Data Analytics;1-feb-22;2021;;;43;49;The problem of inflation has always been a macro problem that occurs in developing countries, especially Indonesia. Observation of the inflation rate cannot be done by observing only certain years because the problem of inflation is a long-term problem. The case of inflation in Indonesia has become quite important to note since Indonesia adopted the inflation target system. Modeling and forecasting the inflation rate is needed and considered important because it is related to poverty alleviation where people with low incomes or still are required to be able to meet their needs with high prices of goods. One of the forecasting models that can be used is the Long Short Term Memory (LSTM). This model is a development of the previous model Recurrent Neural Network (RNN). The results showed that the best model is the model with 5 nodes in hidden layer, Adam optimizer and 0.01 learning rate. Forecasting results show that until September 2022 Indonesia's inflation rate condition will increase but not significantly increase so that it remains stable below 2% until September 2022 and still classified as mild inflation.;;978-1-6654-0890-5;10.1109/ICAIBDA53487.2021.9689729;Universitas Padjadjaran, ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9689729;Inflation Rate,LSTM,RNN;Training,COVID-19,Recurrent neural networks,Pandemics,Government,Predictive models,Data models;;;;;;15;;1-feb-22;;;IEEE;IEEE Conferences
Prediction New Cases of COVID-19 in Indonesia Using Vector Autoregression (VAR) and Long-Short Term Memory (LSTM) Methods;D. R. Danistya, F. Qaulifa, Y. A. Ramadani, I. Nurma Yulita, M. N. Ardisasmita, D. Agustian;Research Center for Artificial Intelligence and Big Data Padjadjaran University,Bandung,Indonesia, Research Center for Artificial Intelligence and Big Data Padjadjaran University,Bandung,Indonesia, Research Center for Artificial Intelligence and Big Data Padjadjaran University,Bandung,Indonesia, Research Center for Artificial Intelligence and Big Data Padjadjaran University,Bandung,Indonesia, Padjadjaran University,Department of Public Health,Bandung,Indonesia, Padjadjaran University,Department of Public Health,Bandung,Indonesia;2021 International Conference on Artificial Intelligence and Big Data Analytics;1-feb-22;2021;;;1;4;The addition of Covid-19 cases is still uncontrolled, especially in Indonesia. Often the addition of Covid-19 cases in Indonesia always experiences a significant upward trend after a slightly loose government policy. This is because the government does not think there will be a spike in cases after cases go down. This is where the importance of predicting new cases of Covid-19 in Indonesia to be a reference for the government in taking policy. With deep learning, the prediction results will be more accurate. The implementation of vector autoregression (VAR) and long-short term memory (LSTM) methods can reach an accretion rate of up to 98%. With this method, the prediction results can be used for the government in anticipating if there is a surge in new cases per day because it has been predicted from the beginning. In fact, this method can predict new cases for up to a year.;;978-1-6654-0890-5;10.1109/ICAIBDA53487.2021.9689721;Universitas Padjadjaran, ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9689721;New Cases,Prediction,Artificial Intelligence,Vector Autoregression (VAR),Long-Short Term Memory (LSTM);COVID-19,Government policies,Deep learning,Reactive power,Big Data,Market research,Data processing;;;;;;11;;1-feb-22;;;IEEE;IEEE Conferences
Prediction Model for Mortality Analysis of Pregnant Women Affected With COVID-19;Q. A. R. Adib, S. T. Tasmi, S. I. Bhuiyan, M. S. Raihan, A. B. Shams;Brac University,Department of Computer Science and Engineering,Dhaka,Bangladesh, Islamic University of Technology,Department of Computer Science and Engineering,Gazipur,Bangladesh, Islamic University of Technology,Department of Computer Science and Engineering,Gazipur,Bangladesh, Khulna University of Engineering and Technology,Department of Biomedical Engineering,Khulna,Bangladesh, University of Toronto,Department of Electrical and Computer Engineering,Toronto,Canada;2021 24th International Conference on Computer and Information Technology (ICCIT);28-jan-22;2021;;;1;6;COVID-19 pandemic is an ongoing global pandemic which has caused unprecedented disruptions in the public health sector and global economy. The virus, SARS-CoV-2 is responsible for the rapid transmission of coronavirus disease. Due to its contagious nature, the virus can easily infect an unprotected and exposed individual from mild to severe symptoms. The study of the virus’s effects on pregnant mothers and neonatal is now a concerning issue globally among civilians and public health workers considering how the virus will affect the mother and the neonate’s health. This paper aims to develop a predictive model to estimate the possibility of death for a COVID-diagnosed mother based on documented symptoms: dyspnea, cough, rhinorrhea, arthralgia, and the diagnosis of pneumonia. The machine learning models that have been used in our study are support vector machine, decision tree, random forest, gradient boosting, and artificial neural network. The models have provided impressive results and can accurately predict the mortality of pregnant mother’s with a given input. The precision rate for 3 models(ANN, Gradient Boost, Random Forest) is 100% The highest accuracy score(Gradient Boosting, ANN) is 95%, highest recall(Support Vector Machine) is 92.75% and highest f1 score(Gradient Boosting, ANN) is 94.66%. Due to the accuracy of the model, pregnant mother can expect immediate medical treatment based on their possibility of death due to the virus. The model can be utilized by health workers globally to list down emergency patients, which can ultimately reduce the death rate of COVID-19 diagnosed pregnant mothers.;;978-1-6654-9435-9;10.1109/ICCIT54785.2021.9689824;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9689824;Machine Learning,Mortality Analysis,Pregnant Women,COVID-19,Random Forest,Support Vector Machine,Artificial Neural Network,Gradient Boosting,Decision Tree,SMOTE;Pregnancy,COVID-19,Support vector machines,Biological system modeling,Pulmonary diseases,Artificial neural networks,Predictive models;;;;;;25;;28-jan-22;;;IEEE;IEEE Conferences
Application of PSO-BP Neural Network in NTP for Diesel Engine Denitration Experiment;N. Chen, Z. Chen;Jiangsu University of Science and Technology,Energy and Power School,Zhenjiang,Jiangsu,China, Jiangsu University of Science and Technology,Energy and Power School,Zhenjiang,Jiangsu,China;2021 IEEE Conference on Telecommunications, Optics and Computer Science (TOCS);28-jan-22;2021;;;510;514;Artificial neural network is an empirical model that imitates the function of biological neural network. BP neural network is a multi-layer money-box feedback neural system. PSO is an evolutionary computing technology, adopting PSO-BP neural network to achieve faster convergence and more accurate prediction. The removal of NO<inf>x</inf> from diesel engine exhaust as the main power unit of ships is a hot research topic at present. In this paper, a simulated diesel engine distribution system is established, and the denitrification of simulated exhaust gas is studied by non-thermal plasma (NTP) generated by corona discharge. The NO<inf>x</inf> concentration at the exit of NTP system was predicted by PSO-BP neural network, and the NOX concentration at the exit of NTP system was compared with the NOX concentration at the exit of NTP system by the analysis, which verified the accuracy of the experiment.;;978-1-6654-2498-1;10.1109/TOCS53301.2021.9688621;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9688621;diesel engine exhaust,NOx,corona discharge,PSO-BP neural network;Power supplies,Error analysis,Diesel engines,Neural networks,Production,Optics,Discharges (electric);;;;;;12;;28-jan-22;;;IEEE;IEEE Conferences
Prediction Performance and Explainability of COVID-19 Classification Models;N. Phongchit, P. Taeprasartsit;Silpakorn University,department of computing,Nakorn Pathom,Thailand, Silpakorn University,department of computing,Nakorn Pathom,Thailand;2021 25th International Computer Science and Engineering Conference (ICSEC);27-jan-22;2021;;;383;387;The COVID-19 pandemic has been causing the need for better lung-analysis tools to detect disease lesions and evaluate severity of lung damage. However, responsible use of AI in a clinical workflow requires healthcare workers review outputs from AI to judiciously agree or disagree with it. For a classification task, we can examine explanation of its prediction by the use of an explainer such as Grad-CAM. In this work, competent, well-known models, along with their ensemble counterparts, were studied to evaluate their prediction performance and explainability. There are three findings that are main contributions of this work: (1) models with higher prediction performance (e.g., better accuracy) could be outperformed in terms of explainability by models with lower prediction performance, (2) two models producing the same COVID-19 classification result might rely on considerably different features, and (3) while ensemble models created by our approach gained significant improvements in some metrics, they could also get performance degradation in others, and their explainability could be better or worse than their underlying single models. This implication suggests that although we tend to select the model that performs best in metrics that matter the most in a target application, in a clinical environment, it may be better if we employ multiple models so that we can assess explanations from them altogether and prevents incorrect decision from human errors. This is essentially important for a positive case detected by AI, as an accurate model may provide poor explanation, and the expert falsely rejects its correct prediction.;;978-1-6654-1197-4;10.1109/ICSEC53205.2021.9684653;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9684653;XAI,COVID-19,deep learning,ensemble model;COVID-19,Measurement,Pandemics,Computational modeling,Lung,Medical services,Predictive models;;;;;;18;;27-jan-22;;;IEEE;IEEE Conferences
A Machine Learning Approach to Predict Renal Diseases with SARS-CoV-2;M. A. Mahmood, P. Lata;Khulna University of Engineering & Technology (KUET),Institute of Information and Communication Technology,Khulna,Bangladesh, Khulna University of Engineering & Technology (KUET),Institute of Information and Communication Technology,Khulna,Bangladesh;2021 Emerging Technology in Computing, Communication and Electronics (ETCCE);26-jan-22;2021;;;1;6;Research has shown that up to a lot of people hospitalized with COVID-19 get an intense kidney injury. In some serious cases, Kidney failure occurs suddenly without any major symptoms that are totally unpredictable to identify in the early stage. The reason behind that we have a lack of knowledge and experience regarding this. The main purpose of our research is to develop a framework that will assist individuals with foreseeing the danger of constant renal sickness growing rate after being infected with COVID-19. Here we have utilized 773 raw data and trained them and we have also taken care of our missing data. In this paper, we have used KNN, Naïve Bayes, ANN model and Ant Colony Optimization (ACO) for making the system ready for assumption. We have carried out these calculations in the python language. The exactness that we acquire by utilizing KNN calculation is 95%, Naïve bayes is 98.30% ANN is 97.5% and Ant Colony Optimization (ACO) is 95.5% separately which is generally outstanding. By utilizing our proposed strategy, prediction of renal diseases after COVID-19 in the beginning phase will be conceivable. All the data are collected from our neighborhood medical clinic. This research has shown us the current situation in this COVID-19 pandemic with regards to Chronic Kidney Sickness which is known as renal disease.;;978-1-6654-8364-3;10.1109/ETCCE54784.2021.9689894;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9689894;SARS-CoV-2,COVID-19,KNN,Naïve Bayes,ANN,Ant Colony Optimization (ACO);COVID-19,Ant colony optimization,Pandemics,Machine learning,Coronaviruses,Kidney,Injuries;;;;;;19;;26-jan-22;;;IEEE;IEEE Conferences
IoT-enabled model for Digital Twin Of Mental Stress (DTMS);R. Ferdousi, M. A. Hossain, A. El Saddik;Multimedia Communications Research Laboratory (MCRLab) University of Ottawa,School of Electrical Engineering and Computer Science (EECS), King Saud University,College of Computer & Information Sciences,Department of Software Engineering, Multimedia Communications Research Laboratory (MCRLab) University of Ottawa,School of Electrical Engineering and Computer Science (EECS);2021 IEEE Globecom Workshops (GC Wkshps);24-jan-22;2021;;;1;6;Stress has become one of the mental health adversaries of the COVID-19 pandemic. Several stressors like fear of infection, lockdown, and social distancing are commonly accountable for the stress. The existing stress prediction systems are less compatible to handle diversly changing stressors during COVID-19. The traditional approaches often use incomplete features from limited sources (e.g., only wearable sensor or user device) and static prediction techniques. The Edge Artificial Intelligence (Edge AI) employs machine learning to make data from these sources usable for decision making. Therefore, In this study, we propose a Digital Twin of Mental Stress (DTMS) model that employs IoT-based multimodal sensing and machine learning for mental stress prediction. We obtained 98% accuracy for four widely used Machine Learning(ML) algorithms Naïve Bayes(NB), Random Forest(RF), Multilayer Perceptron(MLP), and Decision Tree (DT). The optimal Digital Twin Features (DTF) could reduce the classification time.;;978-1-6654-2390-8;10.1109/GCWkshps52748.2021.9681996;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9681996;COVID-19,Mental Stress,Internet of Things,Digital Twin,Machine Learning;COVID-19,Pandemics,Digital twin,Machine learning,Predictive models,Prediction algorithms,Nonhomogeneous media;;;;;;19;;24-jan-22;;;IEEE;IEEE Conferences
A Survey of The Relationship Between Human Faces And Body Mass Index (BMI);Y. Zhang, W. Li;Xi'an University of Posts and Telecommunications, Institute of Computing Technology,CAS;2021 IEEE Globecom Workshops (GC Wkshps);24-jan-22;2021;;;1;6;Nowadays, under the influence of the COVID 19 epidemic, risks of obesity are increasing. Body mass index (BMI) is a good measure of obesity and studies have proved that face is affected by BMI. If we could find a model to predict BMI by human face, it will reduce the time costs and the infection risk of the hospital. However, the number of relevant studies is limited. There are predictive models for BMI but not relevant models for Asian faces. In this paper, collected relevant studies were analyzed and classified based on research objectives and research methods, according to the classification, a face prediction BMI model which uses residual network and Asian face datasets was recommended. In the end, we summarize all the researches and list the directions not researched and innovative places.;;978-1-6654-2390-8;10.1109/GCWkshps52748.2021.9682060;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9682060;BMI,Face Recognition,Obesity,Deep Learning;Obesity,Epidemics,Costs,Hospitals,Face recognition,Predictive models,Feature extraction;;;;;;13;;24-jan-22;;;IEEE;IEEE Conferences
COVID-19 impact on students' Mental Health: Explainable AI and Classifiers;A. Ul Hussna, I. Immami Trisha, I. Jahan Ritun, M. G. Rabiul Alam;BRAC University,Department of Computer Science and Engineering,Dhaka,Bangladesh, BRAC University,Department of Computer Science and Engineering,Dhaka,Bangladesh, BRAC University,Department of Computer Science and Engineering,Dhaka,Bangladesh, BRAC University,Department of Computer Science and Engineering,Dhaka,Bangladesh;2021 International Conference on Decision Aid Sciences and Application (DASA);24-jan-22;2021;;;847;851;COVID-19, lockdown, and isolation have included an enormous impact on the students around the world like others. As isolation strategy with quarantine is useful to prevent transmission, students remaining at home gained nothing but illness perception, anxiety, and depression in spite of sharpening their knowledge and reflecting the thoughts. The detachment from routine life has affected the pillars of the mental health balance and isolated and suffocating lives have created toxic feelings in lives. Therefore the purpose of our paper is to predict the mental health of students in such situations. To accomplish our work, we have collected the students' mental health survey dataset from the Kaggle website later trained the data with suitable classifiers to predict mental health. In this paper, we demonstrated five different classifiers models to predict optimal accuracy, including two different Explainable AI (XAI) techniques (LIME, SHAP) as it enhances the trust in an AI system.;;978-1-6654-1634-4;10.1109/DASA53625.2021.9682371;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9682371;COVID-19,XAI,LIME,SHAP,random forest,xgboost,logistic regression,ANN,adaboost,mental health;COVID-19,Biological system modeling,Anxiety disorders,Education,Mental health,Machine learning,Forestry;;;;;;11;;24-jan-22;;;IEEE;IEEE Conferences
An air quality prediction model based on deep learning and wavelet analysis considering the COVID-19 pandemic factors;T. Pu, H. Cai, G. He, Y. Luo, M. Wu;Southwest University of Science and Technology,School of Science,Mianyang,China, Southwest University of Science and Technology,School of Computer Science and Technology,Mianyang,China, Southwest University of Science and Technology,School of Computer Science and Technology,Mianyang,China, Southwest University of Science and Technology,School of Computer Science and Technology,Mianyang,China, Southwest University of Science and Technology,School of Computer Science and Technology,Mianyang,China;2021 IEEE International Performance, Computing, and Communications Conference (IPCCC);20-jan-22;2021;;;1;2;Based on the air pollution data in China from January 1,2014 to December 31,2020, the characteristics of extreme value and period of air quality in different regions on different time scales were studied by using wavelet analysis. Wavelet coherence analysis was used to evaluate the relationship between air quality and meteorological factors in the period of COVID-19. We found that the spatial characteristics of air quality changed significantly in summer. Generally, air pollution is more severe in spring and winter. During the lockdown period, the overall air quality in the study area improved significantly. In general, except for O3, the concentration of all other pollutants has dropped considerably. The improvement in air quality is a direct result of emission reductions due to the implementation of the COVID-19 blockade, which is unsustainable in the long term. Eventually, a prediction model attention_CNN_LSTM based on deep learning method is proposed in this paper. The experimental results show that the attention proposed in this study the model has a good prediction effect in the long-term prediction of air quality, but the attention mechanism's impact is lower. After shortening the prediction period, the attention_CNN_LSTM model has good prediction performance on most data sets, with average MAPE = 2.67% and RMSE = 2.29.;2374-9628;978-1-6654-4331-9;10.1109/IPCCC51483.2021.9679440;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9679440;Air quality prediction,Deep Learning,Wavelet Analysis,Attention_CNN_LSTM,COVID-19;COVID-19,Deep learning,Pandemics,Meteorological factors,Atmospheric modeling,Computational modeling,Predictive models;;;;;;2;;20-jan-22;;;IEEE;IEEE Conferences
Deep Learning in Agronomic Forecast;S. P. P, B. S, P. R;Sri Ramakrishna Engineering College,Department of Computer Science and Engineering,Coimbatore,India, Sri Ramakrishna Engineering College,Department of Computer Science and Engineering,Coimbatore,India, Sri Ramakrishna Engineering College,Department of Computer Science and Engineering,Coimbatore,India;2021 5th International Conference on Electronics, Communication and Aerospace Technology (ICECA);20-jan-22;2021;;;116;121;In India, Agriculture plays an imperative role in the development of our country. More than 50% of entirety populace of India is directly or indirectly depends on agriculture and the agronomist are the backbone of the agronomic diligence but the agricultural backdrop facing decades-long tribulations and unpredicted challenges that are so critical to resolve. Some of the major issues that agronomist finding hard is water scarcity, soil erosion, lack of market intellect, poor quality of seeds, usage of fertilizers, inadequate knowledge on preserving soil for further cultivation etc. In addition to this, due to Covid19, still more problems faced by farmers are shortage of agri-inputs, lack of laborers and transportation of farm products. In order to rectify some of the agricultural tribulations, this paper has been primed as an effort to re-evaluate the study on the significance of deep learning techniques in the domain of agro crop yield production and rainfall-temperature forecasting with respect to density. The objective is to build an application that is user-friendly for the agronomist suggesting legitimate crop selection fine points according to the crop year, zone, season, soil nutrient on their farm which hikes the yield of the crops devoid of fertilizers and preserving the soil composition without degradation as well. This work integrates finding soil nutrients such as Nitrogen, Potassium, and Phosphorous. The input parameters considered for predicting the crop are likely the district, the crop year and the previous crop planted. Based on the survey, Artificial Neural Networks(ANN), Convolutional Neural Network(CNN), Decision Tree, Recurrent Neural Network (RNN), Random Forest and Support Vector Machine(SVM) classification models are the best models to predict accurate values and obtained the optimized results.;;978-1-6654-3524-6;10.1109/ICECA52323.2021.9675858;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9675858;Deep learning,Crop yield,Prediction,Agronomist,Soil;Deep learning,Recurrent neural networks,Crops,Transportation,Support vector machine classification,Production,Soil;;;;;;15;;20-jan-22;;;IEEE;IEEE Conferences
Empirical Quantitative Analysis of COVID-19 Forecasting Models;Y. Zhao, Y. Wang, J. Liu, H. Xia, Z. Xu, Q. Hong, Z. Zhou, L. Petzold;University of California,Department of Computer Science,Santa Barbara,CA,USA, University of California,Department of Computer Science,Santa Barbara,CA,USA, University of California,Department of Computer Science,Santa Barbara,CA,USA, University of California,Department of Computer Science,Santa Barbara,CA,USA, University of California,Department of Computer Science,Santa Barbara,CA,USA, University of California,Department of Computer Science,Santa Barbara,CA,USA, Northwestern University Feinberg School of Medicine,Department of Preventive Medicine,Chicago,IL,USA, University of California,Department of Computer Science,Santa Barbara,CA,USA;2021 International Conference on Data Mining Workshops (ICDMW);20-jan-22;2021;;;517;526;COVID-19 has been a public health emergency of international concern since early 2020. Reliable forecasting is critical to diminish the impact of this disease. To date, a large number of different forecasting models have been proposed, mainly including statistical models, compartmental models, and deep learning models. However, due to various uncertain factors across different regions such as economics and government policy, no forecasting model appears to be the best for all scenarios. In this paper, we perform quantitative analysis of COVID-19 forecasting of confirmed cases and deaths across different regions in the United States with different forecasting horizons, and evaluate the relative impacts of the following three dimensions on the predictive performance (improvement and variation) through different evaluation metrics: model selection, hyperparameter tuning, and the length of time series required for training. We find that if a dimension brings about higher performance gains, if not well-tuned, it may also lead to harsher performance penalties. Furthermore, model selection is the dominant factor in determining the predictive performance. It is responsible for both the largest improvement and the largest variation in performance in all prediction tasks across different regions. While practitioners may perform more complicated time series analysis in practice, they should be able to achieve reasonable results if they have adequate insight into key decisions like model selection.;2375-9259;978-1-6654-2427-1;10.1109/ICDMW53433.2021.00069;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9679932;COVID-19 Pandemic,Time Series Forecasting,SARIMA Model,SEIR-HCD Model,Deep Learning;COVID-19,Training,Analytical models,Statistical analysis,Biological system modeling,Time series analysis,Predictive models;;;;;;30;;20-jan-22;;;IEEE;IEEE Conferences
Analyzing and Battling The Emerging Variants Of Covid-19 Using Artificial Neural Network And Blockchain;R. U. Khan, A. U. Haq, S. M. Hussain, S. Ullah, S. Almakdi, R. Kumar, H. H. Shah, J. Li;University of Electronic Science and Technology of China,Yangtze Delta Region Institute (Huzhou),China,313001, University of Electronic Science and Technology of China,School of Computer Science and Engineering,Chengdu,China, Balochistan University of Information Technology,Engineering and Management Sciences (BUITEMS),Department of Mathematical Sciences,Quetta,Pakistan,87300, Chengdu University of Technology,Chengdu,China, Najran University,College of Computer Science and Information Systems,Department of Computer Science,Najran,Saudi Arabia,55461, University of Electronic Science and Technology of China,Yangtze Delta Region Institute (Huzhou),China,313001, Balochistan University of Information Technology,Engineering and Management Sciences (BUITEMS),Department of Mathematical Sciences,Quetta,Pakistan,87300, University of Electronic Science and Technology of China,School of Computer Science and Engineering,Chengdu,China;2021 18th International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP);19-jan-22;2021;;;101;105;The fast expansion of the COVID-19 epidemic has revealed the shortcomings of current healthcare institutions in dealing with public emergency situations. One of the big reasons of Covid-19 spread is the lack of standard track and trace mechanisms in healthcare infrastructures. Furthermore, throughout the epidemic, the transmission of disinformation has accelerated, and existing platforms lacking capability of verifying the veracity of information, resulting to social unrest and illogical conduct. Therefore, building a track and trace system is critical to ensuring that data collected by the government and the public entities is accurate and dependable. It is obvious that implementing state-of-the-art predictive models like Artificial Neural Network and Blockchain-based traceable mechanisms can help to prevent the spreads of the new variants. In this paper, we proposed a Blockchain based traceable model to track and trace the infected cases so to help an effective planning to prevent the spread.;2576-8964;978-1-6654-1364-0;10.1109/ICCWAMTIP53232.2021.9674142;National Natural Science Foundation of China(grant numbers:U2033212), University of Electronic Science and Technology of China(grant numbers:U03210068), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9674142;Forecasting,Artificial Neural Network,Blockchain,B1.1.529-Omicron,Predictive Model;COVID-19,Computational modeling,Artificial neural networks,Medical services,Predictive models,Media,Mathematical models;;;;;;17;;19-jan-22;;;IEEE;IEEE Conferences
Machine learning methods as a tool for diagnostic and prognostic research in cardiovascular disease;C. Khidirova, S. Sadikova, S. Mukhsinov, G. Nashvandova, S. Mirzaeva;Tashkent University of Information Technologies named after Muhammad al-Khwarizmi,Department of System and Applied Programming,Tashkent,Uzbekistan, Tashkent State Technical University,Department of Information Processing and Control Systems,Tashkent,Uzbekistan, Tashkent University of Information Technologies named after Muhammad al-Khwarizmi,Department of System and Applied Programming,Tashkent,Uzbekistan, Tashkent State Technical University,Department of Information Processing and Control Systems,Tashkent,Uzbekistan, Tashkent State Technical University,Department of Information Processing and Control Systems,Tashkent,Uzbekistan;2021 International Conference on Information Science and Communications Technologies (ICISCT);17-jan-22;2021;;;1;6;Machine learning (ML) methods are the main tool of artificial intelligence, the use of which makes it possible to automate the processing and analysis of big data, to reveal hidden or non-obvious patterns on this basis, and to extract new knowledge. The review presents an analysis of scientific literature on the use of ML methods for diagnosing and predicting the clinical course of coronary heart disease. Provides information on reference databases, the use of which allows you to develop models and validate them (European ST-T Database, Cleveland Heart Disease database, Multi-Ethnic Study of Atherosclerosis, etc.). The advantages and disadvantages of individual ML methods (logistic regression, support vector machines, decision trees, naive Bayesian classifier, k-nearest neighbors) for the development of diagnostic and predictive algorithms are shown. The most promising ML methods include deep learning, which is implemented using multilayer artificial neural networks. It is assumed that the improvement of models based on ML methods and their introduction into clinical practice will help support medical decision-making, improve the effectiveness of treatment and optimize health care costs.;;978-1-6654-3258-0;10.1109/ICISCT52966.2021.9670168;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9670168;machine learning,logistic regression,support vector machines,decision trees,naive Bayesian classifier,k-nearest neighbors,diagnostic and predictive models,ischemic heart disease;Heart,Databases,Support vector machine classification,Medical services,Predictive models,Prediction algorithms,Nonhomogeneous media;;;;;;56;;17-jan-22;;;IEEE;IEEE Conferences
Personalized Stress Monitoring AI System For Healthcare Workers;R. G. Bangani, V. Menon, E. Jovanov;University of Alabama,Department of Computer Science,Huntsville,USA, University of Alabama,Department of Computer Science,Huntsville,USA, University of Alabama,Department of Electrical and Computer Engineering,Huntsville,USA;2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM);14-jan-22;2021;;;2992;2997;In the current COVID-19 pandemic scenario, healthcare workers, in particular nurses, face prolonged exposure to stress. This intense duress takes a toll on their health overtime, affects their quality of life, and in turn impacts the quality of care provided to the patients. Hence, real-time detection and monitoring of stress is extremely important for early detection of stress patterns, prevention of burnouts and chronic conditions in healthcare workers as well as facilitate improved patient-care outcomes. In this paper, we present a proof-of-concept case study using machine learning (ML) and artificial intelligence (AI)-based stress detection model that determines a personalized assessment of stress level using heart rate, heart rate variability, and physical activity of the users. We used wearable electrocardiogram and inertial sensor to record heart activity and physical activity of nurses during their shifts. Our preliminary results indicate that the proposed stress tracking model can effectively predict any stress occurrences. This study is a pivotal attempt to emphasize the significance of stress-detection and relief for healthcare workers and provide them a tool for an effective assessment of personalized stress levels.;;978-1-6654-0126-5;10.1109/BIBM52615.2021.9669321;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9669321;Personalized stress monitoring,machine learning,CNN,AI,K-Means clustering,classification;Training,Pandemics,Inertial sensors,Medical services,Machine learning,Predictive models,Real-time systems;;;;;;12;;14-jan-22;;;IEEE;IEEE Conferences
Multi-modal Information Fusion-powered Regional Covid-19 Epidemic Forecasting;H. Zhang, Y. Xu, L. Liu, X. Lu, X. Lin, Z. Yan, L. Cui, C. Miao;Shandong University,School of Software,China, Shandong University,Joint SDU-NTU Centre for Artificial Intelligence Research (C-FAIR),China, Shandong University,Joint SDU-NTU Centre for Artificial Intelligence Research (C-FAIR),China, Shandong University,School of Software,China, Shandong University,School of Software,China, Shandong University,School of Software,China, Shandong University,Joint SDU-NTU Centre for Artificial Intelligence Research (C-FAIR),China, Nanyang Techonlogical University,Joint NTU-UBC Research Centre of Excellence in Active Living for the Elderly,Singapore;2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM);14-jan-22;2021;;;779;784;With the current raging spread of the COVID19, early forecasting of the future epidemic trend is of great significance to public health security. The COVID-19 is virulent and spreads widely. An outbreak in one region often triggers the spread of others, and regions with relatively close association would show a strong correlation in the spread of the epidemic. In the real world, many factors affect the spread of the outbreak between regions. These factors exist in the form of multimodal data, such as the time-series data of the epidemic, the geographic relationship, and the strength of social contacts between regions. However, most of the current work only uses historical epidemic data or single-modal geographic location data to forecast the spread of the epidemic, ignoring the correlation and complementarity in multi-modal data and its impact on the disease spread between regions. In this paper, we propose a Multimodal InformatioN fusion COVID-19 Epidemic forecasting model (MINE). It fuses inter-regional and intra-regional multi-modal information to capture the temporal and spatial relevance of the COVID-19 spread in different regions. Extensive experimental results show that the proposed method achieves the best results compared to state-of-art methods on benchmark datasets.;;978-1-6654-0126-5;10.1109/BIBM52615.2021.9669328;National Natural Science Foundation of China, Shandong University, ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9669328;multi-modal information fusion,COVID-19 forecasting,graph neural network,self-attention,social network analysis;COVID-19,Epidemics,Correlation,Fuses,Biological system modeling,Network analyzers,Predictive models;;;;;;20;;14-jan-22;;;IEEE;IEEE Conferences
Predicting the Length of Stay of Patients in Hospitals;Z. Fu, X. Gu, J. Fu, M. Moattari, F. Zulkernine;Queen’s University,School of Computing,Kingston,Ontario,Canada, Queen’s University,School of Computing,Kingston,Ontario,Canada, Queen’s University,School of Computing,Kingston,Ontario,Canada, Queen’s University,School of Computing,Kingston,Ontario,Canada, Queen’s University,School of Computing,Kingston,Ontario,Canada;2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM);14-jan-22;2021;;;3150;3156;Due to the intensive treatment process of coronavirus pneumonia cases, it is important to predict the Length of Stay (LOS) of patients at the hospital to allow better management of resources and increase the efficiency of hospital services to provide improved healthcare. To predict LOS, we used four artificial neural network models namely the Multilayer Perceptron (MLP), Convolutional Neural Network (CNN), Multilayer Perceptron with PCA (PCA+MLP), and the Bidirectional Long Short Term Memory (BiLSTM) model to analyze the advantages and disadvantages of the different models using the Microsoft Hospital Length of Stay data. The proposed method is compared with the state-of-the-art models and a simple MLP model. Our models achieved an accuracy between 73% and 88% with the CNN model providing the highest accuracy.;;978-1-6654-0126-5;10.1109/BIBM52615.2021.9669527;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9669527;ANNs,CNN,LSTM,COVID-19,Corona,hospital length of stay,accuracy,predictive analytics;COVID-19,Analytical models,Hospitals,Urban areas,Predictive models,Multilayer perceptrons,Data models;;;;;;29;;14-jan-22;;;IEEE;IEEE Conferences
An Interpretable Multi-Level Enhanced Graph Attention Network for Disease Diagnosis with Gene Expression Data;X. Xing, F. Yang, H. Li, J. Zhang, Y. Zhao, M. Gao, J. Huang, J. Yao;The Chinese University of Hong Kong,Department of Electronic Engineering,Shatin,Hong Kong,China, AI Lab,Tencent,Shenzhen,China, AI Lab,Tencent,Shenzhen,China, AI Lab,Tencent,Shenzhen,China, AI Lab,Tencent,Shenzhen,China, AI Lab,Tencent,Shenzhen,China, AI Lab,Tencent,Shenzhen,China, AI Lab,Tencent,Shenzhen,China;2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM);14-jan-22;2021;;;556;561;Clinical omics, especially gene expression data, have been widely studied and successfully applied for disease diagnosis using machine learning techniques. As genes often work interactively rather than individually, investigating co-functional gene modules can improve our understanding of disease mechanisms and facilitate disease state prediction. To this end, we in this paper propose a novel Multi-Level Enhanced Graph ATtention (MLE-GAT) network to explore the gene modules and intergene relational information contained in the omics data. In specific, we first format the omics data of each patient into co-expression graphs using weighted correlation network analysis (WGCNA) and then feed them to a well-designed multi-level graph feature fully fusion (MGFFF) module for disease diagnosis. For model interpretation, we develop a novel full-gradient graph saliency (FGS) mechanism to identify the disease-relevant genes. Comprehensive experiments show that our proposed MLE-GAT achieves state-of-the-art performance on transcriptomics data from TCGA-LGG/TCGA-GBM and proteomics data from COVID-19/non-COVID-19 patient sera.;;978-1-6654-0126-5;10.1109/BIBM52615.2021.9669621;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9669621;Gene co-expression graph,disease diagnosis,graph neural network.;COVID-19,Biological system modeling,Neural networks,Proteomics,Network analyzers,Machine learning,Medical diagnosis;;;;;;24;;14-jan-22;;;IEEE;IEEE Conferences
Extracting geographical characteristics about COVID-19 evolution worldwide using machine learning;A. -R. Passadakis, A. Vlachos, P. Tzouveli, S. Kollias;National Technical University of Athens,School of Electrical and Computer Engineering,Athens,Greece, National Technical University of Athens,School of Electrical and Computer Engineering,Athens,Greece, National Technical University of Athens,School of Electrical and Computer Engineering,Athens,Greece, National Technical University of Athens,School of Electrical and Computer Engineering,Athens,Greece;2021 IEEE International Conference on Big Data (Big Data);13-jan-22;2021;;;5978;5981;Since the beginning of 2020, the whole world has been plagued by the coronavirus pandemic. During the last sixteen months, almost every country in the world has faced several epidemic waves. An intriguing question that arises is whether neighboring countries, similar in regard to their socioeconomic status and the restrictions employed to counter the spread of the virus, showcase similarities in their respective number of cases and deaths. To that end, in this paper we form three clusters of similar countries (European and USA, African-Asian and Latin American) and we use their cumulative data as training data for machine learning models (RNN family, TCN and Attention) that predict the respective cases and deaths of 4 fixed neighboring countries, namely Cyprus, Greece, Italy and Spain. The results of the experiments conducted show that these 4 countries accent bigger similarity with the European cluster, as expected. Thus, evidence is provided bolstering the claim that similar neighboring countries exhibit alike behavior regarding the repercussions of the COVID-19.;;978-1-6654-3902-2;10.1109/BigData52589.2021.9671797;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9671797;COVID-19 cases/deaths,Machine learning,RNNs,Attention,Time Series,Geographical features and similarity;COVID-19,Pandemics,Europe,Training data,Machine learning,Big Data,Predictive models;;;;;;16;;13-jan-22;;;IEEE;IEEE Conferences
Beyond a binary of (non)racist tweets: A four-dimensional categorical detection and analysis of racist and xenophobic opinions on Twitter in early Covid-19;X. Pei, D. Mehta;School of International Communications University of Nottingham,Ningbo,China, Monash eResearch Centre Monash University,Melbourne,Australia;2021 IEEE International Conference on Big Data (Big Data);13-jan-22;2021;;;2510;2515;Transcending the binary categorization of racist and xenophobic texts, this research takes cues from social science theories to develop a four-dimensional category for racism and xenophobia detection, namely stigmatization, offensiveness, blame, and exclusion. With the aid of deep learning techniques, this categorical detection enables insights into the nuances of emergent topics reflected in racist and xenophobic expression on Twitter. Moreover, a stage wise analysis is applied to capture the dynamic changes of the topics across the stages of early development of Covid-19 from a domestic epidemic to an international public health emergency, and later to a global pandemic. The main contributions of this research include, first the methodological advancement. By bridging the state-of-the-art computational methods with social science perspective, this research provides a meaningful approach for future research to gain insight into the underlying subtlety of racist and xenophobic discussion on digital platforms. Second, by enabling a more accurate comprehension and even prediction of public opinions and actions, this research paves the way for the enactment of effective intervention policies to combat racist crimes and social exclusion under Covid-19.;;978-1-6654-3902-2;10.1109/BigData52589.2021.9671945;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9671945;racism,xenophobia,covid-19,twitter;COVID-19,Deep learning,Social networking (online),Pandemics,Conferences,Social sciences,Blogs;;;;;;30;;13-jan-22;;;IEEE;IEEE Conferences
Modeling Influenza with a Forest Deep Neural Network Utilizing a Virtualized Clinical Semantic Network;F. Rahman, A. Rahman, A. S. Azad Rabby, M. J. Rahman Rifat, M. Banik, M. M. Islam, A. Islam, N. A. Aziz, R. Meyer, J. Kriak, S. Goldblatt;Apurba Technologies,CA,USA, The University of California,Berkeley,CA,USA, The University of Alabama at Birmingham,AL,USA, The University of Alabama at Birmingham,AL,USA, Colorado State University,CO,USA, The University of Alabama at Birmingham,AL,USA, The University of Alabama at Birmingham,AL,USA, Apurba Technologies,Malaysia, Goldblatt Systems,AZ,USA, MolecularDx LLC,PA,USA, Goldblatt Systems,AZ,USA;2021 IEEE International Conference on Big Data (Big Data);13-jan-22;2021;;;4753;4760;CoViD-19 pandemic has shown that we have deep gaps in understanding this extremely infectious virus—not only both from a clinical diagnosis and treatment perspective—but also from a forecasting point of view, so that we are better prepared for the next onset of a similar pandemic, which, at this point, seems almost inevitable. In this paper, we present a novel approach towards modeling influenza, a closely related disease to CoViD-19, marrying clinical understanding with artificial intelligence, exploiting the Forest Deep Neural Network (fDNN) with accuracy rates in the 90% range.;;978-1-6654-3902-2;10.1109/BigData52589.2021.9671507;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9671507;FDNN,Disease modeling,vCSN,Influenza,NLP;COVID-19,Deep learning,Analytical models,Pandemics,Neural networks,Semantics,Influenza;;;;;;23;;13-jan-22;;;IEEE;IEEE Conferences
A Human Mobility Data Driven Hybrid GNN+RNN Based Model For Epidemic Prediction;S. Mahmud, H. Shen, Y. N. Z. Foutz, J. Anton;University of Virginia,Department of Computer Science,Charlottesville,VA,USA, University of Virginia,Department of Computer Science,Charlottesville,VA,USA, University of Virginia,McIntire School of Commerce,Charlottesville,VA,USA, X-Mode social,Reston,VA,USA;2021 IEEE International Conference on Big Data (Big Data);13-jan-22;2021;;;857;866;Epidemic simulation traditionally serves as one of the important methods to forecast how an epidemic may spread among a population. However, there are two key limitations that restrict the scope of such methods. The first limitation is that the existing tools rely on different sets of static parameters (e.g., infection probability, recovering probability) for simulating an epidemic spread that may fail to capture the dynamic nature of population interactions that acts as a dominant factor in an epidemic spread scenario such as COVID-19 pandemic. To handle this challenge, we propose a machine learning based model that combines a Graph Convolutional Neural Network (GCN) and a Recurrent Neural Network (RNN). It integrates the ability of the GCN to capture spatial dependency in human interaction and the ability of the RNN to incorporate temporal effects of the virus spread. The second limitation is that these methods do not address the computation overhead problem when dealing with time-dynamic graphs. Training a GCN on a very large graph suffers from the communication overhead from different graph partitions and the computation overheads stemming from partitioning dynamic graphs. This limitation impacts the scalability of the existing systems. To solve this challenge, we partition the graph in a computationally less expensive manner by partitioning the graph using the min-cut principle. We conducted comprehensive large scale real-world human mobility data driven experiments. Our experimental result shows that the proposed machine learning based forecasting model achieves overall 84% classification accuracy with greater than 72% precision and 62% recall. Also, the proposed graph partitioning approach reduces computation time and commutation overhead by a significant margin.;;978-1-6654-3902-2;10.1109/BigData52589.2021.9671474;Microsoft Research, ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9671474;;Training,Epidemics,Recurrent neural networks,Computational modeling,Sociology,Machine learning,Predictive models;;;;;;37;;13-jan-22;;;IEEE;IEEE Conferences
Use of Natural Language Processing and Deep Learning towards Guiding Healthy Cholesterol Free Life;D. Sasanka, H. K. N. Malshani, U. I. Wickramaratne, Y. Kavindi, M. Tissera, B. Attanayaka;Sri Lanka Institute of Information Technology,Computer Systems Engineering Department,Malabe,Sri Lanka, Sri Lanka Institute of Information Technology,Computer Systems Engineering Department,Malabe,Sri Lanka, Sri Lanka Institute of Information Technology,Computer Systems Engineering Department,Malabe,Sri Lanka, Sri Lanka Institute of Information Technology,Computer Systems Engineering Department,Malabe,Sri Lanka, Sri Lanka Institute of Information Technology,Computer Systems Engineering Department,Malabe,Sri Lanka, Sri Lanka Institute of Information Technology,Computer Systems Engineering Department,Malabe,Sri Lanka;2021 3rd International Conference on Advancements in Computing (ICAC);11-jan-22;2021;;;152;157;High blood cholesterol is a key risk factor for cardiovascular diseases such as coronary heart disease and stroke. This has become a severe health problem, because it causes a considerable amount of deaths annually. The major risk factors that affect a person’s cholesterol level include unawareness of cholesterol risk, unhealthy dietary habits, lack of proper exercises, and high stress conditions. In this research, novel approaches are introduced to provide an automated and personalized guidance to maintain healthy cholesterol level and raise the awareness of each risk factors mentioned above. This research associates with four novel approaches. Natural Language Processing (NLP) based Cholesterol risk analyzer, Fuzzy based Food management with Meal predictor, Machine Learning based Physical exercise planner and Stress controller. Altogether with results, this research will provide a complete and facts-proven solution to reduce and guide people towards a cholesterol-free healthy lifestyle.;;978-1-6654-0862-2;10.1109/ICAC54203.2021.9671230;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9671230;High blood cholesterol,Cholesterol risk,Natural Language Processing,Fuzzy ontology,Multiple linear regression,Stress scale;Optical filters,Schedules,Natural language processing,Frequency measurement,Software reliability,Data mining,Stress;;;;;;10;;11-jan-22;;;IEEE;IEEE Conferences
Stress Analysis and Care Prediction System for Online Workers;A. A. S. M. Amarasinghe, I. M. S. Malassri, K. C. N. Weerasinghe, I. B. Jayasingha, P. K. W. Abeygunawardhana, S. Silva;Sri Lanka Institute of Information Technology,Department of Information Technology,Colombo,Sri Lanka, Sri Lanka Institute of Information Technology,Department of Information Technology,Colombo,Sri Lanka, Sri Lanka Institute of Information Technology,Department of Information Technology,Colombo,Sri Lanka, Sri Lanka Institute of Information Technology,Department of Information Technology,Colombo,Sri Lanka, Sri Lanka Institute of Information Technology,Department of Computer System Engineering,Colombo,Sri Lanka, Sri Lanka Institute of Information Technology,Department of Computer System Engineering,Colombo,Sri Lanka;2021 3rd International Conference on Advancements in Computing (ICAC);11-jan-22;2021;;;329;334;Working from home (WFH) online during the covid-19 pandemic has caused increased stress level. Online workers/students have been affecting by the crisis according to new researches. Natural response of body, to external and internal stimuli is stress. Even though stress is a natural occurrence, prolonged exposure while working Online to stressors can lead to serious health problems if any action will not be applied to control it. Our research has been conducted deeply to identify the best parameters, which have connection with stress level of online workers. As a result of our research, a desktop application has been created to identify the users stress level in real time. According to the results, our overall system was able to provide outputs with more than 70% accuracy. It will give best predictions to avoid the health problems. Our main goal is to provide best solution for the online workers to have healthy lifestyles. Updates for the users will be provided according to the feedback we will have in the future from the users. Our System will be a most valuable application in the future among online workers.;;978-1-6654-0862-2;10.1109/ICAC54203.2021.9671106;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9671106;stress detection,fatigue recognition,emotion detection,behavior detection,keystroke detection,CNN,VGG16;COVID-19,Transient response,Pandemics,Real-time systems,Stress;;;;;;18;;11-jan-22;;;IEEE;IEEE Conferences
ICU Ventilator Estimation in Hospitals for COVID19 Infected Patients in NCT Delhi, India;V. Abhyankar, A. Sharma, R. Thakkar, M. Keshav, S. Rajkumar, S. Prakash;Vellore Institute of Technology,School of Electronics Engineering,Vellore,India, Vellore Institute of Technology,School of Electronics Engineering,Vellore,India, Arizona State University,Department of Electrical Engineering,Arizona,USA, Vellore Institute of Technology,School of Electronics Engineering,Vellore,India, Vellore Institute of Technology,School of Electronics Engineering,Vellore,India, IIIT Allahabad,Department of ECE,Prayagraj,India;2021 IEEE Bombay Section Signature Conference (IBSSC);11-jan-22;2021;;;1;4;COVID19 pandemic originated in China in 2019 and has significantly affected the world with over 16 crore cases. The pandemic up to now has claimed the lives of around 258,000 people in India. All India’s major cities have been heavily affected due to this pandemic, with many health and economic issues coming to the fore. NCT of Delhi is one of the most badly pandemic-hit regions in the country, with over 13,60,000 confirmed cases and around 21,000 deaths. As of 13<sup>th</sup> May 2021, India is experiencing a horrific second COVID19 wave, while Delhi is experiencing its fourth localized COVID19 wave. There is a significant crunch in Patients’ hospital beds, intensive care unit (ICU) beds, COVID19 ventilators and oxygen cylinders. This study developed a deep learning model to predict COVID19 cases in NCT Delhi, India. The model considers the trends in recovery rate, active cases, cases with comorbidities and patient data to predict the likely number of ICU ventilators dedicated to COVID19 patients required shortly. The testing rates and the serosurvey results were also considered while making the predictions. This study aims to provide the concerned authorities with an estimate of daily Covid19 cases and ventilators required in the near future and hope to help combat the pandemic.;;978-1-6654-1758-7;10.1109/IBSSC53889.2021.9673196;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9673196;Coronavirus Disease 2019 (COVID19),COVID19 Pandemic,COVID19 Patients Analysis,ICU Ventilator Estimation,SARIIqSq Model;COVID-19,Ventilators,Pandemics,Hospitals,Urban areas,Predictive models,Market research;;;;;;20;;11-jan-22;;;IEEE;IEEE Conferences
Automatic Identification of Student’s Cognitive Style from Online Laboratory Experimentation using Machine Learning Techniques;A. M. F. Yousef, A. Atia, A. Youssef, N. A. S. Eldien, A. Hamdy, A. M. A. El-Haleem, M. M. Elmesalawy;Fayoum University,Faculty of Specific Education,Education Technology Department,Fayoum,Egypt, Helwan University,HCI-LAB, Faculty of Computers and Artificial Intelligent,Computer Science Department,Cairo,Egypt, New Cairo Academy,Computer Science and Information Technology Department,Cairo,Egypt, October University for Modern Sciences and Arts (MSA),Faculty of Computer Science,Giza,Egypt, Misr International University,Faculty of Computer Science,Cairo,Egypt, Helwan University,Faculty of Engineering,Electronics and Communications Engineering Department,Cairo,Egypt, British University in Egypt (BUE),Faculty of Engineering,Electrical and Communication Engineering Department,Cairo,Egypt;2021 IEEE 12th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON);10-jan-22;2021;;;143;149;Online learning has emerged as powerful learning methods for the transformation from traditional education to open learning through smart learning platforms due to Covid-19 pandemic. Despite its effectiveness, many studies have indicated the necessity of linking online learning methods with the cognitive learning styles of students. The level of students always improves if the teaching methods and educational interventions are appropriate to the cognitive style of each student individually. Currently, psychological measures are used to assess students’ cognitive styles, but about the application in virtual environment, the matter becomes complicated. The main goal of this study is to provide an efficient solution based on machine learning techniques to automatically identify the students’ cognitive styles by analyzing their mouse interaction behaviors while carrying out online laboratory experiments. This will help in the design of an effective online laboratory experimentation system that is able to individualize the experiment instructions and feedback according to the identified cognitive style of each student. The results reveal that the KNN and SVM classifiers have a good accuracy in predicting most cognitive learning styles. In comparison to KNN, the enlarged studies ensemble the KNN, linear regression, neural network, and SVM reveal a 13% increase in overall total RMS error. We believe that this finding will enable educators and policy makers to predict distinct cognitive types in the assessment of students when they interact with online experiments. We believe that integrating deep learning algorithms with a greater emphasis on mouse location traces will improve the accuracy of our classifiers’ predictions.;;978-1-6654-0690-1;10.1109/UEMCON53757.2021.9666516;Academy of Scientific Research and Technology, ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9666516;Online learning,Cognitive learning style,Student behaviour,machine learning;Support vector machines,Learning systems,Deep learning,Neural networks,Linear regression,Education,Virtual environments;;;;;;28;;10-jan-22;;;IEEE;IEEE Conferences
Demystifying Black-box Learning Models of Rumor Detection from Social Media Posts;F. Tafannum, M. N. Sharear Shopnil, A. Salsabil, N. Ahmed, M. G. Rabiul Alam, M. Tanzim Reza;BRAC University,Department of Computer Science and Engineering,Dhaka,Bangladesh, BRAC University,Department of Computer Science and Engineering,Dhaka,Bangladesh, BRAC University,Department of Computer Science and Engineering,Dhaka,Bangladesh, BRAC University,Department of Computer Science and Engineering,Dhaka,Bangladesh, BRAC University,Department of Computer Science and Engineering,Dhaka,Bangladesh, BRAC University,Department of Computer Science and Engineering,Dhaka,Bangladesh;2021 IEEE 12th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON);10-jan-22;2021;;;358;364;Social media and its users are vulnerable to the spread of rumors, therefore, protecting users from the spread of rumors is extremely important. For this reason, we propose a novel approach for rumor detection in social media that consists of multiple robust models: XGBoost Classifier, Support Vector Machine, Random Forest Classifier, Extra Tree Classifier, Decision Tree Classifier, a hybrid model, deep learning models-LSTM and BERT. For evaluation, two datasets are used. These artificial intelligence algorithms are often referred to as Blackbox where data go in the box and predictions come out of the box but what is happening inside the box frequently remains cloudy. Although, there have been several works on detecting fake news, the number of works regarding rumor detection is still limited and the models used in the existing works do not explain their decision-making process. We take models with higher accuracy to illustrate which feature of the data contributes the most for a post to have been predicted as a rumor or a non-rumor by the models to explain the opaque process happening inside the black-box models. Our hybrid model achieves an accuracy of 93.22% and 82.49%, while LSTM provides 99.81%, 98.41% and BERT provides 99.62%, 94.80% accuracy scores on the COVID19 Fake News and the concatenation of Twitter15 and Twitter16 datasets respectively.;;978-1-6654-0690-1;10.1109/UEMCON53757.2021.9666567;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9666567;Rumor,Detection,Black-box,Machine Learning,Deep Learning,Explainable;Deep learning,Support vector machines,Machine learning algorithms,Social networking (online),Bit error rate,Predictive models,Prediction algorithms;;;;;;17;;10-jan-22;;;IEEE;IEEE Conferences
EEG-based System Using Deep Learning and Attention Mechanism for Driver Drowsiness Detection;M. Zhu, H. Li, J. Chen, M. Kamezaki, Z. Zhang, Z. Hua, S. Sugano;Southwest Jiaotong University,The School of Information Science and Technology,Chengdu,China,611756, Southwest Jiaotong University,The School of Information Science and Technology,Chengdu,China,611756, Southwest Jiaotong University,The School of Information Science and Technology,Chengdu,China,611756, Waseda University,The Research Institute for Science and Engineering (RISE),Tokyo,Japan,162-0044, Southwest Jiaotong University,The School of Mechanical Engineering,Chengdu,China,610031, Southwest Jiaotong University,The School of Electrical Engineering,Chengdu,China,610031, Waseda University,The Department of Modern Mechanical Engineering,Tokyo,Japan,169-8555;2021 IEEE Intelligent Vehicles Symposium Workshops (IV Workshops);10-jan-22;2021;;;280;286;The lack of sleep (typically <6 hours a night) or driving for a long time are the reasons of drowsiness driving and caused serious traffic accidents. With pandemic of the COVID-19, drivers are wearing masks to prevent infection from it, which makes visual-based drowsiness detection methods difficult. This paper presents an EEG-based driver drowsiness estimation method using deep learning and attention mechanism. First of all, an 8-channels EEG collection hat is used to acquire the EEG signals in the simulation scenario of drowsiness driving and normal driving. Then the EEG signals are pre-processed by using the linear filter and wavelet threshold denoising. Secondly, the neural network based on attention mechanism and deep residual network (ResNet) is trained to classify the EEG signals. Finally, an early warning module is designed to sound an alarm if the driver is judged as drowsy. The system was tested under simulated driving environment and the drowsiness detection accuracy of the test set was 93.35%. Drowsiness warning simulation also verified the effectiveness of proposed early warning module.;;978-1-6654-7921-9;10.1109/IVWorkshops54471.2021.9669234;National Natural Science Foundation of China, Waseda University, Research and Development, ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9669234;;Deep learning,Sleep,Conferences,Estimation,Brain modeling,Electroencephalography;;;;;;27;;10-jan-22;;;IEEE;IEEE Conferences
LSTM-Based Prediction of COVID-19 Vaccination Drive in India;A. Kannan, A. Jain, P. Nivas, R. Gajjar, M. I. Patel;Nirma University,Electronics and Communication Dept.,Ahmedabad,India, Nirma University,Electronics and Communication Dept.,Ahmedabad,India, SV National Institute of Technology,Electronics and Communication Dept.,Surat,India, Nirma University,Electronics and Communication Dept.,Ahmedabad,India, Nirma University,Electronics and Communication Dept.,Ahmedabad,India;2021 International Conference on Artificial Intelligence and Machine Vision (AIMV);10-jan-22;2021;;;1;5;The vaccination drive for the much dangerous and contagious Coronavirus (COVID-19) has started successfully in India. This paper proposes to predict the vaccination drive of COVID-19 using the time series data for India. The proposed model was used for predicting the number of people to be vaccinated once per day in the country. The proposed model was compared with the direct input-based Long Short Term Memory (LSTM) cell model using various performance parameters and the proposed model was found to perform better. The actual closeness of the model’s prediction from the actual data was depicted through line graphs. The proposed model was further used to predict the short-term and long-term future values. Herd immunity is another key ongoing research area when it comes to COVID-19. The Herd Immunity Threshold (HIT) of COVID-19 has not been found yet. However, this paper has proposed the expected number of days for different population thresholds. The proposed model predicts 174 days for obtaining a population threshold of 50% and 319 days for obtaining a population threshold of 90%.;;978-1-6654-4211-4;10.1109/AIMV53313.2021.9670953;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9670953;COVID-19 vaccination forecasting,Herd Immunity Threshold,Long Short Term Memory,Recurrent Neural Network,Time Series Forecasting;COVID-19,Pandemics,Machine vision,Sociology,Time series analysis,Predictive models,Vaccines;;;;;;17;;10-jan-22;;;IEEE;IEEE Conferences
Artificial Neural Networks in Export and Import Forecasting: An Analysis of Opportunities;M. R. Luchko, N. Dziubanovska, O. Arzamasova;West Ukrainian National University,Faculty of Finance and Accounting,Ternopil,Ukraine,46009, West Ukrainian National University,Faculty of Computer Information Technologies,Ternopil,Ukraine,46009, West Ukrainian National University,SSU Vocational College of Economics, Law and Information Technologies,Ternopil,Ukraine,46009;2021 11th IEEE International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications (IDAACS);5-jan-22;2021;2;;916;923;The paper concerns the issue of forecasting trends in trade relations between Malaysia and Ukraine using artificial neural networks. The current state of trade relations between the countries in the context of the COVID-19 pandemic has been analyzed. Considering the advantages and disadvantages of the types of neural networks built into the software product STATISTICA 10, MLP network has been chosen to build a predictive model of imports and exports of goods. The forecast values for the volumes of exports and imports of goods for the period from January 2021 to December 2022 have been calculated. Comparing the results, the researchers concluded that the artificial neural network is the most successful model for forecasting imports and exports. Suggestions for effective evaluation and forecasting of international trade indicators using the theory of time series and neural network technologies are given and the directions of further scientific research arising from this paper are formed.;2770-4254;978-1-6654-2605-3;10.1109/IDAACS53288.2021.9660856;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9660856;export,import,forecasting,neural network,Malaysia,Ukraine;COVID-19,International trade,Uncertainty,Pandemics,Time series analysis,Artificial neural networks,Predictive models;;;;;;24;;5-jan-22;;;IEEE;IEEE Conferences
Integrated Video Based Crowdedness Forecasting Framework with a Review of Crowd Counting Models;L. B. I. P. Thilakasiri, D. M. P. M. Alwis, R. T. Nanayakkara, G. M. R. I. Godaliyadda, M. P. B. Ekanayake, H. M. V. R. Herath, J. B. Ekanayake;University of Peradeniya,Faculty of Engineering,Department of Electrical and Electronic Engineering, University of Peradeniya,Faculty of Engineering,Department of Electrical and Electronic Engineering, University of Peradeniya,Faculty of Engineering,Department of Electrical and Electronic Engineering, University of Peradeniya,Faculty of Engineering,Department of Electrical and Electronic Engineering, University of Peradeniya,Faculty of Engineering,Department of Electrical and Electronic Engineering, University of Peradeniya,Faculty of Engineering,Department of Electrical and Electronic Engineering, University of Peradeniya,Faculty of Engineering,Department of Electrical and Electronic Engineering;2021 IEEE 16th International Conference on Industrial and Information Systems (ICIIS);3-jan-22;2021;;;29;34;Crowd counting and forecasting is an important problem amidst Covid 19 circumstances. A unified system to automate crowd monitoring, collect data about crowdedness and predict future crowds is presented in this paper. An evaluation of existing state-of-the-art crowd counting algorithms on a novel dataset is conducted in the first part of the paper, which demonstrates the shortcomings of these algorithms. Several novel algorithms, including a densely connected neural network, convolutional neural network, and a long short term memory based recurrent neural network, for predicting crowd counts in the near and distant future are presented afterwards in the second half of the paper.;2164-7011;978-1-6654-2637-4;10.1109/ICIIS53135.2021.9660701;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9660701;Crowd counting,Crowd population forecasting,Evaluation;Recurrent neural networks,Sociology,Predictive models,Prediction algorithms,Convolutional neural networks,Forecasting,Statistics;;;;;;29;;3-jan-22;;;IEEE;IEEE Conferences
PSO-Optimized CoVID-19 MLP-NARX Mortality Prediction Model;I. M. Yassin, A. Zabidi, M. S. A. M. Ali, R. Baharom;Universiti Teknologi Mara (UiTM),Microwave Research Institute (MRI),Shah Alam,Malaysia, Universiti Malaysia Pahang (UMP),Faculty of Computer Systems and Software Engineering,Malaysia, Universiti Teknologi Mara (UiTM),Microwave Research Institute (MRI),Shah Alam,Malaysia, Universiti Teknologi Mara (UiTM),College of Engineering,Shah Alam,Malaysia;2021 IEEE Industrial Electronics and Applications Conference (IEACon);30-dec-21;2021;;;308;312;Mortality prediction models localized for Malaysia is limited, warranting a research gap to study further. A predictive model for CoVID-19 mortality prediction is presented in this paper. The model utilized the MLP-NARX structure. Parameters for the model were optimized using PSO. Prediction results yielded average MSE value of <tex>8.1141\times 10\times ^{-7}</tex> with acceptable validation results.;;978-1-7281-9253-6;10.1109/IEACon51066.2021.9654684;Universiti Teknologi Mara, ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9654684;Nonlinear Auto-Regressive with Exogeneous Inputs (NARX),Particle Swarm Optimization (PSO),Multi-Layer Perceptron (MLP),CoVID-19;COVID-19,Industrial electronics,Conferences,Predictive models,Particle swarm optimization;;;;;;9;;30-dec-21;;;IEEE;IEEE Conferences
Application of Artificial Neural Network (ANN) and Support Vector Machine (SVM) for Government Policy Recommendations to Allow People to Do Activities Without Masks;D. J. Cross Sihombing, D. Christine Othernima, A. Kieputra, T. H. Artpinkkan;Atma Jaya Catholic University of Indonesia,Information System, Faculty of Engineering,Jakarta, Atma Jaya Catholic University of Indonesia,Information System, Faculty of Engineering,Jakarta, Atma Jaya Catholic University of Indonesia,Information System, Faculty of Engineering,Jakarta, Atma Jaya Catholic University of Indonesia,Information System, Faculty of Engineering,Jakarta;2021 IEEE 5th International Conference on Information Technology, Information Systems and Electrical Engineering (ICITISEE);30-dec-21;2021;;;197;201;The Covid-19 pandemic that has hit the world, including Indonesia, has affected various aspects of life. This has also led to various new policies by the Indonesian government to limit the spread of Covid-19, one of which is the use of masks while on the move. This study aims to apply machine learning to government policy recommendations in allowing people to move without masks. The method used in this research is SVM (Support Vector Machine) for classification and ANN (Artificial Neural Network) for forecasting. The results of this study are MSE (Mean Squared Error) of 4.62 and MAE (Mean Absolute Error) of 0.97, and this study predicts the Covid-19 pandemic will decrease in February 2022 but will tend to rise again in March 2022. Next, in April 2022, cases will decrease. Based on the study results, the implementation of the policy can be carried out in April 2022 regarding community activities without masks.;;978-1-6654-0196-8;10.1109/ICITISEE53823.2021.9655965;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9655965;ANN,SVM,Forecasting,Covid-19;COVID-19,Support vector machines,Government policies,Pandemics,Artificial neural networks,Machine learning,Licenses;;;;;;16;;30-dec-21;;;IEEE;IEEE Conferences
The Study of Multivariable Autoregression Methods to Forecast Infectious Diseases;M. A. R. Azhar, H. Adi Nugroho, S. Wibirama;Universitas Gadjah Mada,Faculty of Engineering,Department of Electrical and Information Engineering,Yogyakarta,Indonesia, Universitas Gadjah Mada,Faculty of Engineering,Department of Electrical and Information Engineering,Yogyakarta,Indonesia, Universitas Gadjah Mada,Faculty of Engineering,Department of Electrical and Information Engineering,Yogyakarta,Indonesia;2021 IEEE 5th International Conference on Information Technology, Information Systems and Electrical Engineering (ICITISEE);30-dec-21;2021;;;83;88;Infectious diseases can have an enormous impact on the public because they negatively affect not only mortality but also unemployment and other social impacts. It is crucial to anticipate additional resources to counter infectious diseases mathematical and statistical tools that can be used to generate forecasts of reported cases. In this paper, the multivariable autoregression methods were compared for forecasting infectious diseases. We discuss the methods and use them to forecast infectious diseases. In this case, we used several COVID-19 cases as the object of forecasting. We used three prediction methods as Vector Autoregression (VAR), Vector Autoregression Moving Average (VARMA), and Autoregression Moving Average with exogenous variable (VARMA-X). The results show that the models have different results, among three methods, VAR give the best result of forecasting daily covid case for both stationary and non-stationary data. While VARMA-X shows the lowest performance for forecasting the dataset. We suggest by combining the AR model with the ANN model can provide a better result for forecasting.;;978-1-6654-0196-8;10.1109/ICITISEE53823.2021.9655881;Universitas Gadjah Mada, ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9655881;Forecasting,Autoregression,Multivariable;COVID-19,Reactive power,Infectious diseases,Artificial neural networks,Predictive models,Data models,Forecasting;;;;;;26;;30-dec-21;;;IEEE;IEEE Conferences
Convolutional Neural Network Classification for Machine Tool Wear Based on Unsupervised Gaussian Mixture Model;V. A. Arias, J. Vargas-Machuca, F. C. Zegarra, A. M. Coronado;Laboratorio de Sistemas Inteligentes, EPIME, Universidad Nacional Tecnológica de Lima Sur (UNTELS),Lima,Peru, Laboratorio de Sistemas Inteligentes, EPIME, Universidad Nacional Tecnológica de Lima Sur (UNTELS),Lima,Peru, Laboratorio de Sistemas Inteligentes, EPIME, Universidad Nacional Tecnológica de Lima Sur (UNTELS),Lima,Peru, Laboratorio de Sistemas Inteligentes, EPIME, Universidad Nacional Tecnológica de Lima Sur (UNTELS),Lima,Peru;2021 IEEE Sciences and Humanities International Research Conference (SHIRCON);29-dec-21;2021;;;1;4;In today's manufacturing industry it is of great importance to know the condition of a tool as it wears out. This knowledge allows us to reduce possible errors and failures in the manufacturing process. This work focuses on classifying the level of wear of a machine tool, allowing us to know its current state using measurements of forces and accelerations. First, tool wear levels are obtained by unsupervised learning (through the Gaussian mixture model). Then a convolutional neural network trained directly using the measured time series predicts the level of tool wear. After careful selection of the optimal window length, optimization algorithm, and number of epochs, wear levels were predicted with accuracy greater than 85%.;;978-1-6654-2914-6;10.1109/SHIRCON53068.2021.9652266;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9652266;unsupervised learning,machine tool,Gaussian mixture,Convolutional neural networks,time series;Manufacturing processes,Current measurement,Time series analysis,Prediction algorithms,Time measurement,Machine tools,Convolutional neural networks;;;;;;15;;29-dec-21;;;IEEE;IEEE Conferences
Feature-Weighted Stacking for Nonseasonal Time Series Forecasts: A Case Study of the COVID-19 Epidemic Curves;P. Cawood, T. L. van Zyl;University of the Witwatersrand,Computer Science and Applied Maths,Johannesburg,South Africa, University of Johannesburg,Institute for Intelligent Systems,Johannesburg,South Africa;2021 8th International Conference on Soft Computing & Machine Intelligence (ISCMI);29-dec-21;2021;;;53;59;We investigate ensembling techniques in forecasting and examine their potential for use in nonseasonal time-series similar to those in the early days of the COVID-19 pandemic. Developing improved forecast methods is essential as they provide data-driven decisions to organisations and decision-makers during critical phases. We propose using late data fusion, using a stacked ensemble of two forecasting models and two meta-features that prove their predictive power during a preliminary forecasting stage. The final ensembles include a Prophet and long short term memory (LSTM) neural network as base models. The base models are combined by a multilayer perceptron (MLP), taking into account meta-features that indicate the highest correlation with each base model’s forecast accuracy. We further show that the inclusion of meta-features generally improves the ensemble’s forecast accuracy across two forecast horizons of seven and fourteen days. This research reinforces previous work and demonstrates the value of combining traditional statistical models with deep learning models to produce more accurate forecast models for time-series from different domains and seasonality.;2640-0146;978-1-7281-8683-2;10.1109/ISCMI53840.2021.9654809;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9654809;COVID-19,Forecasting,Machine learning,Neural-networks,Ensemble,Stacking,Meta-learning,Time-series;COVID-19,Correlation,Pandemics,Stacking,Neural networks,Time series analysis,Predictive models;;;;;;25;;29-dec-21;;;IEEE;IEEE Conferences
Prediction Model for the Tenant's Potential Failure from Business Incubation Process during COVID-19 Period Using Supervised Learning;I. G. B. A. Budaya, G. I. R. Martha, D. P. Agustino, I. M. P. P. Wijaya, I. G. Harsemadi;Institute of Technology and Business, STIKOM Bali,Departement of Information System,Denpasar,Indonesia, Institute of Technology and Business, STIKOM Bali,Departement of Information System,Denpasar,Indonesia, Institute of Technology and Business, STIKOM Bali,Departement of Information System,Denpasar,Indonesia, Institute of Technology and Business, STIKOM Bali,Departement of Information System,Denpasar,Indonesia, Institute of Technology and Business, STIKOM Bali,Departement of Information System,Denpasar,Indonesia;2021 3rd International Conference on Cybernetics and Intelligent System (ICORIS);28-dec-21;2021;;;1;5;The COVID-19 has brought the world to a new economic crisis. Hence, it creates a disruption that causes the shutdown of many businesses. Business Incubator is also responsible for their tenant business sustainability, especially during this pandemic period. Analyzing the incubation parameter process can be the initial study to collect the relevant information to determine how each tenant is successful. Using the information, building the prediction model in the classification problem for the potential failure of the tenant can be initiated. The works involve the data mining analysis for 207 tenant's track record data from 6 university business incubators in Bali Province, Indonesia. The selected data as the features are the intensity of tenants joining the mentoring program, the level of financial literacy, and the amount of capital or saving. The prediction applies cost-sensitive classifiers combined with machine learning algorithms in WEKA. Based on the model analysis from the precision, recall, F-Measure, and AUC-ROC, the Random Forest model has the highest accuracy, followed by KNN, SVM, MLP, and Naïve Bayes as the lowest. The AUC-ROC from the algorithms models sequentially: (1) 0.934, (2) 0.930, (3) 0.890, (4) 0.859, and (5) 0.846. The features are too few to generalize if they can be used to build a robust supervised learning model to predict the potential failure of the tenant incubation process, but at least based on the observation, the three features have a direct implication. University Business Incubator can consider the three features as the primary points to give their main attention.;;978-1-6654-2580-3;10.1109/ICORIS52787.2021.9649505;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9649505;prediction,supervised learning,covid-19,business incubation,tenants;Support vector machines,Machine learning algorithms,Pandemics,Supervised learning,Predictive models,Prediction algorithms,Classification algorithms;;;;;;19;;28-dec-21;;;IEEE;IEEE Conferences
Investigation of recurrent networks LSTM in the problem of Covid-19 forecasting;Y. Zaychenko, H. Zaichenko, G. Hamidov;Igor Sikorsky Kyiv Polytechnic Institute,Kyiv,Ukraine, Igor Sikorsky Kyiv Polytechnic Institute,Kyiv,Ukraine, Azershiq,Information Technologies Department,Baku,Azerbaijan;2021 IEEE 16th International Conference on Computer Sciences and Information Technologies (CSIT);27-dec-21;2021;1;;9;12;in this paper problem of Covid-19 forecasting was considered and investigated. Review of different models and methods of pandemic forecasting are presented. For middle term forecasting indicators of Covid-19 the application of LSTM networks is suggested. The experimental investigations were carried out during which the optimal parameters LSTM network were found: sliding window size, forecasting interval and network architecture. The efficiency of LSTM in Covid-19 forecasting was estimated.;2766-3639;978-1-6654-4257-2;10.1109/CSIT52700.2021.9648696;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9648696;covid 19 forecasting,LSTM networks,parameters and architecture optimization;COVID-19,Analytical models,Pandemics,Computational modeling,Neural networks,Computer architecture,Predictive models;;;;;;18;;27-dec-21;;;IEEE;IEEE Conferences
Novel Nonparametric Test for Comparing Machine Learning Models for COVID-19 Outbreak Prediction;D. Klyushin, K. Golubeva;Taras Shevchenko National University of Kyiv,Department of Computer Science and Cybernetics,Kyiv,Ukraine, Taras Shevchenko National University of Kyiv,Department of Computer Science and Cybernetics,Kyiv,Ukraine;2021 IEEE 16th International Conference on Computer Sciences and Information Technologies (CSIT);27-dec-21;2021;1;;1;4;Machine learning process involves comparing classifiers in order to select the most accurate model. For this, n-fold cross-validation methods and statistical error estimates are commonly used. However, a naive comparison of such estimates is incorrect, since they are random variables. The correct approach is to test the hypothesis that one of the estimates is statistically significantly greater. For this, tests of statistical significance are used, provided that the errors obey the same distribution. If the test statistic exceeds the specified threshold, the hypothesis that the distributions are identical is rejected. The paper describes a nonparametric test for testing the hypothesis about the identity of distributions, which has high sensitivity and specificity for absolutely continuous distributions. Unlike classical methods, for example, the Mann-Whitney-Wilcoxon test, the proposed test works equally well with non-overlapping samples and with strongly overlapping samples. The paper compares seven machine learning models used to predict the COVID-19 epidemic curve in five countries (China, Germany, Italy, Iran, and USA): five variants of the Gray Wolf Optimizer (GOW), multilayer perceptron (MLP), and adaptive network fuzzy inference (ANFIS). The obtained results of comparing models for predicting epidemic curves prove the high power of the proposed test.;2766-3639;978-1-6654-4257-2;10.1109/CSIT52700.2021.9648801;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9648801;Machine Learning,Nonparametric Statistics,Nonparametric Significance Test,Time Series,Forecasting,COVID-19;COVID-19,Ranking (statistics),Adaptation models,Epidemics,Time series analysis,Machine learning,Predictive models;;;;;;27;;27-dec-21;;;IEEE;IEEE Conferences
Disturbance Storm Time Index Prediction using Long Short-Term Memory Machine Learning;Wihayati, H. D. Purnomo, S. Trihandaru;Satya Wacana Christian University,Doctoral Prog. of Information Technology,Salatiga,Central Java,Indonesia, Satya Wacana Christian University,Doctoral Prog. of Information Technology,Salatiga,Central Java,Indonesia, Satya Wacana Christian University,Science and Mathematics Dept.,Salatiga,Central Java,Indonesia;2021 4th International Conference of Computer and Informatics Engineering (IC2IE);27-dec-21;2021;;;311;316;The cosmic matter that has the most influence on space weather on earth is greatly influenced by solar activity. Abnormal solar activity often affects the intensity of the solar wind into space, which is known as the geomagnetic storm phenomenon. One of the impacts caused by this phenomenon is the disruption of the satellite navigation system. In determining solar activity that affects the earth, observing the CME (Coronal Mass Eject) and flares continuously is necessary. One of the references for measuring the level of geomagnetic storms is the disturbance storm time index (Dst-index). This paper predicts the Dst-index based on data from the OMNI web obtained from NASA’s Advanced Composition Explorer (ACE) satellite. This paper aims to predict the disturbance storm time index using long short-term memory (LSTM). The results of the LSTM model were then evaluated using the root mean square error (RMSE) from the training results and testing results for comparative analyses of data with prediction to determine the error level. The best LSTM model for the Dst-index prediction shows the RMSEs are around the value of 3 for the training and testing.;;978-1-6654-4288-6;10.1109/IC2IE53219.2021.9649119;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9649119;disturbance storm time,LSTM,solar wind,RMSE,prediction;Training,Earth,Wind,Satellites,Storms,Predictive models,Data models;;;;;;33;;27-dec-21;;;IEEE;IEEE Conferences
Time Series Analysis of Infected COVID-19 Cases in the Zamboanga Peninsula, Philippines using Long Short-Term Memory Neural Networks;U. B. Patayon;Jose Rizal Memorial State University,Zamboanga del Norte,Philippines;2021 4th International Conference of Computer and Informatics Engineering (IC2IE);27-dec-21;2021;;;106;111;Infectious disease outbreaks, such as COVID-19 pandemics, exhibit patterns that can be described by the dynamics of a mathematical model This study seeks to explore the use of LSTM in order to develop models that will capture the non-linear dynamic changes of COVID-19 cases in Zamboanga Peninsula. The study uses 436 data points where the latest timestamp for the dataset is on May 29, 2021 and the oldest is on March 20, 2020. These data are taken from the DOH repositories and revalidated using the data from the DOH Regional Office. The training and testing phase results show that among the different LSTM variants, convLSTM trained using Adam and RMSProp attained the smallest RMSE result of 42.34 and 43.67 and a correlation coefficient of 0.94 0.93, respectively. ConvLSTM, when trained with Adam and RMSProp, produces the best results, as evidenced by the shortest RMSE and highest correlation coefficient. Results revealed that convLSTM appears to be a viable choice for modeling the time series of the COVID 19 infected cases in Zamboanga Peninsula Region in compared with the different variants of LSTM.;;978-1-6654-4288-6;10.1109/IC2IE53219.2021.9649041;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9649041;COVID-19,forecasting,LSTM,machine learning,philippines;COVID-19,Correlation coefficient,Training,Pandemics,Infectious diseases,Time series analysis,Neural networks;;;;;;28;;27-dec-21;;;IEEE;IEEE Conferences
Analysis of Neural Network and Statistical Models Used for Forecasting of a Disease Infection Cases;M. S. A. Abotaleb, T. Makarovskikh;South Ural State University,Dept. of System Programming,Chelyabinsk,Rusia, South Ural State University,Dept. of System Programming,Chelyabinsk,Rusia;2021 International Conference on Information Technology and Nanotechnology (ITNT);24-dec-21;2021;;;1;7;More than a year has passed since the coronavirus 2 (SARS-CoV2) pandemic began, and no one has been able to forecast the infection cases of the disease with high accuracy. Nowadays, a lot of studies are devoted to finding out the pattern of infection spreading and forecasting cases of infection. But models used in those studies have large errors in forecasts, and this makes it more challenging to discover the pattern of infection spreading. The choice of appropriate models may vary from country to country. The increase of the number of infection cases is one of the global challenges nowadays not only for virusologists and medicians, but also for data analytics. In our paper, we analyze errors in the forecast in the list of the top 10 countries affected by disease on January 1, 2021 using the following the neural network models, linear and non-linear classical statistical models, and also classical epidemiological SIR model. The other part of our computational experiment is devoted to forecasting the dates of the peak values of time series. It is shown on time series for the regions most affected by pandemics that neural network models allow to forecast this date with high accuracy. We also discover the possible field of application of such algorithms in other fields.;;978-1-6654-3217-7;10.1109/ITNT52450.2021.9649126;Ministry of Science and Higher Education of the Russian Federation, ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9649126;Epidemic,Machine learning,Neural network,LSTM,BiLSTM,GRU,ARIMA,BATS,TBATS,Holt linear trend,SIR model,Nonlinear models;COVID-19,Analytical models,Pandemics,Computational modeling,Time series analysis,Neural networks,Machine learning;;;;;;20;;24-dec-21;;;IEEE;IEEE Conferences
COVID-19 Vaccination Prediction in India Using Deep Learning;N. R. Umrani, S. G. R, S. Audichya, A. Rai, A. Kodipalli, R. Joy Martis;Computer Science and Engineering Global Academy Of Technology,Bengaluru,India, Computer Science and Engineering Global Academy Of Technology,Bengaluru,India, Computer Science and Engineering Global Academy Of Technology,Bengaluru,India, Computer Science and Engineering Global Academy Of Technology,Bengaluru,India, Computer Science and Engineering Global Academy Of Technology,Bengaluru,India, Computer Science and Engineering Global Academy Of Technology,Bengaluru,India;2021 IEEE 9th Region 10 Humanitarian Technology Conference (R10-HTC);22-dec-21;2021;;;1;6;The worldwide spread of COVID-19, an infectious disease caused by SARS-CoV-2, has ravaged the medical, social, financial and political institutions across the globe. Vaccines are in great need to prevent the spread of this disease in the absence of an effective medical treatment. A vaccine stimulates immune system without causing illness. This simple and powerful method will help to avoid many dangerous infectious diseases. This study proposes deep learning-based models for analyzing a set of data across India and performing short-term forecasting on the total number of people vaccinated for COVID-19 over a 10-day period in all states and union territories. In this study, epidemiological data from 16<sup>th</sup> January 2021 to 20<sup>th</sup> March 2021 were used to make predictions. On the basis of Mean Absolute Percentage Error (MAPE), the average error obtained from various proposed Long Short-Term Memory (LSTM) models is less than 3.9%. The findings will assist researchers, policymakers and COVID-19 warriors across the country in establishing appropriate medical facilities and taking required preventive measures.;2572-7621;978-1-6654-3240-5;10.1109/R10-HTC53172.2021.9641703;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9641703;COVID-19 vaccine,Deep learning,Long Short-Term Memory model,Mean Absolute Percentage Error,Prediction;COVID-19,Analytical models,Infectious diseases,Pandemics,Biological system modeling,Memory management,Predictive models;;;;;;20;;22-dec-21;;;IEEE;IEEE Conferences
Table of Contents;;;2021 IEEE 9th Region 10 Humanitarian Technology Conference (R10-HTC);22-dec-21;2021;;;1;3;Table of Contents;2572-7621;978-1-6654-3240-5;10.1109/R10-HTC53172.2021.9641716;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9641716;;COVID-19,Predictive models,Deep learning,Brain modeling,Analytical models,Solid modeling,Data models;;;;;;22-dec-21;;;IEEE;IEEE Conferences;;
Experiment on Deep Learning Models for COVID-19 Detection from Blood Testing;F. Bismadhika, N. N. Qomariyah, A. A. Purwita;Bina Nusantara University,Faculty of Computing and Media,Computer Science Department,Jakarta,Indonesia,11480, Bina Nusantara University,Faculty of Computing and Media,Computer Science Department,Jakarta,Indonesia,11480, Bina Nusantara University,Faculty of Computing and Media,Computer Science Department,Jakarta,Indonesia,11480;2021 IEEE International Biomedical Instrumentation and Technology Conference (IBITeC);22-dec-21;2021;;;136;141;Due to the equipment and expert shortages in diagnosing COVID-19 disease, detecting an individual infected with Coronavirus using hematochemical data could provide a cheaper and faster alternative. The quicker and less expensive alternative could be realized by utilizing deep learning to classify Coronavirus infection using complete blood count test results. Two architectures are developed and implemented in this study, which is custom-built DNN (Deep Neural Network) and TabNet. Also, three datasets from the hospitals in Italy, Brazil, and Indonesia are used for training the models. The deep learning models trained with the datasets from San Raphael Hospital in Italy, Albert Einstein Hospital in Brazil, and Pasar Minggu Hospital in Indonesia obtained average AUC scores of 0.87, 0.90, and 0.88, respectively. Based on the results obtained, this method of diagnosis could serve as an alternative in developing countries to diagnose COVID-19 disease without costly RT-PCR equipment and the expert to operate it.;;978-1-6654-4179-7;10.1109/IBITeC53045.2021.9649254;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9649254;Artificial Intelligence,COVID-19,Coronavirus,Complete blood count (CBC) test,Classifier,Deep Learning,Neural Network;COVID-19,Deep learning,Training,Hospitals,Developing countries,Predictive models,Blood;;;;;;18;;22-dec-21;;;IEEE;IEEE Conferences
An Improved Technique for Diabeties Prediction By Combining Feature Selection Techniques And BFGS Optimization Algorithm With Weight Constrained Neural Network;S. Parveen, P. Patre, J. Minj;VEC,Department of CS and Engg,Lakhanpur,C.G,India, VEC,Department of CS and Engg,Lakhanpur,C.G,India, VEC,Department of CS and Engg,Lakhanpur,C.G,India;2021 International Conference on Smart Generation Computing, Communication and Networking (SMART GENCON);21-dec-21;2021;;;1;4;Diabetes is among basic illnesses and bunches of individuals are experiencing this infection. Age, weight, absence of activity, genetic diabetes, living style, awful eating routine, hypertension, and so forth can cause Diabetes. Individuals having diabetes have high danger of sicknesses like coronary illness, kidney infection, stroke, eye issue, nerve harm, and so forth. Current practice in medical clinic is to gather required data for diabetes determination through different tests and suitable therapy is given dependent on conclusion. Information science techniques can possibly profit other logical fields by revealing new insight into regular enquiries. Both engineered and true investigations show that ANN strategy is best, more dependable and seriously powerful with respect to differed bunch sizes, shapes and densities. However, in the event that a portion of the loads have huge qualities, they overwhelm and in some cases decide the neural organization's yield, thusly, corrupting the grouping proficiency of the organization along these lines current work is centered around the execution of a Weight Constrained Neural Network Training Algorithm for productive forecast of diabetes utilizing Limited-memory BFGS (L-BFGS or LMBFGS) as an advancement calculation. The strategy is exceptionally proficient when weight esteems are enormous and has been appeared to adequately make forecast if diabetes.;;978-1-6654-2503-2;10.1109/SMARTGENCON51891.2021.9645892;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9645892;Genetic Algorithms,Artificial Neural Network,Weight Constrained Neural Network,Limited-memory BFGS (L-BFGS or LM-BFGS);Training,Information science,Shape,Neural networks,Medical treatment,Organizations,Prediction algorithms;;;;;;16;;21-dec-21;;;IEEE;IEEE Conferences
Predicting the number of new cases of COVID-19 in India using Survival Analysis and LSTM;A. S, R. F. Johnson, R. k. N, M. T R, V. V;G.Pulla Reddy Engineering College,Department of Computer Science and Engineering,Kurnool,India, CMR Institute of Technology,Department of Computer Science and Engineering,Bangalore,India, Jain (Deemed-to-be University),Department of Computer Science and Engineering,Bangalore,India, Jain (Deemed-to-be University),Department of Computer Science and Engineering,Bangalore,India, Jain (Deemed-to-be University),Department of Computer Science and Engineering,Bangalore,India;2021 Fifth International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC);20-dec-21;2021;;;1;4;COVID-19 has been the cause of death for thousands of people across the globe. The goal of this paper is to forecast the new COVID-19 cases in India. The other methods used to forecast COVID-19 cases fail to give results with good accuracy when they try to predict the new cases number for a long time period or when the count of daily cases reported is large since the population of a country is large. The proposed study overcomes the challenge by firstly customizing the dataset. Second, the survival analysis has been utilized to choose appropriate factors, and third, the data will be integrated into the Long Short-Term Memory Network (LSTM). With a mean absolute percentage error of 5.79 percent, data from the 30th of January, 2020, to the 16th of June, 2021, was used to determine the new cases number of every day for the next 21 days.;2768-0673;978-1-6654-2642-8;10.1109/I-SMAC52330.2021.9640899;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9640899;Covid-19,forecasting,India,Survival analysis,LSTM;COVID-19,Analytical models,Sociology,Predictive models,Data models,Forecasting,Statistics;;;;;;13;;20-dec-21;;;IEEE;IEEE Conferences
COVID-19 Future Forecasting Tool: Infected Patients Recovery and Hospitalization Trends Using Deep Learning Models;N. Tasnia, S. Mahmud, M. F. Mridha;Jahangirnagar University,Applied statistics and Data science,Dhaka,Bangladesh, United International University,Computer Science and Engineering,Dhaka,Bangladesh, Bangladesh University of Business and Technology,Computer Science and Engineering,Dhaka,Bangladesh;2021 International Conference on Science & Contemporary Technologies (ICSCT);20-dec-21;2021;;;1;6;This paper presents a deep learning-based prediction system tool for COVID-19 patients using ARIMA, LSTM, and prophet hybrid algorithms. COVID-19 pandemic poses a significant impact all over the world. However, when we get infected, we do not understand where we should go, whether we need to be hospitalized, which doctor we should consult, and how much it would cost. This work explores how to solve those problems using API technology and deep learning to help moderate those who endure COVID-19. Using this tool, the user will find a better hospital for their patient, and the tool will predict the hospital based on patient budget, location, recovery time. Overall, by analyzing the patient’s data like age, gender, oxygen saturation level, tools will give suggestions. We collected 250 data as a testing data scenario and acquired the training data set from John Hopkins University, which is available on public platforms. So this proposed work has cooperated with the API and deep learning model, this tool contains ARIMA, LSTM, and Prophet hybrid model. API will update the new cases of coronavirus, recovery rate, and death rate. Finally, the proposed tool will predict a better solution base on those API data.;;978-1-6654-2132-4;10.1109/ICSCT53883.2021.9642691;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9642691;COVID-19 pandemic,Machine Learning,API,ARIMA,LSTM and Prophet Algorithm;COVID-19,Deep learning,Hospitals,Pandemics,Training data,Predictive models,Prediction algorithms;;;;;;14;;20-dec-21;;;IEEE;IEEE Conferences
Covid-19 and its impact on school closures: a predictive analysis using machine learning algorithms;F. Faisal, M. M. Nishat, M. A. Mahbub, M. M. I. Shawon, M. M. -U. -H. Alvi;Islamic University of Technology,Department of Electrical and Electronic Engineering,Dhaka,Bangladesh, Islamic University of Technology,Department of Electrical and Electronic Engineering,Dhaka,Bangladesh, Islamic University of Technology,Department of Electrical and Electronic Engineering,Dhaka,Bangladesh, Islamic University of Technology,Department of Electrical and Electronic Engineering,Dhaka,Bangladesh, Islamic University of Technology,Department of Electrical and Electronic Engineering,Dhaka,Bangladesh;2021 International Conference on Science & Contemporary Technologies (ICSCT);20-dec-21;2021;;;1;6;This research presents an extensive point of reference for investigating the operation of several machine learning (ML) algorithms in postulating the multiclass classification problem regarding the forthcoming effects of Covid-19 on school closures. With the prompt closure of schools across the world in response to this pandemic, school-going children and teenagers are ruptured both mentally and physically. Hence, ML has come across to be a reliable component to forecast the scenario effectively. A dataset from UNESCO is trained and tested by ten supervised ML algorithms. A comprehensive analysis among the predictive ML models was executed which bought satisfactory results with regard to accuracy, precision, sensitivity, F1 score, ROC-AUC by hyper parameter optimization. In this regard, grid search cross validation (GridSearchCV) was utilized in order to obtain the optimal parameters. However, the performance of Artificial Neural Network (ANN) was also investigated and compared with the supervised ML models where ANN displayed maximum accuracy of 80.37%. After rigorous comparative analysis, Decision Tree (DT) portrayed the highest accuracy of 90.75%. Hence, it is evident that machine learning algorithm holds strong promise in forecasting the upcoming scenario of school closures due to Covid-19 and can contribute significantly in decision making for the welfare of the education system.;;978-1-6654-2132-4;10.1109/ICSCT53883.2021.9642617;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9642617;ML Algorithms,Multiclass Classification,Covid-19,School Closure,Accuracy;COVID-19,Machine learning algorithms,Sensitivity,Education,Artificial neural networks,Predictive models,Classification algorithms;;;;3;;31;;20-dec-21;;;IEEE;IEEE Conferences
Machine Learning Based Prediction and Forecasting of Electricity Price During COVID-19;K. Arya, K. R. M. Vijaya Chandrakala;Amrita Vishwa Vidyapeetham,Amrita School of Engineering, Coimbatore,Department of Electrical and Electronics Engineering,India, Amrita Vishwa Vidyapeetham,Amrita School of Engineering, Coimbatore,Department of Electrical and Electronics Engineering,India;2021 IEEE International Power and Renewable Energy Conference (IPRECON);16-dec-21;2021;;;1;6;During COVID-19 impact especially on energy markets, reliable electricity pricing has now become unpredictable and it becomes a challenging task to get prepared for the future price forecasting. The pandemic has mostly affected energy markets and efficient operation of the restructured electricity market effectively all over the world. In this work, the analysis of electricity price and forecasting is carried out on the wholesale market of United States namely MISO electricity market. Due to uncertainty of demand occurring during the pandemic period, the market price data is analyzed. And, using statistical learning and deep learning method day ahead price is forecasted which would prepare the electricity market to operate in an efficient manner to face such pandemics in the future. In this study, three methods are proposed namely Auto Regressive Integrated Moving Average (ARIMA), decision-tree-based ensemble Machine Learning algorithm namely Extreme Gradient Boosting (XGboost) and Recurrent Neural Network (RNN) for forecasting the electricity price. Depending upon the electricity price data attributes, the electricity price of MISO electricity market is predicted and forecasted. The performance of the methods to predict and forecast the electricity price is compared based on the processing speed and error.;;978-1-6654-0137-1;10.1109/IPRECON52453.2021.9640701;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9640701;Electricity market,Price,Price forecasting,Machine Learning Methods;COVID-19,Deep learning,Temperature distribution,Recurrent neural networks,Uncertainty,Pandemics,Predictive models;;;;;;27;;16-dec-21;;;IEEE;IEEE Conferences
Forecasting the potential influence of Covid-19 using Data Science and Analytics;M. Murale, N. Devi, A. G. Gokul, P. Leela Rani, N. V. S;Sri Venkateswara College of Engineering,Department of Information Technology,Sriperumbudur,India, Sri Venkateswara College of Engineering,Department of Information Technology,Sriperumbudur,India, Sri Venkateswara College of Engineering,Department of Information Technology,Sriperumbudur,India, Sri Venkateswara College of Engineering,Department of Information Technology,Sriperumbudur,India, Sri Venkateswara College of Engineering,Department of Information Technology,Sriperumbudur,India;2021 International Conference on Innovative Computing, Intelligent Communication and Smart Electrical Systems (ICSES);16-dec-21;2021;;;1;5;The major purpose of the study topic is to use data science to anticipate the future effect of COVID-19 using existing data. The goal of this research is to use data science and analytics to generate precise forecasts of the number of substantiations and deaths. LSTM, GRUs, and Prophet are the major models created and tested for the solution. An LSTM model is a type of Recurrent Neural Network that is used to forecast datasets with increasingly changing patterns. Gated recurrent units only has two gateways: reboot and update. The prophet is best suited for forecasting assignments involving observation swith at least a year of history. The various models discussed above were used to the covid-19 data set to forecast the number of positive cases, active cases, and deaths associated with covid-19. We trained the model using data from April and May 2021 to demonstrate a comparison between the observed and expected number of positive events. To assume the future happing of COVID-19 by applying models which are in use, so that we will be able to calculate the impact of the disease's potential spread throughout the human being, preparing our selves to make proper planning and idea to prevent further transmission and equip health systems to manage the disease properly and battle the worldwide pandemic.;;978-1-6654-3521-5;10.1109/ICSES52305.2021.9633787;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9633787;Deep Learning,Mel frequency cepstral coefficients,Speech separation,Speech recognition;COVID-19,Recurrent neural networks,Pandemics,Predictive models,Data science,Logic gates,Data models;;;;;;7;;16-dec-21;;;IEEE;IEEE Conferences
Using Machine Learning Techniques to Predict RT- PCR Results for COVID-19 Patients;B. Durden, M. Shulman, A. Reynolds, T. Phillips, D. Moore, I. Andrews, S. Pouriyeh;Kennesaw State University,Department of Information Technology,Marietta,GA,USA, Kennesaw State University,Department of Information Technology,Marietta,GA,USA, Kennesaw State University,Department of Information Technology,Marietta,GA,USA, Kennesaw State University,Department of Information Technology,Marietta,GA,USA, Kennesaw State University,Department of Information Technology,Marietta,GA,USA, Kennesaw State University,Department of Information Technology,Marietta,GA,USA, Kennesaw State University,Department of Information Technology,Marietta,GA,USA;2021 IEEE Symposium on Computers and Communications (ISCC);15-dec-21;2021;;;1;4;This paper aims to explore the role of Machine Learning (ML) techniques in combating COVID-19. In this study, different ML techniques and data portioning methods will be used to predict RT-PCR results from ER-admitted patients. The data set contains 199 instances with 81 attributes. 5-Fold Cross Validation, 10-Fold Cross Validation, and 80% Training are the different data portioning methods utilized for this research. Decision tree (J48), Random Forest (RaF), and Rotation Forest (RoF), Multi-Layer Perceptron (MLP), Naïve Bayes (NB), K-Nearest Neighbors (kNN), Logistic Regression (LR), LogitBoost (LB), and Sequential Minimal Optimization (SMO) are the main classifiers we explore in this study. The results of our experiments indicate that Rotation Forest gives a highest accuracy of 90% on the data set.;2642-7389;978-1-6654-2744-9;10.1109/ISCC53001.2021.9631418;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9631418;Covid-19,Machine Learning,SARS-Cov-2;COVID-19,Training,Classification tree analysis,Regression tree analysis,Random forests;;;;;;9;;15-dec-21;;;IEEE;IEEE Conferences
Epidemiological forecasting of COVID-19 infection using deep learning approach;A. Blagojević, T. Šušteršič, N. Filipović;University of Kragujevac,Faculty of Engineering,Kragujevac,Serbia, University of Kragujevac,Faculty of Engineering,Kragujevac,Serbia, University of Kragujevac,Faculty of Engineering,Kragujevac,Serbia;2021 IEEE 21st International Conference on Bioinformatics and Bioengineering (BIBE);15-dec-21;2021;;;1;5;Since the novel SARS-CoV-2 virus appeared, interest in developing epidemiological mechanisms that would help in prevention of its spread has increased. Epidemiological models are the most important mechanisms for examining the spread of the virus. For that purpose, we propose deep learning approach, LSTM neural network model. LSTM is a special kind of neural network structure capable of learning long-term dependencies in sequence prediction problems. The model was fed with official statistical data available online for Belgium in the period of March 15<sup>th</sup>, 2020 to March 15<sup>th</sup>, 2021. Results show that LSTM is capable of predicting in long-term manner with the low values of RMSE and MAE. Higher values of RMSE and MAE are observed in the infected cases (RMSE was 397.23 and MAE was 315.35) which is expected due to thousands of infected people per day in Belgium. In future studies, we will include more phenomena, especially medical intervention and asymptomatic infection, in order to better describe the COVID-19 spread and development.;2471-7819;978-1-6654-4261-9;10.1109/BIBE52308.2021.9635289;Serbian Ministry of Education, Science, and Technological Development(grant numbers:451-03-9/2021-14/200107), European Union's Horizon 2020 research and innovation programmes(grant numbers:952603), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9635289;COVID-19,disease spread modelling,time series forecasting,deep learning,LSTM-ED neural network;COVID-19,Deep learning,Pandemics,Biological system modeling,Neural networks,Urban areas,Sociology;;;;;;11;;15-dec-21;;;IEEE;IEEE Conferences
DST-Predict: Predicting Individual Mobility Patterns From Mobile Phone GPS Data;S. M. A. Zaidi, V. Chandola, E. -H. Yoo;Computer Science and Engineering, University at Buffalo-SUNY, Buffalo, NY, USA, Computer Science and Engineering, University at Buffalo-SUNY, Buffalo, NY, USA, Department of Geography, University at Buffalo-SUNY, Buffalo, NY, USA;IEEE Access;30-dec-21;2021;9;;167592;167604;Predicting spatial behaviors of an individual (e.g., frequent visits to specific locations) is important to improve our understanding of the complexity of human mobility patterns, and to capture anomalous behaviors in an individual’s spatial movements, which can be particularly useful in situations such as those induced by the COVID-19 pandemic. We propose a system called <italic>Deep Spatio-Temporal Predictor</italic> (<monospace>DST-Predict</monospace>), that can predict the future visit frequency of an individual based on one’s past mobility behaviour patterns using GPS trace data collected from mobile phones. Predicting such spatial behavior is challenging, primarily because individuals’ patterns of location visits for each individual consists of both systematic and random components, which vary across the spatial and temporal scales of analysis. To address these issues, we propose a novel multi-view sequence-to-sequence model that uses Convolutional Long-short term memory (ConvLSTM) where the past history of frequent visit patterns features is used to predict individuals’ future visit patterns in a multi-step manner. Using the GPS survey data obtained from 1,464 participants in western New York, US, we demonstrated that the proposed system is capable of predicting individuals’ frequency of visits to common places in an urban setting, with high accuracy.;2169-3536;;10.1109/ACCESS.2021.3134586;National Science Foundation, Office of Advanced Cyberinfrastructure (OAC)(grant numbers:1910539), National Institutes of Health(grant numbers:R01GM108731), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9645540;Human mobility,deep learning,predictive learning;Global Positioning System,Predictive models,Deep learning,Forecasting,Computer architecture,Mobile handsets,Microprocessors;;;;;;62;CCBY;10-dec-21;;;IEEE;IEEE Journals
Research on warning and monitoring mechanism of economic operation of air passenger transport economic operation under the impact of COVID-19;Y. He, M. Lu;China Academy of Civil Aviation Science and Technology,Beijing,China, China Academy of Civil Aviation Science and Technology,Beijing,China;2021 IEEE 3rd International Conference on Civil Aviation Safety and Information Technology (ICCASIT);10-dec-21;2021;;;401;407;The COVID-19 has had a great impact on the global air transport industry. This paper analyzes the impact on China’s air economic operation, including the current situation, challenges and problems of the regulation mechanism. A warning system for the economic operation of air passenger transport industry is conducted. With the help of warning lights, it reflects the degree of hotness or coldness of economic operation in 2011-2020. In addition, the study establishes the BP neural network forecast model to predict the economic operation of civil aviation industry in the next three years, and proposes the specific early warning management mechanism from five aspects. The conclusion of this study provides a strong support for guiding the civil aviation industry to prevent economic operation risks and improving the anti-vulnerability and resilience of the development of China's civil aviation industry.;;978-1-6654-2518-6;10.1109/ICCASIT53235.2021.9633396;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9633396;COVID-19,Early Warning System,BP Neural Network Model;Economics,Industries,COVID-19,Neural networks,Alarm systems,Predictive models,Regulation;;;;;;9;;10-dec-21;;;IEEE;IEEE Conferences
Novel COVID-19 Screening Using Cough Recordings of A Mobile Patient Monitoring System;X. Zhang, M. Pettinati, A. Jalali, K. S. Rajput, N. Selvaraj;Biofourmis Inc,Boston,MA,USA,02110, Biofourmis Inc,Boston,MA,USA,02110, Biofourmis Inc,Boston,MA,USA,02110, Biofourmis Inc,Boston,MA,USA,02110, Biofourmis Inc,Boston,MA,USA,02110;2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC);9-dec-21;2021;;;2353;2357;Since the COVID-19 pandemic began, research has shown promises in building COVID-19 screening tools using cough recordings as a convenient and inexpensive alternative to current testing techniques. In this paper, we present a novel and fully automated algorithm framework for cough extraction and COVID-19 detection using a combination of signal processing and machine learning techniques. It involves extracting cough episodes from audios of a diverse real-world noisy conditions and then screening for the COVID-19 infection based on the cough characteristics. The proposed algorithm was developed and evaluated using self-recorded cough audios collected from COVID-19 patients monitored by Biovitals<sup>®</sup> Sentinel remote patient management platform and publicly available datasets of various sound recordings. The proposed algorithm achieves a duration Area Under Receiver Operating Characteristic curve (AUROC) of 98.6% in the cough extraction task and a mean cross-validation AUROC of 98.1% in the COVID-19 classification task. These results demonstrate high accuracy and robustness of the proposed algorithm as a fast and easily accessible COVID-19 screening tool and its potential to be used for other cough analysis applications.;2694-0604;978-1-7281-1179-7;10.1109/EMBC46164.2021.9630722;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9630722;Machine learning,Signal processing,Audio Analysis,COVID-19 screening,Convolutional neural network (CNN);COVID-19,Machine learning algorithms,Signal processing algorithms,Tools,Predictive models,Feature extraction,Data models;;;COVID-19,Cough,Humans,Monitoring, Physiologic,Pandemics,Research Design,SARS-CoV-2,Sound Recordings;1;;20;;9-dec-21;;;IEEE;IEEE Conferences
SpeechSpiro: Lung Function Assessment from Speech Pattern as an Alternative to Spirometry for Mobile Health Tracking;K. Vatanparvar, V. Nathan, E. Nemati, M. M. Rahman, D. McCaffrey, J. Kuang, J. A. Gao;Samsung Research America,Digital Health Lab,Mountain View,CA,USA, Samsung Research America,Digital Health Lab,Mountain View,CA,USA, Samsung Research America,Digital Health Lab,Mountain View,CA,USA, Samsung Research America,Digital Health Lab,Mountain View,CA,USA, Samsung Research America,Digital Health Lab,Mountain View,CA,USA, Samsung Research America,Digital Health Lab,Mountain View,CA,USA, Samsung Research America,Digital Health Lab,Mountain View,CA,USA;2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC);9-dec-21;2021;;;7237;7243;Respiratory illnesses are common in the United States and globally, people deal with these illnesses in various forms, such as asthma, chronic obstructive pulmonary diseases, or infectious respiratory diseases (e.g., coronavirus). The lung function of subjects affected by these illnesses degrades due to infection or inflammation in their respiratory airways. Typically, lung function is assessed using in-clinic medical equipment, and quite recently, via portable spirometry devices. Research has shown that the obstruction and restriction in the respiratory airways affect individuals’ voice characteristics. Hence, audio features could play a role in predicting the lung function and severity of the obstruction. In this paper, we go beyond well-known voice audio features and create a hybrid deep learning model using CNN-LSTM to discover spatiotemporal patterns in speech and predict the lung function parameters with accuracy comparable to conventional devices. We validate the performance and generalizability of our method using the data collected from 201 subjects enrolled in two studies internally and in collaboration with a pulmonary hospital. SpeechSpiro measures lung function parameters (e.g., forced vital capacity) with a mean normalized RMSE of 12% and R<sup>2</sup> score of up to 76% using 60-second phone audio recordings of individuals reading a passage.Clinical relevance — Speech-based spirometry has the potential to eliminate the need for an additional device to carry out the lung function assessment outside clinical settings, hence, it can enable continuous and mobile track of the individual’s condition, healthy or with a respiratory illness, using a smartphone.;2694-0604;978-1-7281-1179-7;10.1109/EMBC46164.2021.9630077;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9630077;;Performance evaluation,Deep learning,Force measurement,Hospitals,Pulmonary diseases,Transfer learning,Lung;;;Humans,Lung,Pulmonary Disease, Chronic Obstructive,Speech,Spirometry,Telemedicine;;;29;;9-dec-21;;;IEEE;IEEE Conferences
L-Boost: Identifying Offensive Texts From Social Media Post in Bengali;M. F. Mridha, M. A. H. Wadud, M. A. Hamid, M. M. Monowar, M. Abdullah-Al-Wadud, A. Alamri;Department of Computer Science and Engineering, Bangladesh University of Business and Technology, Dhaka, Bangladesh, Department of Computer Science and Engineering, Bangladesh University of Business and Technology, Dhaka, Bangladesh, Department of Information Technology, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia, Department of Information Technology, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia, Research Chair of Pervasive and Mobile Computing, King Saud University, Riyadh, Saudi Arabia, Research Chair of Pervasive and Mobile Computing, King Saud University, Riyadh, Saudi Arabia;IEEE Access;21-dec-21;2021;9;;164681;164699;Due to the significant increase in Internet activity since the COVID-19 epidemic, many informal, unstructured, offensive, and even misspelled textual content has been used for online communication through various social media. The Bengali and Banglish(Bengali words written in English format) offensive texts have recently been widely used to harass and criticize people on various social media. Our deep excavation reveals that limited work has been done to identify offensive Bengali texts. In this study, we have engineered a detection mechanism using natural language processing to identify Bengali and Banglish offensive messages in social media that could abuse other people. First, different classifiers have been employed to classify the offensive text as baseline classifiers from real-life datasets. Then, we applied boosting algorithms based on baseline classifiers. AdaBoost is the most effective ensemble method called adaptive boosting, which enhances the outcomes of the classifiers. The long short-term memory (LSTM) model is used to eliminate long-term dependency problems when classifying text, but overfitting problems occur. AdaBoost has strong forecasting ability and overfitting problem does not occur easily. By considering these two powerful and diverse models, we propose L-Boost, the modified AdaBoost algorithm using bidirectional encoder representations from transformers (BERT) with LSTM models. We tested the L-Boost model on three separate datasets, including the BERT pre-trained word-embedding vector model. We find our proposed L-Boost’s efficacy better than all the baseline classification algorithms reaching an accuracy of 95.11%.;2169-3536;;10.1109/ACCESS.2021.3134154;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9642973;Offensive text,social media harassment,natural language processing,ensemble learning,BERT model;Social networking (online),Bit error rate,Predictive models,Hate speech,Classification algorithms,Writing,Licenses;Internet,learning (artificial intelligence),natural language processing,neural nets,pattern classification,social networking (online),text analysis;L-Boost's efficacy,identifying offensive texts,social media post,COVID-19 epidemic,Bengali words written in English format,offensive Bengali texts,natural language processing,Banglish offensive messages,offensive text,baseline classifiers,AdaBoost,adaptive boosting,short-term memory model,long-term dependency problems,classifying text,overfitting problem,L-Boost model,BERT pre-trained word-embedding vector model;;;;59;CCBY;8-dec-21;;;IEEE;IEEE Journals
Coronary Illness Prediction Using the AdaBoost Algorithm;G. Deivendran, S. Vishal Balaji, B. Paramasivan, S. Vimal;;Sensor Data Analysis and Management: The Role of Deep Learning;;2021;;;161;172;There are various machine learning (ML) algorithms such as naïve Bayes, random forest, k‐nearest neighbor, decision tree, support vector machine, and many others that are used in the prediction of heart disease. Various ML algorithms provide different accuracies. Neural networks prove to be efficient in heart disease prediction. This chapter considers a classification algorithm known as the AdaBoost algorithm. The fundamental goal of this examination is to improve the accuracy of coronary illness forecast. This algorithm increases the weights for the misclassified elements, thereby decreasing the error rate which, in turn, increases the efficiency of the coronary illness prediction. The chapter presents discussions related to heart disease and existing methods. It deals with implementation details, which include preprocessing, feature selection, classification, performance measures, and results. The chapter concludes with the current work and includes notes on future enhancement.;;9,78112E+12;10.1002/9781119682806.ch10;;https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9640427.pdf&bkn=9640327&pdfType=chapter;;Diseases,Heart,Prediction algorithms,Classification algorithms,Hidden Markov models,Feature extraction,Artificial intelligence;;;;;;7-dec-21;;;IEEE;Wiley-IEEE Press eBook Chapters;;
Forecast of Covid-19 Using Deep Learning;A. Raj, N. R. Umrani, S. G R, S. Audichya, A. Kodipalli, R. J. Martis;Global Academy of Technology,Computer Science and Engineering,Bengaluru,India, Global Academy of Technology,Computer Science and Engineering,Bengaluru,India, Global Academy of Technology,Computer Science and Engineering,Bengaluru,India, Global Academy of Technology,Computer Science and Engineering,Bengaluru,India, Global Academy of Technology,Computer Science and Engineering,Bengaluru,India, Global Academy of Technology,Computer Science and Engineering,Bengaluru,India;2021 IEEE International Conference on Electronics, Computing and Communication Technologies (CONECCT);7-dec-21;2021;;;1;5;Outbreak of Covid-19 pandemic caused significant mortality and it became a threat to the human life. Since then every government is doing its best to curtail this health emergency. In India also the government has adapted a number of policies to contain this public health emergency. Despite of all these measures undertaken early prediction and forecast of the number of cases can greatly augment with the health policies implemented by the government bodies. In this direction various deep learning algorithms such as variants of Long Short Term Memory (LSTM) models are used in this study to forecast the number of cases. It is inferred from this study that the Bidirectional LSTM provided highest performance by providing a minimum mean absolute percentage error (MAPE) of 0.021% on the Indian Covid-19 data. The proposed methodology can be used in efficient planning and management of Covid-19.;2766-2101;978-1-6654-2849-1;10.1109/CONECCT52877.2021.9622721;Karnataka State Council for Science and Technology of Government of Karnataka, India and Global Academy of Technology, ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9622721;Covid-19,Prediction,Deep learning,Recurrent Neural Network,LSTM,Mean Absolute Percentage Error;COVID-19,Deep learning,Pandemics,Biological system modeling,Government,Time series analysis,Predictive models;;;;;;19;;7-dec-21;;;IEEE;IEEE Conferences
Prediction and Analysis of Covid-19 Positive Cases Using Deep Learning Model;M. Farhan, S. Jabbar, M. R. Shahid;The University of Faisalabad,Departmental of Computational Sciences,Faislabad,Pakistan, The University of Faisalabad,Departmental of Computational Sciences,Faislabad,Pakistan, The University of Faisalabad,Departmental of Computational Sciences,Faislabad,Pakistan;2021 International Conference on Computing, Electronic and Electrical Engineering (ICE Cube);7-dec-21;2021;;;1;6;At the end of December 2019, the COVID-19 virus was the initial report case in China Wuhan City. On March 11, 2020. The Department of Health (WHO) announced COVID-19, a global pandemic. The COVID-19 spread rapidly out all over the world within a few weeks. We will propose to develop a forecasting model of COV-19 positive case predict outbreak in Pakistan using Deep Learning (DL) models. We assessed the main features to forecast patterns and indicated The new COVID-19 disease pattern in Pakistan and other countries of the world. This research will use the deep learning model to measure several COVID-19 positive case reports in Pakistan. LSTM cell to process time-series data forecasts is very efficient. Recurrent neural network processes to handle time-dependent and involve hidden layers are confirmed and predict positive cases and weekly cases reported in the future. Bidirectional LSTM (Bi-LSTM) processes data and information in one direction to predict and analyze the weekly 6-9 days readily forecast the number of positive cases of COVID-19;;978-1-6654-0154-8;10.1109/ICECube53880.2021.9628335;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9628335;Prediction,Analysis,Deep learning model,LSTM,RNN,CNN,(Bi-LSTM);COVID-19,Deep learning,Analytical models,Recurrent neural networks,Computational modeling,Urban areas,Bidirectional control;;;;;;17;;7-dec-21;;;IEEE;IEEE Conferences
Automatic Stylized Plaid Check Pattern Try-on;J. Kim, J. Park, J. Kwon;School of Computer Science and Engineering, Chung-Ang University,Seoul,Republic of Korea, School of Computer Science and Engineering, Chung-Ang University,Seoul,Republic of Korea, School of Computer Science and Engineering, Chung-Ang University,Seoul,Republic of Korea;2021 International Conference on Information and Communication Technology Convergence (ICTC);7-dec-21;2021;;;1703;1706;In ithe nterest of pleasing the needs of customers finding new styles in fashion, we present a novel method that is capable of creating novel plaid and check patterned shirts based on consumer taste integrated with well-known art piece, as well as giving a predicted look of the shirt on the customer. This is done through a combination of three existing deep neural networks [1]–[3]. Since public stores are closing due to the COVID-19, customers are unable to try out apparel before purchasing. Qualitative experiments demonstrate the effectiveness of the proposed method. We believe that our service meets the need of frustrated customers in the pandemic of COVID-19.;2162-1233;978-1-6654-2383-0;10.1109/ICTC52510.2021.9621177;IITP(Institute for Information & communications Technology Promotion)(grant numbers:20170001000051001), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9621177;;Deep learning,Art,Footwear,Information and communication technology,Augmented reality,Clothing;;;;;;5;;7-dec-21;;;IEEE;IEEE Conferences
An Ensemble Machine Learning Approach For Time Series Forecasting of COVID-19 Cases;R. R. Maaliw, M. A. Ballera, Z. P. Mabunga, A. T. Mahusay, D. A. Dejelo, M. P. Seño;College of Engineering, Southern Luzon State University,Lucban,Quezon,Philippines, Graduate Programs, Technological Institute of the Philippines,Manila,Philippines, College of Engineering, Southern Luzon State University,Lucban,Quezon,Philippines, College of Engineering, Southern Luzon State University,Lucban,Quezon,Philippines, Southern Luzon State University,College of Allied Medicine,Lucban,Quezon,Philippines, Southern Luzon State University,College of Arts and Sciences,Lucban,Quezon,Philippines;2021 IEEE 12th Annual Information Technology, Electronics and Mobile Communication Conference (IEMCON);6-dec-21;2021;;;633;640;Forecasting assists governments, epidemiologists, and policymakers make calculated decisions to mitigate the spread of the COVID-19 pandemic, thus saving lives. This paper presents an ensemble machine learning model by combining the distinctive strengths of autoregressive integrated moving averages (ARIMA) and stacked long short-term memory networks (S-LSTM) using extensive training procedures and model integration algorithms. We validated the model's generalization capabilities by analyzing time series data of four countries, such as the Philippines, United States, India, and Brazil spanning 467 days. The quantitative results show that our ensemble model outperforms stand-alone models of ARIMA and S-LSTM for a 15-day forecast accuracy of 93.50% (infected cases) and 87.97% (death cases).;2644-3163;978-1-6654-0066-4;10.1109/IEMCON53756.2021.9623074;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623074;combined time series models,infectious disease,optimization,pandemic,prediction,neural networks;COVID-19,Training,Machine learning algorithms,Pandemics,Time series analysis,Machine learning,Predictive models;;;;2;;25;;6-dec-21;;;IEEE;IEEE Conferences
Forecasting pharmacy purchases orders;B. K. Almentero, J. Li, C. Besse;Université Laval,Thales Research and Technology,Quebec,QC,Canada, Thales Research and Technology,Quebec,QC,Canada, Université Laval,Institute Intelligence et Données,Quebec,QC,Canada;2021 IEEE 24th International Conference on Information Fusion (FUSION);2-dec-21;2021;;;1;8;Inventory represents the largest asset in pharmacy products distribution. Forecasting pharmacy purchases is essential to keep an effective stock balancing supply and demand besides minimizing costs. In this work, we investigate how to forecast product purchases for a pharmaceutical distributor. The data contains inventory sale histories for more than 10 thousand active products during the past 15 years. We discuss challenges on data preprocessing of the pharmacy data including cleaning, feature constructions and selections, as well as processing data during the COVID period. We experimented on different machine learning and deep learning neural network models to predict future purchases for each product, including classical Seasonal Autoregressive Integrated Moving Average (SARIMA), Prophet from Facebook, linear regression, Random Forest, XGBoost and Long Short-Term Memory (LSTM). We demonstrate that a carefully designed SARIMA model outperformed the others on the task, and weekly prediction models perform better than daily predictions.;;978-1-7377497-1-4;;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9627017;Machine learning (ML),regression,time series forecasting,SARIMA,LSTM,COVID,explainable AI,SHAP value;Deep learning,Machine learning algorithms,Social networking (online),Neural networks,Predictive models,Prediction algorithms,Data models;;;;;;29;;2-dec-21;;;IEEE;IEEE Conferences
Surrogate Parameters Optimization for Data and Model Fusion of COVID-19 Time-series Data;O. Timilehin, T. L. van Zyl;University of the Witwatersrand,Computer Science and Applied Mathematics,Johannesburg,South Africa, University of Johannesburg,Institute for Intelligent Systems,Johannesburg,South Africa;2021 IEEE 24th International Conference on Information Fusion (FUSION);2-dec-21;2021;;;1;7;Our research focuses on developing a computational framework to simulate the transmission dynamics of COVID-19 pandemic. We examine the development of a system named ADRIANA for the simulation using South Africa as a case study. The design of ADRIANA system interconnects three sub-models to establish a computational technique to advise policy regarding lockdown measures to reduce the transmission pattern of COVID-19 in South Africa. Additionally, the output of the ADRIANA can be used by healthcare administration to predict peak demand time for resources needed to treat infected individuals. ABM is suited for our research experiment, but to prevent the computational constraints of using ABM-based framework for this research, we develop an SEIR compartmental model, a discrete event simulator, and an optimized surrogate model to form a system named ADRIANA. We also ensure that the surrogate’s findings are accurate enough to provide optimal solutions. We use the Genetic Algorithm (GA) for the optimization by estimating the optimal hyperparameter configuration for the surrogate. We concluded this study by discussing the solutions presented by the ADRIANA system, which aligns with the primary goal of our study to present an optimal guide to lockdown policy by the government and resource management by the hospital administrators.;;978-1-7377497-1-4;;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9627065;Optimization,genetic algorithm,data science,recurrent neural network,time-series,stationary data,COVID-19,forecast,deep learning;COVID-19,Personal protective equipment,Pandemics,Hospitals,Computational modeling,Predictive models,Data models;;;;;;38;;2-dec-21;;;IEEE;IEEE Conferences
CNN Based Architecture for Automatically Detecting People without Face Mask;S. K. Chandra, A. Bhansali;OP Jindal University,Computer Science and Engineering,Raigarh,India, OP Jindal University,Computer Science and Engineering,Raigarh,India;2021 Emerging Trends in Industry 4.0 (ETI 4.0);1-dec-21;2021;;;1;6;COVID-19 emerged as one of the major outbreak to human society and has been declared as pandemic by World Health Organization (WHO). The first phase was almost over in the month of February 2021 in India, but soon after second wave emerged out with greater impact. The whole world is struggling hard to contain the spread of virus but finding it difficult, as new mutations and variants are taking shape continuously. Many mathematical models have been designed to predict spread of COVID-19, but prediction fails due to evolution of virus as well as its behavior. WHO provided many guidelines to prevent spread of COVID-19 which includes social distancing, wearing of masks in public places and frequent sensitization of hands. Wearing of mask has been proved to be the most effective in preventing the spread of corona virus. Wearing masks perhaps is the most important life style change which could help contain the spread of virus specially in offices, malls, theaters, restaurants and other public places. Though the administration frequently issues guidelines to wear masks but it is really very difficult to identify the peoples without mask in large gatherings. In the present manuscript, an automatic mask detection system has been proposed using machine learning to automatically identity the people without masks.;;978-1-6654-2237-6;10.1109/ETI4.051663.2021.9619257;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9619257;COVID-19,Deep learning,Covolutional Neural Network,Face mask detection;COVID-19,Visualization,Shape,Pandemics,Organizations,Social factors,Mathematical models;;;;;;25;;1-dec-21;;;IEEE;IEEE Conferences
Prediction of Heart Disease using Random Forest;N. M. Lutimath, N. Sharma, B. K. Byregowda;Rajiv Gandhi Institute of Technology,Department of Computer Science and Engineering,Bengaluru,India, Chandigarh University,Department of CSE(Apex),Mohali,Punjab,India, Sir M Visveswaraya Institute of Technology,Department of Information Science and Engineering,Bengaluru,India;2021 Emerging Trends in Industry 4.0 (ETI 4.0);1-dec-21;2021;;;1;4;Random Forests are of the vital models in machine learning. They are comprehensive and effective classification paradigms in machine learning. The random forest recognizes the most important attributes of a given problem. The heart disorder is a cardiovascular disease, with a set of conditions affecting the heart. During heart disease there will be heart beat problems with congenital heart disorders and coronary artery defects. Coronary heart defect is a heart disease, which decreases the flow of blood to the heart. When the flow of blood decreases heart attack occurs. It is necessary to analyse the prediction of heart attack based on the symptoms. Available data set instances of the patients with heart defects symptoms is taken and analysed in this paper. Python language is utilized to prediction of the accuracy.;;978-1-6654-2237-6;10.1109/ETI4.051663.2021.9619208;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9619208;Decision Tree,Machine Learning,Random Forest,Python,healthcare;Heart,Support vector machines,Deep learning,Heart beat,Cardiac arrest,Forestry,Market research;blood,blood vessels,cardiology,cardiovascular system,diseases,learning (artificial intelligence),medical signal processing,pattern classification;heart defects symptoms,heart disease,random forest,Random Forests,machine learning,heart disorder,cardiovascular disease,heart beat problems,congenital heart disorders,coronary heart defect,heart attack;;;;7;;1-dec-21;;;IEEE;IEEE Conferences
Monitoring and Controlling Thermal Comfort in Air Conditioner Using YoloV4 And Predicted Mean Vote;B. G. Pratama, O. Yuliani;Institut Teknologi Nasional Yogyakarta,Fakultas Teknologi Industri,Sleman,Indonesia, Institut Teknologi Nasional Yogyakarta,Fakultas Teknologi Industri,Sleman,Indonesia;2021 7th International Conference on Electrical, Electronics and Information Engineering (ICEEIE);30-nov-21;2021;;;460;465;Indonesia is the one of many countries that the AC sales are rising each year, especially on corona pandemic. Because of that, Indonesia becomes the world largest Cooling Degree Days (CDD) exposure after India and China and it’s worsening due to the location of Indonesia in equator line. Our research aimed to create a prototype that control and monitor AC using YoloV4 and predicted mean vote. YoloV4 was employed to predict and count human in the room. Meanwhile, predicted mean vote was utilized as AC temperature controller based on reference given by users. The created system could turn off AC when there was no one in the room, vice versa. When user selected one of thermal comfort modes (Hot, Warm, Normal, Cool, or Cold), the system calculated the best temperature at given relative humidity and human presence then changed the AC temperature using MQTT protocol.;;978-1-6654-3232-0;10.1109/ICEEIE52663.2021.9616849;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9616849;Computer Vision,Internet of Things,Deep Learning,Thermal Comfort,Smart System;Temperature sensors,Temperature measurement,Protocols,Pandemics,Cooling,Thermal engineering,Prototypes;;;;;;30;;30-nov-21;;;IEEE;IEEE Conferences
Comparison of CNN and CNN-LSTM Architectures for Tool Wear Estimation;F. C. Zegarra, J. Vargas-Machuca, A. M. Coronado;Universidad Nacional Tecnológica de Lima Sur (UNTELS),Laboratorio de Sistemas Inteligentes, EPIME,Lima,Peru,15834, Universidad Nacional Tecnológica de Lima Sur (UNTELS),Laboratorio de Sistemas Inteligentes, EPIME,Lima,Peru,15834, Universidad Nacional Tecnológica de Lima Sur (UNTELS),Laboratorio de Sistemas Inteligentes, EPIME,Lima,Peru,15834;2021 IEEE Engineering International Research Conference (EIRCON);30-nov-21;2021;;;1;4;Modern manufacturing needs to guarantee product quality and reduce operating costs. These can be achieved through the use of analytical tools, which depend on the collection of large amounts of data, in this particular case in the form of time series. During the last few years, various conventional and neural network-based methods have shown great promise in problems related to estimating milling cutter wear. Among neural networks, recurrent networks are especially promising due to the memory mechanism they use. In the present work, a comparison is made between a CNN network and a CNN-LSTM network. Both networks extract information directly from the time series of a widely used database. Unlike similar works in the existing literature, two simple preprocessing techniques are used: to remove the tendency of the time series and to equalize the initial values of the tool wear. Additionally, Bayesian optimization of hyperparameters is used. Mean square errors are obtained that are consistently around 10, results equivalent to the state of the art.;;978-1-6654-4445-3;10.1109/EIRCON52903.2021.9613659;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9613659;CNC machine tool,tool wear prediction,CNN,CNN-LSTM,hyperparameter optimization;Time series analysis,Neural networks,Computer architecture,Milling,Tools,Product design,Quality assessment;;;;;;17;;30-nov-21;;;IEEE;IEEE Conferences
Building an AI Model on ECG Data for Identifying Burnout/Stressed Healthcare Workers Involved in Covid-19 Management;A. Mahajan, M. K. Shetty, G. M. P., M. D. Gupta, A. Gupta;IIIT-Delhi,Department of CSE,India, Maulana Azad Medical College,Department of Pharmacology,Delhi,India, G.B.Pant Institute of Post Graduate,Department of Cardiology,Delhi,India, G.B.Pant Institute of Post Graduate,Department of Cardiology,Delhi,India, IIIT-Delhi,SBILab,Department of ECE,India;2021 Fourth International Conference on Electrical, Computer and Communication Technologies (ICECCT);29-nov-21;2021;;;1;6;An electrocardiogram (ECG) is used to monitor electrical activity of the heart. ECG data with 12 leads can help in detecting various cardiac (heart) problems. One of the significant factors that contribute to various cardiac diseases is work/personal stress. Use of various machine and deep learning approaches to analyse ECG data has yielded promising results in the field of predictive and diagnostic healthcare with less human error or bias. In our study, 10sec of 500Hz, 12-lead ECG samples were collected from the healthcare workers, who were involved directly or indirectly in taking care of COVID-19 patients. The present study was designed to determine whether Healthcare workers were stressed by using only ECG as input to a deep learning model. To the best of our knowledge, no earlier ECG based study has been carried out to identify stressed persons among the healthcare workers who are giving support to COVID-19 patients. In this study, ECG data of healthcare workers giving services to COVID-19 patients is utilized. This data was collected from four tertiary academic care centres of India. A modified version of AlexNet is utilized on this data that is able to identify a stressed healthcare worker with 99.397% accuracy and 99.411% AUC score. Successful deployment of such systems can help governments and hospital administrations make appropriate policy decisions during pandemics.;;978-1-6654-1480-7;10.1109/ICECCT52121.2021.9616635;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9616635;ECG signal,Feature Extraction,Classification,Convolution Neural Network(CNN),AlexNet,Visualization;COVID-19,Training,Heart,Deep learning,Pandemics,Computational modeling,Medical services;;;;;;18;;29-nov-21;;;IEEE;IEEE Conferences
Neural Networks Architecture for COVID-19 Early Detection;R. Zgheib, G. Chahbandarian, F. Kamalov, O. E. Labban;Canadian University Dubai,School of Computer Engineering,Dubai,UAE, Institut de recherche en informatique de Toulouse,Toulouse,France, Canadian University Dubai,School of Computer Engineering,Dubai,UAE, Al Zahra Hospital,Family Medicine Department,Dubai,UAE;2021 International Symposium on Networks, Computers and Communications (ISNCC);25-nov-21;2021;;;1;6;Coronavirus fight seems far from being won. Governments are trying to balance the necessity to enforce restrictions on travel outside the home and the impact of these restrictions on the economy. Healthcare workers are overloaded, a considerable number of unnecessary and costly PCR tests are performed to serve as a certificate to go to work. At this stage, going back to everyday life safely requires the companies and public places to adopt AI-based solutions to assist the public authorities and the hospitals with the COVID detection. The most important issue that we tackle in this paper is the prediction to be very accurate. As a result, we propose an AI system based on Neural Networks (NN) method to predict whether a person has caught COVID19 disease or not. In this study, we used a real data set of 9416 patients tested for COVID19 at a hospital in Dubai. After training the NN model, the average error function of the neural network was equal to 0.01, and the accuracy of the prediction of whether a person has COVID or not was 97.6%.;;978-1-6654-0304-7;10.1109/ISNCC52172.2021.9615883;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9615883;;COVID-19,Training,Heart rate,Hospitals,Pandemics,Artificial neural networks,Computer architecture;;;;;;23;;25-nov-21;;;IEEE;IEEE Conferences
Deep Learning and Augmented Reality for IoT-based Air Quality Monitoring and Prediction System;M. S. H. Sassi, L. C. Fourati;Sfax University,Digital Research Center of Sfax (CRNS) Laboratory of Signals, systeMs, aRtificial Intelligence, and neTworkS (SM@RTS),Tunisia, Sfax University,Digital Research Center of Sfax (CRNS) Laboratory of Signals, systeMs, aRtificial Intelligence, and neTworkS (SM@RTS),Tunisia;2021 International Symposium on Networks, Computers and Communications (ISNCC);25-nov-21;2021;;;1;6;During the pandemic of Corona-virus Disease 2019 (COVID-19), the whole world was confronted by a particularly high death toll and infection rate. Research has shown that air pollution plays a considerable part in the spread of certain illnesses and diseases. In the case of the COVID-19 pandemic, research has shown that increased air pollution has a negative effect on people’s well-being and plays a role in the quick spread of the disease. Air pollution by itself affects the respiratory system of individuals which is aggravated, in addition, by a COVID19 infection. Some efforts have been made to use emerging technologies to combat the virus and its subsequent aerosol aspects to reduce transmission. In this context, we present an IoT system for Air Quality (AQ) monitoring and prediction using deep learning for data analysis and Augmented Reality (AR) for data visualization. The proposed system shows great potential for using Recurrent Neural Networks (RNN) and Long Short-Term Memory (LSTM) units as a framework for leveraging knowledge from time-series data of AQ. Moreover, integrating AR visualization for the proposed IoT system enables intuitive interaction between users and IoT devices and further improves visualization of AQ data which effectively contributes to easily conducting a deeper analysis of data and makes faster decisions.;;978-1-6654-0304-7;10.1109/ISNCC52172.2021.9615639;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9615639;Augmented reality,internet of things,deep learning,air quality;COVID-19,Deep learning,Recurrent neural networks,Pandemics,Data visualization,Predictive models,Air pollution;;;;;;19;;25-nov-21;;;IEEE;IEEE Conferences
Multimodal Detection of COVID-19 Symptoms using Deep Learning & Probability-based Weighting of Modes;M. Effati, Y. -C. Sun, H. E. Naguib, G. Nejat;Autonomous Systems and Biomechatronics Laboratory (ASBLab), Autonomous Systems and Biomechatronics Laboratory (ASBLab), University of Toronto,Toronto Smart Materials and Structures (TSMART) Department of Mechanical and Industrial Engineering, Autonomous Systems and Biomechatronics Laboratory (ASBLab);2021 17th International Conference on Wireless and Mobile Computing, Networking and Communications (WiMob);22-nov-21;2021;;;151;156;The COVID-19 pandemic is one of the most challenging healthcare crises during the 21<sup>st</sup> century. As the virus continues to spread on a global scale, the majority of efforts have been on the development of vaccines and the mass immunization of the public. While the daily case numbers were following a decreasing trend, the emergent of new virus mutations and variants still pose a significant threat. As economies start recovering and societies start opening up with people going back into office buildings, schools, and malls, we still need to have the ability to detect and minimize the spread of COVID-19. Individuals with COVID-19 may show multiple symptoms such as cough, fever, and shortness of breath. Many of the existing detection techniques focus on symptoms having the same equal importance. However, it has been shown that some symptoms are more prevalent than others. In this paper, we present a multimodal method to predict COVID-19 by incorporating existing deep learning classifiers using convolutional neural networks and our novel probability-based weighting function that considers the prevalence of each symptom. The experiments were performed on an existing dataset with respect to the three considered modes of coughs, fever, and shortness of breath. The results show considerable improvements in detection of COVID-19 using our weighting function when compared to an equal weighting function.;2160-4894;978-1-6654-2854-5;10.1109/WiMob52687.2021.9606355;AGE-WELL, ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9606355;COVID-19 screening,multimodal classification,deep learning,statistical-based weighting system;COVID-19,Deep learning,Wireless communication,Pandemics,Market research,Coronaviruses,Vaccines;;;;;;45;;22-nov-21;;;IEEE;IEEE Conferences
ANN based DoA Estimation of the Signal Received by Two-element Textile Wearable Antenna Array;Z. Stanković, O. Pronić-Rančić, N. Dončov;University of Niš,Faculty of Electronic Engineering,Niš,Serbia,18000, University of Niš,Faculty of Electronic Engineering,Niš,Serbia,18000, University of Niš,Faculty of Electronic Engineering,Niš,Serbia,18000;2021 15th International Conference on Advanced Technologies, Systems and Services in Telecommunications (TELSIKS);22-nov-21;2021;;;86;91;ANN model for one-dimensional DoA estimation of the signal received by two-element textile wearable antenna array is proposed in this paper. Multilayer perceptron network is used to create the MLP_DoA module which is capable to provide information of a radio gateway location in azimuthal plane as output when a spatial correlation matrix, found by receiving the radio gateway signal using two-element textile wearable antenna array, is on its input. The noise impact on the accuracy of the proposed ANN model is investigated. Comparison of the presented model with the root MUSIC algorithm in terms of accuracy and program execution time is also demonstrated.;;978-1-6654-4442-2;10.1109/TELSIKS52058.2021.9606386;Ministry of Education, ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9606386;ANN,DoA,TWAA,root MUSIC;Direction-of-arrival estimation,Correlation,Receiving antennas,Estimation,Logic gates,Multilayer perceptrons,Multiple signal classification;;;;;;14;;22-nov-21;;;IEEE;IEEE Conferences
Faraday Polarization Rotation in the Ionosphere using Radial Basis Function ANN;Z. Ž. Stanković, M. Sarevska, N. S. Dončov;University of Nis,Faculty of Electronic Engineering,Nis,Serbia,18000, American University of Europe-FON,Skopje,North Macedonia,1000, University of Nis,Faculty of Electronic Engineering,Nis,Serbia,18000;2021 15th International Conference on Advanced Technologies, Systems and Services in Telecommunications (TELSIKS);22-nov-21;2021;;;33;38;An alternative way, based on Artificial Neural Networks (ANN), for the estimation of Faraday polarization rotation of the electromagnetic wave that propagates in the ionosphere, is presented here. It uses a model developed by a Radial Basis Function ANN that determines approximate value of the total content of free electrons on the propagating path of the EM wave according to the latitude of the receiving terminal and daytime instance. Afterwards, this value is used to estimate the angle of Faraday Polarization Rotation. This model provides the estimation of the angle for summer and winter period in the Mediterranean area.;;978-1-6654-4442-2;10.1109/TELSIKS52058.2021.9606387;Ministry of Education, ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9606387;Faraday rotation (FR),FR estimation,Artificial neural network (ANN),Radial Basis Function ANN,Synthetic aperture radar;Estimation,Artificial neural networks,Faraday effect,Data models,Time measurement,Software,Numerical models;;;;;;26;;22-nov-21;;;IEEE;IEEE Conferences
ANN-EM Model of Dual Band Square Patch Antenna with a Floating Rectangular Slot;K. Pesic, Z. Stankovic, N. Doncov;University of Nis,Faculty of Electronic Engineering,Nis,Serbia,18000, University of Nis,Faculty of Electronic Engineering,Nis,Serbia,18000, University of Nis,Faculty of Electronic Engineering,Nis,Serbia,18000;2021 15th International Conference on Advanced Technologies, Systems and Services in Telecommunications (TELSIKS);22-nov-21;2021;;;153;156;In this paper, an ANN-EM neural model of dual band square patch antenna with a floating rectangular slot is presented. For the desired resonant frequencies, this ANN-EM model allows to speed up the process of estimating the physical parameters of the antenna with a good match between the antenna and the power line. The ANN EM model makes it possible to obtain antenna parameters for resonant frequencies that belong to the frequency range 700-3000 MHz.;;978-1-6654-4442-2;10.1109/TELSIKS52058.2021.9606409;Ministry of Education, ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9606409;Dual band patch antenna,Neural network,Neural model;Time-frequency analysis,Slot antennas,Patch antennas,Resonant frequency,Dual band,Artificial neural networks,Frequency response;;;;;;12;;22-nov-21;;;IEEE;IEEE Conferences
Estimating and analyzing the spread of Covid-19 in Turkey using Long Short-Term Memory;G. Güçlü, A. Al-Dulaimi;Yalova University,Department of Computer Engineering,Yalova,Turkey, Yalova University,Department of Computer Engineering,Yalova,Turkey;2021 5th International Symposium on Multidisciplinary Studies and Innovative Technologies (ISMSIT);19-nov-21;2021;;;17;26;The COVID-19 virus that began in late December 2019 continues to spread rapidly in many countries around the world. Due to its contagious and fast-spreading nature, it causes great harm to countries economically, medically, socially and in all other areas. Therefore, it is imperative to predict the evolution and spread of the epidemic. By understanding the trend of developing confirmed cases in an area, governments can control the epidemic by launching appropriate plans and instructions.Many scientists have tried to predict the number of cases using traditional mathematical techniques, however, the common traditional mathematical differential equations have limitations in estimating cases numbers in time series data and even have major errors in estimation. To solve this problem, we propose an improved method for predicting validated states based on the LSTM (long-term memory) neural network.Since the traditional prediction models predict the number of cumulative cases only, so they expect that the rate of infections will always rise and they cannot predict when the spread of the virus will decrease or end, so our model is built on short-term memory that predicts the number of daily cases but not the number of cumulative cases (LSTM).;;978-1-6654-4930-4;10.1109/ISMSIT52890.2021.9604594;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9604594;COVID-19,LSTM,Turkey,Prediction,RNN;COVID-19,Epidemics,Local government,Biological system modeling,Time series analysis,Estimation,Predictive models;;;;;;18;;19-nov-21;;;IEEE;IEEE Conferences
Exploring the Speech Language Therapy through Information Communication Technologies, Machine Learning and Neural Networks;S. K. Chronopoulos, E. I. Kosma, K. P. Peppas, D. Tafiadis, K. Drosos, N. Ziavra, E. I. Toki;University of Ioannina,Department of Speech Language Therapy,Ioannina,Greece, University of Ioannina,Department of Speech Language Therapy,Ioannina,Greece, University of Peloponnese,Department of Informatics and Telecommunications,Tripolis,Greece, University of Ioannina,Department of Speech Language Therapy,Ioannina,Greece, European University Cyprus,iCommunicate Research Center (iCRC),Department of Speech Language Therapy,Cyprus, University of Ioannina,Department of Speech Language Therapy,Ioannina,Greece, University of Ioannina,Department of Speech Language Therapy,Ioannina,Greece;2021 5th International Symposium on Multidisciplinary Studies and Innovative Technologies (ISMSIT);19-nov-21;2021;;;193;198;Currently, the needs for new technologies are rising and especially due to Covid-19. The world is changing into a digital theater of businesses and educational processes. Consequently, tele-health is constantly enriched with new scientific areas of expertise, a fact that gives a new and promising perspective for people who cannot reach in-time a specialist. Specifically, for the case of speech language therapy (SLT), new techniques emerge and involve telepractice and tele-counceling. In turn, the aim of the present study was to discover a model of predicting potential benefits from the online form of speech and language therapy (distant sessions) along with the view of the involved speech therapists and parents. For this purpose, a hypothetical sample of specialists and parents, was produced as being supposedly participated into sessions with their children for evaluating the overall performance of each technique (live and distant) with a total score. Thereinafter, statistical analyses were performed and the relevant machine learning was applied for building an artificial neural network for examining the results, in order to show the capabilities of the proposed model. This outcome is important as it can actuate SLT scientific area to include, in the future, more advanced techniques for distant sessions, concluding to even surpassing the classical technique.;;978-1-6654-4930-4;10.1109/ISMSIT52890.2021.9604553;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9604553;speech language therapy,tele-practice,internet speech therapy,tele-health,distant speech therapy,machine learning,neural network;COVID-19,Statistical analysis,Sociology,Buildings,Medical treatment,Machine learning,Artificial neural networks;;;;;;26;;19-nov-21;;;IEEE;IEEE Conferences
Comparative Study of Forecasting Models for COVID-19 Outbreak in Turkey;M. Nakip, O. Çopur, C. Güzeliş;Institute of Theoretical and Applied Informatics, Polish Academy of Sciences,Gliwice,Poland, Sapienza Universiy of Rome,Department of Statistics,Rome,Italy, Yaşar University,Dept. of Electrical-Electronics Engineering,Izmir,Turkey;2021 Innovations in Intelligent Systems and Applications Conference (ASYU);18-nov-21;2021;;;1;6;This paper gives an explanation for the failure of machine learning models for the prediction of the cases and the other future trends of Covid-19 pandemic. The paper shows that simple Linear Regression models provide high prediction accuracy values reliably but only for a 2-weeks period and that relatively complex machine learning models, which have the potential of learning long-term predictions with low errors, cannot achieve to obtain good predictions with possessing a high generalization ability. It is suggested in the paper that the lack of a sufficient number of samples is the source of the low prediction performance of the forecasting models. To exploit the information, which is of most relevant with the active cases, we perform feature selection over a variety of variables such as the numbers of active cases, deaths, recoveries, and population. Furthermore, we compare Linear Regression, Multi-Layer Perceptron, and Long-Short Term Memory models each of which is used for prediction of active cases together with various feature selection methods. Our results show that the accurate forecasting of the active cases with high generalization ability is possible up to 3 days because of the small sample size of COVID-19 data. We observe that the Linear Regression model has much better prediction performance with high generalization ability as compared to the complex models but, as expected, its performance decays sharply for more than 14-days prediction horizons.;;978-1-6654-3405-8;10.1109/ASYU52992.2021.9599053;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9599053;COVID-19,forecasting,machine learning,feature selection,generalization;COVID-19,Pandemics,Linear regression,Time series analysis,Machine learning,Predictive models,Benchmark testing;;;;;;29;;18-nov-21;;;IEEE;IEEE Conferences
Analysis of the Effects of Smoking Desire and Self-Efficacy on Nicotine Use Levels During the Covid-19 Pandemic Period Using Machine Learning Techniques;S. Duman, Y. Aydin, P. Bilim, M. Ali Aktaş;Taros University,Department of Software Engineering,Mersin,Turkey, Taros University,Department of Psychology,Mersin,Turkey, Taros University,Department of Psychology,Mersin,Turkey, Taros University,Department of Software Engineering,Mersin,Turkey;2021 Innovations in Intelligent Systems and Applications Conference (ASYU);18-nov-21;2021;;;1;3;In March 2020, when the first COVID-19 case was reported in Turkey, some regulations as minimum physical contact, staying at home, closed schools, and unstable working systems became a part of our lives. With these accusatory changes in lifestyle, it has become difficult for people to cope with this period. In this study, the effect of self-efficacy and desire to smoke on nicotine addiction during the COVID-19 pandemic was analyzed and classified by machine learning methods. Among the classification algorithms used, classification was made with a random forest classifier with an accuracy of 71.4%.;;978-1-6654-3405-8;10.1109/ASYU52992.2021.9598996;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9598996;addiction,nicotine,smoking,kNN,random forest,ANN,self-efficacy;COVID-19,Technological innovation,Machine learning algorithms,Pandemics,Predictive models,Reliability engineering,Prediction algorithms;;;;;;17;;18-nov-21;;;IEEE;IEEE Conferences
Predict ATFCM weather regulations using a time-distributed Recurrent Neural Network;S. Mas-Pujol, E. Salamí, E. Pastor;Technical University of Catalonia,Computer Architecture Department,Barcelona,Spain, Technical University of Catalonia,Computer Architecture Department,Barcelona,Spain, Technical University of Catalonia,Computer Architecture Department,Barcelona,Spain;2021 IEEE/AIAA 40th Digital Avionics Systems Conference (DASC);15-nov-21;2021;;;1;8;In recent years, prior to COVID-19, capacity shortfalls in airspace and airports inevitably caused an increase in aircraft delays. Therefore, when it returns to normal conditions, the airspace will exhibit the same capacity limits, even under normal weather conditions. To ensure that air traffic remains safe, reliable, and efficient in adverse weather conditions, planning and coordination activities through a Collaborative Decision Making process are required to deliver the most effective Air Traffic Flow and Capacity Management services to Air Traffic Control and Aircraft Operators. Nowadays, this task is based on air traffic controllers’ experience and historical data. That means that the Flow Manager Positions and the Network Manager operators have to process a huge amount of information, and the detection of future overloads is based on past experiences. Moreover, due to the inherent uncertainty of weather information, a reliable decision support framework is required to handle these situations as efficiently as possible. We propose a Deep Learning model able to extract the relationship between both the historical data and the implemented actions, accurately identifying the intervals of time that must be regulated. The proposed model achieves an accuracy between 80% and 90% across six traffic volumes belonging to both the MUAC and REIMS regions, a recall higher than 85%, and an F1-score higher than 0.8 in all the cases. Furthermore, the confidence-level analysis shows a really high activation when making a prediction. Finally, the SHapley Additive exPlanations method is applied to identify the most relevant input features.;2155-7209;978-1-6654-3420-1;10.1109/DASC52595.2021.9594303;Ministry of Economy, ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9594303;Air Traffic Management,ATFCM measures,weather regulations,deep learning;Training,TV,Atmospheric modeling,Europe,Regulation,Data models,Air traffic control;;;;;;22;;15-nov-21;;;IEEE;IEEE Conferences
Prediction of COVID-19 Related Information Spreading on Twitter;K. Babić, M. Petrović, S. Beliga, S. Martinčić-Ipšić, M. Pranjić, A. Meštrović;University of Rijeka,Department of Informatics,Rijeka,Croatia,51000, University of Rijeka,Department of Informatics,Rijeka,Croatia,51000, University of Rijeka,Department of Informatics,Rijeka,Croatia,51000, University of Rijeka,Department of Informatics,Rijeka,Croatia,51000, Jožef Stefan International Postgraduate School,Ljubljana,Slovenia, University of Rijeka,Department of Informatics,Rijeka,Croatia,51000;2021 44th International Convention on Information, Communication and Electronic Technology (MIPRO);15-nov-21;2021;;;395;399;In this paper, we explore the influence of COVID-19 related content in tweets on their spreadability. The experiment is performed in two steps on the dataset of tweets in the Croatian language posted during the COVID-19 pandemics. In the first step, we train a feedforward neural network model to predict if a tweet is highly-spreadable or not. The trained model achieves 62.5% accuracy on the binary classification problem. In the second step, we use this model in a set of experiments for predicting the average spreadability of tweets. In these experiments, we separate the original dataset into two disjoint subsets: one composed of tweets filtered using COVID-19 related keywords and the other that contains the rest of the tweets. Additionally, we modified these two subsets by adding and removing tokens into tweets and thus making them artificially COVID-19 related or not related. Our preliminary results indicate that tweets that are semantically related to COVID-19 have on average higher spreadability than the tweets that are not semantically related to COVID-19.;2623-8764;978-953-233-101-1;10.23919/MIPRO52101.2021.9596693;Croatian Science Foundation(grant numbers:IP-CORONA-04-2061), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9596693;information spreading,neural networks,NLP,Twitter,COVID-19;COVID-19,Social networking (online),Pandemics,Blogs,Predictive models,Feedforward neural networks;feedforward neural nets,learning (artificial intelligence),natural language processing,neural nets,pattern classification,social networking (online);tweet,COVID-19 related keywords,COVID-19 related information spreading,trained model achieves,feedforward neural network model,COVID-19 pandemics,COVID-19 related content;;1;;30;;15-nov-21;;;IEEE;IEEE Conferences
A Multi-level Biosensor-based Epidemic Simulation Model for COVID-19;S. V. Balkus, H. Fang, J. Rumbut, A. Moormann, E. Boyer;Computer and Information Science, University of Massachusetts Dartmouth, North Dartmouth, MA, USA., Computer and Information Science, University of Massachusetts Dartmouth, North Dartmouth, MA, USA, and also with the Population and Quantitative Health Sciences, University of Massachusetts Chan Medical School, Worcester, MA, USA. (e-mail: HuaJulia.Fang@umassmed.edu), Computer and Information Science, University of Massachusetts Dartmouth, North Dartmouth, MA, USA, and also with the Population and Quantitative Health Sciences, University of Massachusetts Chan Medical School, Worcester, MA, USA., Division of Infectious Diseases and Immunology, University of Massachusetts Chan Medical School, Worcester, MA, USA., Department of Emergency Medicine, Brigham and Women’s Hospital, Harvard Medical School, Boston, MA, USA.;IEEE Internet of Things Journal;;2021;PP;99;1;1;In order to design effective public health policies to combat the COVID-19 pandemic, local governments and organizations must be able to forecast the expected number of cases in their area. Although researchers have developed individual models for predicting COVID-19 based on sensor data without requiring a test, less research has been conducted on how to leverage those individual predictions in forecasting virus spread for determining hierarchical predictions from the community level to the state level. The Multi-Level Adaptive and Dynamic Biosensor Epidemic Model, or m-ADBio, is designed to improve on the traditional SEIR model used to forecast the spread of COVID-19. In this study, the predictive performance of m-ADBio is examined at the state, county, and community levels through numerical experimentation. We find that the model improves over SEIR at all levels, but especially at the community level, where the m-ADBio model with sensor-based initial values yielded no statistically significant difference between the forecasted cases and the true observed data -meaning that the model was highly accurate. Therefore, the m-ADBio model is expected to provide a more timely and accurate forecast to help policymakers optimize pandemic management strategy.;2327-4662;;10.1109/JIOT.2021.3127804;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9612608;Biosensor Modeling and Analysis,Epidemic Model Simulation,COVID-19,eHealth and mHealth.;Predictive models,COVID-19,Mathematical models,Statistics,Sociology,Coronaviruses,Biological system modeling;;;;;;;IEEE;12-nov-21;;;IEEE;IEEE Early Access Articles
An Overview on Deep Leaning Application in Coronavirus (COVID-19):Diagnosis, Prediction and Effects;M. Kumari;Chandigarh University,Dept. of ECE,Mohali,Punjab,India;2021 2nd International Conference on Smart Electronics and Communication (ICOSEC);12-nov-21;2021;;;1507;1510;Recently, the coronavirus 2019 or COVID-19, which originated in China, has spread to other countries' population. It is critical to evaluate an automated detection system for rapid alternative prediction and diagnosis in order to reduce the impact of COVID-19. Because of the constant increase in cases, there are fewer COVID-19 available kits than are required for testing in hospitals. Deep learning methods are evolving to provide outstanding performance in the medical field. Deep learning inspired by brain structure is referred to as machine learning. This paper provides an overview of COVID-19’s detection applications based on deep learning. Furthermore, a comprehensive review of the literature on deep leaning in COVID-19 disease has been illustrated. The proposed research study shows that in spite of presence of issues in medical database, where the transfer method can be used effectively.;;978-1-6654-3368-6;10.1109/ICOSEC51865.2021.9591921;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9591921;Coronavirus,COVID-19,deep learning,diagnosis,predictions effects;COVID-19,Deep learning,Brain,Hospitals,Databases,Sociology,Statistics;;;;;;32;;12-nov-21;;;IEEE;IEEE Conferences
Spillover Today? Predicting Traffic Overflows on Private Peering of Major Content Providers;E. Rapaport, I. Poese, P. Zilberman, O. Holschke, R. Puzis;Telekom Innovation Laboratories and the Department of Software and Information Systems Engineering, Ben-Gurion University of the Negev, Beer Sheva, Israel, Benocs GmbH, Berlin, Germany, Telekom Innovation Laboratories and the Department of Software and Information Systems Engineering, Ben-Gurion University of the Negev, Beer Sheva, Israel, Deutsche Telekom AG, T-Labs, Berlin, Germany, Telekom Innovation Laboratories and the Department of Software and Information Systems Engineering, Ben-Gurion University of the Negev, Beer Sheva, Israel;IEEE Transactions on Network and Service Management;9-dec-21;2021;18;4;4169;4182;Large content providers and content distribution network operators usually connect with large Internet service providers (eyeball networks) through dedicated private peering. The capacity of these private network interconnects is provisioned to match the volume of the real content demand by the users. Unfortunately, in cases in which there is a surge in traffic demand, (e.g., due to trending content or massive software updates) the capacity of the private interconnect may deplete, requiring the content provider/distributor to reroute the excess traffic through transit providers. Although such overflow events are rare, they negatively impact content providers, Internet service providers, and end-users. Such impact includes unexpected delays and disruptions that reduce the quality of the user experience, as well as direct costs paid by the Internet service provider to the transit providers. In this article, we examine the problem of predicting an overflow event in order to enable content and Internet service providers to handle the excess traffic in a timely manner. We propose an ensemble of deep learning models trained to predict overflow events over a short-term horizon of 2–4 hours and predict the specific interconnections through which the excess traffic will enter the Internet service provider. Evaluated with 2.5 years (2017-2019) of traffic measurement data from a large European Internet service provider, the models were shown to successfully recall 65% of the events with precision of 51% on average. While the lockdowns imposed by the COVID-19 pandemic reduced the overflow prediction accuracy, the pandemic’s impact on the accuracy was temporary. Although the lockdown continued on and off, the performance of models trained before the pandemic regained their performance during April-May 2020.;1932-4537;;10.1109/TNSM.2021.3126643;Deutsche Telekom AG, ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9609013;Supervised learning,neural networks,predictive models,Internet,traffic control,CDN,ISP,PNI;Internet,Handover,Web and internet services,Predictive models,Task analysis,Pandemics,Deep learning;;;;;;40;IEEE;9-nov-21;;;IEEE;IEEE Journals
An Adaptable LSTM Network Predicting COVID-19 Occurrence Using Time Series Data;A. Li, N. Yadav;Academy for Technology and Computer Science Bergen County Academies,Hackensack,NJ,USA, St. John's University,Division of Computer Science, Mathematics and Science,Queens,NY,USA;2021 IEEE International Conference on Digital Health (ICDH);8-nov-21;2021;;;172;177;As the COVID-19 pandemic progresses, it has become critical for policymakers and medical officials to understand how cases are trending. Machine learning models, particularly deep learning LSTM (Long Short-Term Memory) models, may hold immense value to forecast changes in COVID-19 cases. In this paper, a novel LSTM-based architecture is proposed, developed and trained on human logistics data that includes travel patterns, visits to commercial properties, as well as historical cases, demographic, and climate data. This data includes both time series and static data allowing the LSTM to be used in both classification and regression tasks to predict COVID-19 occurrence trends. For classification, the problem is modeled as a multiclass supervised learning classification problem with varying granularity. The proposed LSTM network achieves an 81.0% F1-score outperforming conventional machine learning model benchmarks (such as the random forest model with an F1 score of 58.9<sup>%</sup>) and is comparable in performance to a time series forest model. Additionally, the LSTM model is adaptable to perform regression and predict a 14-day sliding window based on currently observed data with a mean absolute error of 0.0026. This research serves as a foundation for future work in the forecasting of COVID-19 and other similar disease outbreaks using similar temporal and static data.;;978-1-6654-1685-6;10.1109/ICDH52753.2021.00031;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9581192;Deep learning,supervised learning,LSTM,COVID-19,digital health,time-series prediction,classification;COVID-19,Training,Adaptation models,Pandemics,Time series analysis,Hidden Markov models,Computer architecture;diseases,forecasting theory,learning (artificial intelligence),neural nets,pattern classification,regression analysis,time series;adaptable LSTM network predicting COVID-19 occurrence,time series data,COVID-19 pandemic progresses,medical officials,machine learning models,deep learning LSTM models,Long Short-Term Memory,COVID-19 cases,novel LSTM-based architecture,human logistics data,historical cases,climate data,static data,COVID-19 occurrence trends,multiclass supervised learning classification problem,model benchmarks,random forest model,time series forest model,LSTM model,currently observed data,similar temporal data;;;;21;;8-nov-21;;;IEEE;IEEE Conferences
COVID-19 Mortality Prediction Using Machine Learning Techniques;L. Schirato, K. Makina, D. Flanders, S. Pouriyeh, H. Shahriar;Kennesaw State University,Department of Information Technology,Marietta,GA,USA, Kennesaw State University,Department of Information Technology,Marietta,GA,USA, Kennesaw State University,Department of Information Technology,Marietta,GA,USA, Kennesaw State University,Department of Information Technology,Marietta,GA,USA, Kennesaw State University,Department of Information Technology,Marietta,GA,USA;2021 IEEE International Conference on Digital Health (ICDH);8-nov-21;2021;;;197;202;The COVID-19 pandemic sparked our research interest to explore and design a predictive model through Machine Learning algorithms to determine risk and mortality of COVID-19 admitted patients. Using a data set with over 90,000 patient admits and 20 clinical health features, this study aims to help prioritize care on patients that have a higher risk for COVID-19 based on their bill of health. The accuracy in predicting mortality rate was 96 percent on high performing models. Research methods included data mining using WEKA, Ensemble Learning Techniques with feature tuning on the the following algorithms: Navies Bayes, Decision Trees, K-Nearest Neighbor, Support Vector Machine (SVM), Random Forrest and Multilayer Perceptron (MLP). Tuning the models was achieved through feature selection, ranking, wrapping and filtering.;;978-1-6654-1685-6;10.1109/ICDH52753.2021.00035;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9581276;Machine Learning,WEKA,COVID-19,coronavirus,SARS-CoV-2,pandemic;COVID-19,Support vector machines,Machine learning algorithms,Pandemics,Biological system modeling,Machine learning,Predictive models;;;;;;24;;8-nov-21;;;IEEE;IEEE Conferences
Dynamic Hybrid Model to Forecast the Spread of COVID-19 Using LSTM and Behavioral Models Under Uncertainty;S. M. Zandavi, T. H. Rashidi, F. Vafaee;School of Biotechnology and Biomolecular Sciences, The University of New South Wales, Sydney, NSW 2052, Australia., Research Center for Integrated Transport Innovation, School of Civil and Environmental Engineering, The University of New South Wales, Sydney, NSW 2052, Australia., School of Biotechnology and Biomolecular Sciences and the Data Science Hub, The University of New South Wales, Sydney, NSW 2052, Australia (e-mail: f.vafaee@unsw.edu.au);IEEE Transactions on Cybernetics;;2021;PP;99;1;13;To accurately predict the regional spread of coronavirus disease 2019 (COVID-19) infection, this study proposes a novel hybrid model, which combines a long short-term memory (LSTM) artificial recurrent neural network with dynamic behavioral models. Several factors and control strategies affect the virus spread, and the uncertainty arising from confounding variables underlying the spread of the COVID-19 infection is substantial. The proposed model considers the effect of multiple factors to enhance the accuracy in predicting the number of cases and deaths across the top ten most-affected countries at the time of the study. The results show that the proposed model closely replicates the test data, such that not only it provides accurate predictions but it also replicates the daily behavior of the system under uncertainty. The hybrid model outperforms the LSTM model while accounting for data limitation. The parameters of the hybrid models are optimized using a genetic algorithm for each country to improve the prediction power while considering regional properties. Since the proposed model can accurately predict the short-term to medium-term daily spreading of the COVID-19 infection, it is capable of being used for policy assessment, planning, and decision making.;2168-2275;;10.1109/TCYB.2021.3120967;School of Civil and Environmental Engineering University of New South Wales UNSW Sydney, ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9603287;Coronavirus disease 2019 (COVID-19),dynamic behavioral model,hybrid model,long short-term memory (LSTM),spread prediction;Predictive models,COVID-19,Data models,Mathematical models,Uncertainty,Logic gates,Recurrent neural networks;;;;;;;Crown;4-nov-21;;;IEEE;IEEE Early Access Articles
Time-Series Forecasting of COVID-19 Cases Using Stacked Long Short-Term Memory Networks;R. R. Maaliw, Z. P. Mabunga, F. T. Villa;College of Engineering Southern Luzon State University,Lucban,Quezon,Philippines, College of Engineering Southern Luzon State University,Lucban,Quezon,Philippines, College of Industrial Technology Southern Luzon State University,Lucban,Quezon,Philippines;2021 International Conference on Innovation and Intelligence for Informatics, Computing, and Technologies (3ICT);4-nov-21;2021;;;435;441;The extent of the COVID-19 pandemic has devastated world economies and claimed millions of lives. Timely and accurate information such as time-series forecasting is crucial for government, healthcare systems, decision-makers, and policy-implementers in managing the disease's progression. With the potential value of early knowledge to save countless lives, the research investigated and compared the capabilities and robustness of sophisticated deep learning models to traditional time-series forecasting methods. The results show that the Stacked Long Short-Term Memory Networks (SLSTM) outperforms the Exponential Smoothing (ES) and Autoregressive Integrated Moving Average (ARIMA) models for a 15-day forecast horizon. SLSTM attained a collective mean accuracy of 92.17% (confirmed cases) and 82.31% (death cases) using historical data of 419 days from March 6, 2020 to April 28, 2021 of four countries - the Philippines, United States, India, and Brazil.;;978-1-6654-4032-5;10.1109/3ICT53449.2021.9581688;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9581688;covid-19,forecasting,stacked long short-term memory networks,machine learning,pandemic,time-series;COVID-19,Technological innovation,Smoothing methods,Pandemics,Biological system modeling,Medical services,Predictive models;;;;2;;34;;4-nov-21;;;IEEE;IEEE Conferences
A Secure Internet of Healthcare Things for tackling COVID-19;F. Mohsin, W. Elmedany;College of Information Technology, University of Bahrain,Sakhir,Bahrain, College of Information Technology, University of Bahrain,Sakhir,Bahrain;2021 International Conference on Innovation and Intelligence for Informatics, Computing, and Technologies (3ICT);4-nov-21;2021;;;98;104;Tracking and monitoring systems have gained increasing attention with the rise of the COVID-19 pandemic. This paper provides a brief overview of the IoT and cognitive capabilities of the Internet of Medical Things (CIoMT) and the Internet of Healthcare Things (IoHT) for COVID-19. This paper focuses on the data acquisition phase of these applications, as it has the most constrained resources and sensors and is subjected to the challenge of heating as some sensors are directly attached to patients bodies. SIMON lightweight block cipher is used in this paper based on research conducted about the most published papers in Scopus discussing the use of lightweight cryptography to secure IoT and Wireless Body Area Network (WBAN). SIMON has more papers than AES RC5, RC6, PRESENT, and CLEFIA combined. In these papers, SIMON subjected and proved reliance on various cryptanalysis, including linear, differential, impossible differential, zero-correlation linear, and rational-XOR. WBAN and IoT applications WBAN are subjected to various security and privacy attacks, combined with limited space and power resources. Therefore, we propose to use SIMON with various configurations written in VHDL, depending on the implementation context, to maintain the privacy of patients sensitive data and sustain the required confidentiality requirement of such applications. Thus, Xilinx Vivado 2021.1 was used for verifying, synthesizing, and simulating the various configurations, i.e., SIMON scalar 128/128, 64/128 and 32/64 designs, along with 64/128 outer round pipelined and 64/128 mixed round pipelined. Therefore, xc7z010clg400-1 SoC (Zybo) FPGA is used as the board, with a Zynq-7000 device as a reference to synthesize the designs, and the performance indicators in this paper are LUTs, frequency, IOBs, and throughput-to-slice (TP/slice). Moreover, the Cadence Genus tool is used to calculate estimated battery life, area, and gate count for the scalar designs based on the modified frequencies suitable for these applications, including RTL implementations and Joules power estimator using a Samsung 28nm process. Hence, at the data acquisition level, Simon 32/64 is selected as a preferred core for implementation. It is reasonably robust from a security perspective, while still looks like a reasonable compromise and a lot smaller than the 64/128 and 128/128 and has less wasted resources on all fronts.;;978-1-6654-4032-5;10.1109/3ICT53449.2021.9581819;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9581819;cognitive IoT,healthcare,cyber security,ognitive Internet of Medical Things,Internet of Healthcare Things,WBAN;Wireless communication,COVID-19,Data acquisition,Medical services,Tools,Body area networks,Batteries;;;;;;37;;4-nov-21;;;IEEE;IEEE Conferences
Fake News Prediction On COVID Dataset Using Machine Learning;C. Rajalakshmi, T. Subika, K. Vaishali, J. Shana;Coimbatore Institute of Technology,Department of AIML,Coimbatore,India, Coimbatore Institute of Technology,Department of AIML,Coimbatore,India, Coimbatore Institute of Technology,Department of AIML,Coimbatore,India, Coimbatore Institute of Technology,Department of AIML,Coimbatore,India;2021 12th International Conference on Computing Communication and Networking Technologies (ICCCNT);3-nov-21;2021;;;1;7;Fake news is false information, nowadays these are big challenges in all types of media, especially social media. In this covid-19 pandemic situation, people are facing more problems and struggling every day. One among those problems, is fake news or false information about covid. To tackle this, we have made an attempt and created a dataset with 4200 records from social media. We analyze the outbreak of covid information and visualize them using charts and graphs and predict the fake news using three classifier machine learning models. They are passive aggressive classifiers, Naïve Bayes classifiers and Support Vector Machines.;;978-1-7281-8595-8;10.1109/ICCCNT51525.2021.9579543;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9579543;fake news detection,covid 19,support vector machine,naïve bayes classifier,passive aggressive classifier;COVID-19,Measurement,Deep learning,Machine learning algorithms,Social networking (online),Pandemics,Support vector machine classification;Bayes methods,diseases,learning (artificial intelligence),pattern classification,support vector machines;fake news prediction,COVID dataset,false information,social media,covid-19 pandemic situation,covid information,classifier machine learning models;;;;14;;3-nov-21;;;IEEE;IEEE Conferences
Predicting Covid-19 using Random Forest Machine Learning Algorithm;A. Yadav;GLA University,Mathura,India;2021 12th International Conference on Computing Communication and Networking Technologies (ICCCNT);3-nov-21;2021;;;1;6;COVID-19, also known as 2019-nCoV, is no longer a pandemic but an endemic disease that has killed many people worldwide. COVID-19 has no precise treatment or remedy at this time, but it is unavoidable to live with the disease and its implications. By quickly and efficiently screening for covid, one may determine whether or not one has COVID-19 and thus limit the financial and administrative burdens on healthcare systems. Research has shown that predictions which use many variables in order to predict the likelihood of infection have been established. Due to the world's inadequate healthcare systems, this fact places significant strain on these countries’ healthcare systems, particularly in emerging nations. While there is no proven antiviral medication method or licensed vaccine that can eliminate the COVID-19 pandemic, there are other potential options that would alleviate both healthcare systems and the economy from the weight of the virus. Non-clinical approaches like machine learning, data mining, deep learning, and other artificial intelligence approaches are among the most promising approaches for use outside of a clinical setting. To make diagnosis and prognosis for patients with the 2019-NCoV pandemic easier, use these options. Additionally, artificial intelligence systems, such as decision trees, support vector machines, artificial neural networks, and naïve Bayesian models, are validated using a positive and negative COVID-19 case dataset. To establish the degree of connection between dependent characteristics, correlation coefficients between different dependent and independent variables were investigated. During preparation, the model was trained for 80% of the time, while at the same time, it was tested for 20% of the time. Based on the success evaluation, the Random Forest had the best precision of 94.99%.;;978-1-7281-8595-8;10.1109/ICCCNT51525.2021.9580161;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9580161;Artificial Intelligence,Machine Learning,Support Vector Machine,Covid-19 Prediction;COVID-19,Support vector machines,Pandemics,Biological system modeling,Training data,Tools,Prediction algorithms;;;;;;30;;3-nov-21;;;IEEE;IEEE Conferences
Trend Analysis and Comparison Of COVID - 19 Cases Before and After Administration of Vaccine Using Machine Learning;V. Sagar, J. R. Biswas;Jaypee Institute of Information Technology,Department of Computer Science Engineering,Noida,India, Maharaja Surajmal Institute of Technology,Department of Electronics and Communication Engineering,New Delhi,India;2021 12th International Conference on Computing Communication and Networking Technologies (ICCCNT);3-nov-21;2021;;;1;7;In this study we draw a comparison between the trends in the growing cases of novel coronavirus after the administration of vaccine doses. We compare two scenarios where how the trends have changed after the vaccine has been administered and how the trend would have looked if there were no vaccines present. This study can be used to determine the early changes that the vaccines have brought about in the trends and how much reliability do they show in preventing the cases from rising further. The predictions are made using a Weibull based Long-Short- Term-Memory approach which is also being used by the National Health Service of the UK on a dataset that takes into account features like age groups, air traffic, developmental index of the country, average temperatures of a country, which are detrimental in determining the rate of infection and deaths accurately. The model is tested on data gathered from multiple countries and the results are drawn after analyzing the result for each country as an individual entity for the conclusion to be reliable. With an increasing market competition and not so long testing period given to these vaccines which have made it to the common masses we feel this study can help predict how effectively the vaccines will be able to improve immunity against this virus and is it a viable option to invest such large capital in development and purchase of these vaccines preferring it over the organically decreasing curve following the traditional methods and natural processes.;;978-1-7281-8595-8;10.1109/ICCCNT51525.2021.9579569;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9579569;Weibull Distribution,Long short-term memory,Predictive models,Vaccines,Statistics;COVID-19,Analytical models,Machine learning,Market research,Data models,Vaccines,Coronaviruses;;;;;;16;;3-nov-21;;;IEEE;IEEE Conferences
Students' Adaptability Level Prediction in Online Education using Machine Learning Approaches;M. Hasan Suzan, N. A. Samrin, A. A. Biswas, A. Pramanik;Daffodil International University,Department of CIS,Dhaka,Bangladesh, Daffodil International University,Department of CIS,Dhaka,Bangladesh, Daffodil International University,Department of CIS,Dhaka,Bangladesh, Daffodil International University,Department of CIS,Dhaka,Bangladesh;2021 12th International Conference on Computing Communication and Networking Technologies (ICCCNT);3-nov-21;2021;;;1;7;Online Education has become a buzzword since the COVID-19 hit the World. Most of the educational institutions went online to continue educational activities while developing countries like Bangladesh took a significant period of time to ensure online education at every education level. Students of several levels also faced many difficulties when they got introduced to online education. It is important for the decisionmakers of educational institutions to be informed about the effectiveness of online education so that they can take further steps to make it more beneficial for the students. Our main motivation is to contribute to this matter by analyzing the relevant factors associated with online education. In this work, we have collected students' information of all three different levels(School, College, and University) by conducting both online and physical surveys. The surveys form consists of an individual's socio-demographic factors. To get an idea about the effectiveness of online education we have applied several machine learning algorithms named Decision Tree (DT), Random Forest (RF), Naive Bayes (NB), Support Vector Machine (SVM), K-Nearest Neighbors (KNN), and also Artificial Neural Network(ANN) on our dataset to predict the adaptability level of the students to online education. Among used algorithms, the Random Forest classifier achieved the best accuracy of 89.63% and outperformed other algorithms.;;978-1-7281-8595-8;10.1109/ICCCNT51525.2021.9579741;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9579741;Online Education,Machine Learning,Prediction,Random Forest,Classification;Support vector machines,COVID-19,Machine learning algorithms,Education,Artificial neural networks,Predictive models,Prediction algorithms;;;;;;20;;3-nov-21;;;IEEE;IEEE Conferences
A COVID-19 Prediction Model Based on Neural Network;X. Zhang, H. Yan, Z. Zhang, J. Zhang, R. Zhang, F. Li;Yingkou Institute of Technology, College of Electrical Engineering,Yingkou,China, Yingkou Institute of Technology, College of Electrical Engineering,Yingkou,China, Yingkou Institute of Technology, College of Electrical Engineering,Yingkou,China, Yingkou Institute of Technology, College of Electrical Engineering,Yingkou,China, Yingkou Institute of Technology, College of Electrical Engineering,Yingkou,China, Yingkou Institute of Technology, College of Electrical Engineering,Yingkou,China;2021 IEEE International Conference on Advances in Electrical Engineering and Computer Applications (AEECA);2-nov-21;2021;;;80;84;The emergence and spread of COVID-19 has had a huge negative impact on society. The use of machine learning methods and big data technology to study the spread and development of the epidemic is a hot topic for many scholars. This paper proposes a model based on the <tex>\text{LSTM}+\text{BPNN}</tex> neural network, which predicts the development trend of the new crown epidemic through the migration data of urban population flows, and proves the effectiveness of the model through a large number of experiments.;;978-1-6654-3561-1;10.1109/AEECA52519.2021.9574278;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9574278;COVID-19 neural network,machine Learning;COVID-19,Training,Epidemics,Analytical models,Recurrent neural networks,Neural networks,Time series analysis;;;;;;9;;2-nov-21;;;IEEE;IEEE Conferences
Forecasting Recessions in the US Economy Using Machine Learning Methods;N. Zyatkov, O. Krivorotko;Institute of Computational Mathematics and Mathematical Geophysics SB RAS,Novosibirsk,Russia, Institute of Computational Mathematics and Mathematical Geophysics SB RAS,Novosibirsk,Russia;2021 17th International Asian School-Seminar Optimization Problems of Complex Systems (OPCS);2-nov-21;2021;;;139;146;A quantitative analysis of socio-economic characteristics, the set of which is typical in the pre-crisis periods of a market economy, is carried out. An indicator for forecasting the onset of a recession in the US economy over the next 6, 12 and 24 months has been constructed using machine learning methods (k-nearest neighbors, support vector machine, fully connected neural network, LSTM neural network, etc.). Using roll forward cross-validation, it is shown that the smallest error in predicting the onset of future recessions was obtained by a fully connected neural network. It is also shown that all three constructed indicators successfully predict the onset of each of the last six recessions that occurred in the United States from 1976 to 2021 (Early 1980s recession, Recession of 1981–82, Early 1990s recession, .COM bubble recession, Great Recession, COVID-19 recession). The resulting indicators can be used to assess future economic activity in the United States using current macroeconomic indicators.;;978-1-6654-0562-1;10.1109/OPCS53376.2021.9588678;Russian Science Foundation, ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9588678;recession,financial crisis,US economy,machine learning,deep learning,socio-economic processes;Support vector machines,Deep learning,COVID-19,Statistical analysis,Neural networks,Macroeconomics,Forecasting;;;;;;13;;2-nov-21;;;IEEE;IEEE Conferences
A Spatiotemporal Bidirectional Attention-Based Ride-Hailing Demand Prediction Model: A Case Study in Beijing During COVID-19;Z. Huang, D. Wang, Y. Yin, X. Li;Business School, Sichuan University, Chengdu 610064, China., Business School, Sichuan University, Chengdu 610064, China., School of Management and Economics, University of Electronic Science and Technology of China, Chengdu 611731, China., School of Economics and Management, Beijing University of Chemical Technology, Beijing 100029, China (e-mail: lixiang@mail.buct.edu.cn);IEEE Transactions on Intelligent Transportation Systems;;2021;PP;99;1;12;The COVID-19 pandemic has severely affected urban transport patterns, including the way residents travel. It is of great significance to predict the demand of urban ride-hailing for residents' healthy travel, rational platform operation, and traffic control during the epidemic period. In this paper, we propose a deep learning model, called MOS-BiAtten, based on multi-head spatial attention mechanism and bidirectional attention mechanism for ride-hailing demand prediction. The model follows the encoder-decoder framework with a multi-output strategy for multi-steps prediction. The pre-predicted result and the historical demand data are extracted as two aspects of bidirectional attention flow, so as to further explore the complicated spatiotemporal correlations between the historical, present and future information. The proposed model is evaluated on the real-world dataset during COVID-19 in Beijing, and the experimental results demonstrate that MOS-BiAtten achieves a better performance compared with the state-of-art methods. Meanwhile, another dataset is used to verify the generalization performance of the model.;1558-0016;;10.1109/TITS.2021.3122541;National Natural Science Foundation of China(grant numbers:71722007,71931001,72171161,71971041,71871148), Outstanding Young Scientific and Technological Talents Foundation of Sichuan Province(grant numbers:20JCQN0281), Sichuan University to Building a World-Class University(grant numbers:SKSYL2021-08), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9597476;Bidirectional attention mechanism,attention mechanism,deep learning,short-term ride-hailing demand forecasting,multi-steps ahead prediction.;Predictive models,Spatiotemporal phenomena,Correlation,Deep learning,Epidemics,COVID-19,Neural networks;;;;;;;IEEE;1-nov-21;;;IEEE;IEEE Early Access Articles
Telerehabilitation with Exoskeletons using Adaptive Robust Integral RBF-Neural-Network Impedance Control under Variable Time Delays;G. Bauer, Y. -J. Pan;Dalhousie University,Department of Mechanical Engineering,Halifax,Canada, Dalhousie University,Department of Mechanical Engineering,Halifax,Canada;2021 IEEE 30th International Symposium on Industrial Electronics (ISIE);1-nov-21;2021;;;1;6;With an unprecedented increase in the global aging population and with it, the age-related neuromuscular dysfunction diseases, there is an exorbitant and escalating need for physical rehabilitation. Delivering these services - especially to those that are most vulnerable - under the current COVID-19 pandemic restriction for physical-distancing, is an even greater challenge. Interest in telerehabilitation is spiking, and robotic tel-erehabilitation could drastically improve patients' access to care. Some of the major challenges in developing the control methods for these robots are identifying, estimating, and overcoming the effects of dynamic modeling uncertainties, nonlinearities, and disturbances. Having humans in the loop creates the additional need for safety and compliance. Telerehabilitation control methods have the added requirement of delivering telepresence and addressing communication delays which, if not managed, could result in ineffective therapy, destabilize the system, and even cause injury. In this paper, we present a novel adaptive robust integral Radial Basis Function Neural Network Impedance model (RBFNN-I) control method for telerehabilitation with robotic exoskeletons which compensates for dynamic modeling uncertainties in the presence of external human torques and time delays. One of the salient features of the proposed control system is the implementation of a new human torque regulator which improves telepresence. Stability proof using Lyapunov stability theory is shown for the proposed control method. An exoskeleton was designed and used for unilateral and bilateral telerehabilitation simulations. Excellent tracking performance, telepresence and stability was achieved in the presence of large, variable and asymmetric time delays and human torques.;2163-5145;978-1-7281-9023-5;10.1109/ISIE45552.2021.9576228;Natural Sciences and Engineering Research Council of Canada (NSERC), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9576228;Radial basis function neural networks,Exoskeletons,Teleoperators,Telerobotics,Patient rehabilitation,Telepresence,Human-robot interaction;Adaptation models,Torque,Telepresence,Uncertainty,Regulators,Delay effects,Exoskeletons;;;;1;;32;;1-nov-21;;;IEEE;IEEE Conferences
COVID 19 Mortality Rate Prediction based on Machine Learning Methods;Z. Xiao;Columbia University,Department of Applied Analytics,New York City,US;2021 IEEE International Conference on Computer Science, Electronic Information Engineering and Intelligent Control Technology (CEI);29 Oct 2021;2021;;;169;177;In this work, the mortality rate of COVID-19 patients was predicted based on the dataset from surveillance public database, which included date of cases reported from Dec 31, 2019 to Dec 1, 2020 from the Centers for Disease Control and Prevention (CDC). The dataset contained all cases with an initial report date, current status and summary of personal patients' information tables. In this research, attributes are analyzed in terms of age groups, case demographic, whether patient hospitalized, whether patient admitted to intensive care unit (ICU) to present a model, which could precisely predict the death probability of patients who have COVID-19. We implemented lots of pre-processing for this dataset such as filling in both the missing value and unknown value in the tuple. Furthermore, we inspected the dataset from gender, age group, race and ethnicity to discover how important that the element related to the death probability. We applied the machine learning method to develop five forecasting models to predict the mortality rate of reported COVID-19 patients because machine learning algorithms have already shown their importance to enhance precision of decision making. We had implemented logistic regression, decision tree, neural network and light GBM in order to anticipate potential threatening factors of death rate of COVID-19. The results proved that the Light GBM had the best predictability in all of five standard supervised learning models, also neural network and logistic regression models performed well in predicting death rate in the reported case from Centers for Disease Control and Prevention (CDC), while decision tree model performed not as well as other methods in this COVID-19 case report dataset. From the figure of feature importance of light GBM, it was shown that age group and whether admitted to intensive care unit have larger impacts on death probability.;;978-1-6654-3881-0;10.1109/CEI52496.2021.9574541;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9574541;Mortality Rate,COVID-19,Machine Learning,Light GBM;COVID-19,Surveillance,Senior citizens,Supervised learning,Machine learning,Predictive models,Statistics;;;;;;9;;29 Oct 2021;;;IEEE;IEEE Conferences
Electricity Anomaly Point Detection using Unsupervised Technique Based on Electricity Load Prediction Derived from Long Short-Term Memory;N. S. M. Salleh, M. Saripuddin, A. Suliman, B. N. Jørgensen;College of Computing and Informatics, Universiti Tenaga Nasional,Kajang,Selangor, College of Computing and Informatics, Universiti Tenaga Nasional,Kajang,Selangor, College of Computing and Informatics, Universiti Tenaga Nasional,Kajang,Selangor, Center for Energy Informatics, Mærsk Mc-Kinney Møller Institutte,Odense,Denmark;2021 2nd International Conference on Artificial Intelligence and Data Sciences (AiDAS);27 Oct 2021;2021;;;1;5;Electricity theft caused a major loss for electricity power provider. The anomaly detection helps to predict the abnormal load usage of a consumer. Usually, the classification method used in anomaly detection. This research paper proposed to identify the potential anomaly points by using threshold and outliers. The prediction in time-series applied Long Short-Term Memory (LSTM) algorithm. The historical electricity load dataset of a single industrial consumer was used to generate the prediction of electricity load. There were five optimizers used to produce the model: Adam, Adadelta, Adagrad, RMSProp, and Stochastic gradient descent (SGD). The prediction model was evaluated using mean squared error (MSE) and mean absolute error (MAE). The best model among all five models was generated by Adadelta optimizer with the error rate value of 0.091982 for MSE and 0.018433 for MAE. The prediction values were generated by this model. The anomaly point was detected by using threshold and outliers. The threshold value was 0.218983. One week in August 2019 was chosen to detect any anomaly load occurrences. There were 24 outliers were found within the selected week. The study shall expand on the electricity usage trend during COVID-19 pandemic period.;;978-1-6654-1726-6;10.1109/AiDAS53897.2021.9574184;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9574184;Electricity load,regression,long short-term memory,anomaly detection;COVID-19,Pandemics,Stochastic processes,Predictive models,Prediction algorithms,Market research,Mathematical models;electricity,gradient methods,load forecasting,mean square error methods,power engineering computing,recurrent neural nets,stochastic processes,time series;electricity anomaly point detection,electricity load prediction,electricity theft,electricity power provider,potential anomaly points,historical electricity load dataset,single industrial consumer,stochastic gradient descent,prediction model,mean squared error,mean absolute error,Adadelta optimizer,error rate value,threshold value,anomaly load occurrences,electricity usage trend,time-series applied long short-term memory algorithm,COVID-19 pandemic period;;;;31;;27 Oct 2021;;;IEEE;IEEE Conferences
Sensitivity Analysis of Coronary Heart Disease using Two Deep Learning Algorithms CNN & RNN;M. J. Nwonye, V. L. Narasimhan, Z. A. Mbero;University of Botswana,Plot 4775 Notwane Road,Gaborone,Botswana,P/Bag UB 0022, University of Botswana,Plot 4775 Notwane Road,Gaborone,Botswana,P/Bag UB 0022, University of Botswana,Plot 4775 Notwane Road,Gaborone,Botswana,P/Bag UB 0022;2021 IST-Africa Conference (IST-Africa);26 Oct 2021;2021;;;1;10;Heart disease is one of the major causes of death with a rate of 17.9 million per year of which 85% of them are due to heart attack and stroke, with more than 75% of deaths occurring in Third world countries. Lifestyle, lack of exercise, and unhealthy diet are the main reasons why people get heart diseases resulting in them going to the hospital or medical centres for treatment. Risk factors, including hypertension, diabetes, smoking, and excessive consumption of alcohol, are a threat to heart-related disease. This paper describes a diagnostic model constructed using a series of sensitivity analyses over two deep learning algorithms, namely, Recurrent Neural Network (RNN) and Convolutional Neural Network (CNN). The sensitivity analysis is performed on the Number Of Input Layers (NOIL), perturbation over Training Vs Testing ratio, and the number of epochs. Features selected are based on the risk factors of coronary heart disease on the dataset from the database Kaggle. The result of the sensitivity analysis indicates that the RNN model yields an accuracy value of 89.4% when the dataset is split into 80:20, whereas the CNN model yields an accuracy value of 87.9% when the dataset is split into 75:25 to predict whether or not a person would have the disease in ten years. The analysis would help detect and facilitate the diagnosis of coronary heart diseases at an early stage.;2576-8581;978-1-905824-67-0;;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9576946;Heart disease,Coronary heart disease,CNN,RNN,NOIL,Perturbation analysis,Number of epochs.;Heart,Analytical models,Recurrent neural networks,Sensitivity analysis,Hospitals,Perturbation methods,Predictive models;;;;;;24;;26 Oct 2021;;;IEEE;IEEE Conferences
Multivariate Long And Short Term LSTM-Based Network for Traffic Forecasting Under Interference: Experiments During COVID-19;M. -J. Tsai, H. -Y. Chen, Z. Cui, Y. Wang;University of Washington,Department of Civil and Environmental Engineering,Seattle,WA, University of Washington,Department of Civil and Environmental Engineering,Seattle,WA, University of Washington,Department of Civil and Environmental Engineering,Seattle,WA, University of Washington,Department of Civil and Environmental Engineering,Seattle,WA;2021 IEEE International Intelligent Transportation Systems Conference (ITSC);25 Oct 2021;2021;;;2169;2174;Due to COVID-19, work-from-home policy and travel restrictions were taken to decelerate the virus spreading. While these policies successfully eliminated the transmission of COVID-19, original traffic patterns have been completely disrupted, including considerable reductions in travel time and vehicle miles traveled. The impacted traffic patterns from the unexpected event brings challenges to the U.S. Department of Transportation and transportation planners. With fluctuated traffic conditions, it is difficult for transportation agencies to learn representative traffic patterns from short-term historical data. Therefore, we proposed a multivariate long and short-term LSTM-based model (var LS-LSTM) for network-wide traffic forecasting under interference. We considered multiple spatial and temporal features to evaluate network-wide traffic performance and forecast the influenced travel behaviors. Multi-dimensional spatial-temporal features were fused into long-term and short-term historical matrices and fed into the model, which enabled the model to accommodate intervention from unexpected events. Thorough experiments were conducted using loop detector data in the Greater Seattle Area from 2020 to early 2021 and achieved reliable prediction performance in both robustness as well as accuracy. The proposed model showed competitiveness against other state-of-art algorithms in all experiment time frames, from pre-COVID-19 to COVID-19-relieving period. This study would benefit government agencies and the general public in making sustainable policies and future resilience plans for post-pandemic smart cities.;;978-1-7281-9142-3;10.1109/ITSC48978.2021.9565118;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9565118;;COVID-19,Smart cities,Transportation,Interference,Predictive models,Traffic control,Prediction algorithms;;;;;;24;;25 Oct 2021;;;IEEE;IEEE Conferences
Ambient Assisted Living for Elderly Care and Monitoring in COVID-19 Pandemic;S. Bhowmick, T. Ferdous, R. Momtaz, M. G. Rabiul Alam;Brac University,Department of Computer Science and Engineering,Dhaka,Bangladesh, Brac University,Department of Computer Science and Engineering,Dhaka,Bangladesh, Brac University,Department of Computer Science and Engineering,Dhaka,Bangladesh, Brac University,Department of Computer Science and Engineering,Dhaka,Bangladesh;2021 4th International Conference on Information and Communications Technology (ICOIACT);20 Oct 2021;2021;;;98;103;In late 2019, a novel Coronavirus broke out from China, which has dispersed all over the globe and has taken away countless lives. Despite the fact that every person is at risk of getting infected with the virus, older people are more likely to fall victim to the virus due to their declining immune systems. Although there has been significant development of vaccines, it is seen that the mutation of the COVID-19 has made it tough to control with the medication available. Due to an uncountable number of Coronavirus strains, many countries are now facing several waves of the pandemic. Assisted living technologies are evolving with time to give people a better life. This technology can be used for older people in Coronavirus pandemic situations as most of the older people have physical and cognitive impairments. In this paper, we have proposed an Internet of Things(IoT)-architectured system incorporated with Artificial intelligence and deep learning that can help diagnose COVID-19 in older people. The proposed architecture will collect all the data from different medical IoT sensors and relay them to the cloud, where the system will process and help us monitor the health of older people. This information could be seen from a dedicated dashboard where the user would be able to get diagnosis status of COVID-19 by our system. In order to be prepared for any future pandemic, this type of system will be beneficial.;;978-1-6654-3394-5;10.1109/ICOIACT53268.2021.9564005;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9564005;COVID-19,Ambient Assisted Living,Deep Learning,Artificial Intelligence,Sensor,Prediction,Monitoring,Linear Regression Analysis,Hidden Markov Model,XGBoost,SVM,ESP32,Raspberry Pi,Health Informatics;COVID-19,Deep learning,Ambient assisted living,Pandemics,Senior citizens,Coronaviruses,Vaccines;artificial intelligence,assisted living,diseases,geriatrics,health care,Internet of Things,microorganisms,patient care;ambient assisted,COVID-19 pandemic,countless lives,virus,older people,declining immune systems,Coronavirus strains,assisted living technologies,Coronavirus pandemic situations;;;;23;;20 Oct 2021;;;IEEE;IEEE Conferences
Jointly Prediction of Activities, Locations, and Starting Times for Isolated Elderly People;A. Chaudhary, R. Mishra, H. P. Gupta, K. K. Shukla;Government Engineering College Ajmer, 231264 Ajmer, Rajasthan, India, 305001 (e-mail: atul.chaudhary82@gmail.com), CSE, Indian Institute of Technology BHU Varanasi, 79203 Varanasi, India, 221005 (e-mail: rahulmishra.rs.cse17@iitbhu.ac.in), CSE, IIT BHU, 79203 Varanasi, India, 221005 (e-mail: hprabhatgupta@gmail.com), varanasi, India, (e-mail: kkshukla.cse@iitbhu.ac.in);IEEE Journal of Biomedical and Health Informatics;;2021;PP;99;1;1;Restrictive public health measures such as isolation and quarantine have been used to reduce the pandemic viruss transmission. With no proper treatment, older adults have been specifically advised to stay home, given their vulnerability to COVID-19. This pandemic has created an increasing need for new and innovative assistive technologies capable of easing the lives of people with special needs. Smart home systems have become widely popular in providing such assistive services to isolated older adults. These systems can provide better services to assist older people if it anticipates what activities inhabitants will perform ahead of time. For example, a smart home can prompt inhabitants to initiate essential activities like taking medicine using activity prediction. This paper proposes a multi- task activity prediction system that jointly predicts labels, lo- cations, and starting times of future activities. The observed sequence of previous activities characterizes future activities. We use body activity information from wearable sensors and motion information from passive environmental sensors to sense activities of daily living of older adults. The activity prediction system consists of recurrent neural networks to capture temporal dependencies. This work also carries out several experiments on collected and existing real datasets to evaluate the systems performance.;2168-2208;;10.1109/JBHI.2021.3121296;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9580533;Activity prediction,smart home,pattern mining,deep learning;Task analysis,Intelligent sensors,Smart homes,Feature extraction,COVID-19,Temperature sensors,Predictive models;;;;;;;IEEE;19 Oct 2021;;;IEEE;IEEE Early Access Articles
Improving Neural Networks for Time-Series Forecasting using Data Augmentation and AutoML;I. Y. Javeri, M. Toutiaee, I. B. Arpinar, J. A. Miller, T. W. Miller;University of Georgia,Department of Computer Science,Athens,Georgia, University of Georgia,Department of Computer Science,Athens,Georgia, University of Georgia,Department of Computer Science,Athens,Georgia, University of Georgia,Department of Computer Science,Athens,Georgia, University of Georgia,Department of Computer Science,Athens,Georgia;2021 IEEE Seventh International Conference on Big Data Computing Service and Applications (BigDataService);18 Oct 2021;2021;;;1;8;Statistical methods such as the Box-Jenkins method for time-series forecasting have been prominent since their development in 1970. Many researchers rely on such models as they can be efficiently estimated and also provide interpretability. However, advances in machine learning research indicate that neural networks can be powerful data modeling techniques, as they can provide higher accuracy for a plethora of learning problems and datasets. In the past, they have been tried on time-series forecasting as well, but their overall results have not been significantly better than the statistical models especially for intermediate length times-series data. Their modeling capacities are limited in cases where enough data may not be available to estimate the large number of parameters that these non-linear models require. This paper presents an easy to implement data augmentation method to significantly improve the performance of such networks. Our method, Augmented-Neural-Network, which involves using forecasts from statistical models, can help unlock the power of neural networks on intermediate length time-series and produces competitive results. It shows that data augmentation, when paired with Automated Machine Learning techniques such as Neural Architecture Search, can help to find the best neural architecture for a given time-series. Using the combination of these, demonstrates significant enhancement in the forecasting accuracy of three neural network-based models for a COVID-19 dataset, with a maximum improvement in forecasting accuracy by 21.41%, 24.29%, and 16.42%, respectively, over the neural networks that do not use augmented data.;;978-1-6654-3483-6;10.1109/BigDataService52369.2021.00006;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9564380;statistical models,time-series forecasting,neural networks,data augmentation,AutoML,COVID-19;COVID-19,Statistical analysis,Computational modeling,Conferences,Neural networks,Machine learning,Computer architecture;;;;;;39;;18 Oct 2021;;;IEEE;IEEE Conferences
Fake News Analysis and Graph Classification on a COVID-19 Twitter Dataset;K. Gupta, K. Potika;San Jose State University,Department of Computer Science,San Jose,USA, San Jose State University,Department of Computer Science,San Jose,USA;2021 IEEE Seventh International Conference on Big Data Computing Service and Applications (BigDataService);18 Oct 2021;2021;;;60;68;In this work we aim to study the spread of fake news compared to real news in a social network. We do that by performing social network analysis to discover various characteristics, and formulate the problem as a binary classification one, where we have graphs modeling the spread of fake and real news. For our experiments we rely on how news are propagated through a popular social media service such as Twitter during the pandemic caused by the COVID-19 virus. In the past, several other approaches classify news as fake or real by deploying various graph embedding techniques and deep learning techniques.We focus on developing a dataset that contains tweets specific to COVID-19 by using the content of the tweets. Further, we create graphs of the fake and real news along with their retweets and followers and work on the graphs. We perform social network analysis and compare their characteristics. Additionally, we study the propagation of fake and real news among users using community detection algorithms on the graphs. Finally, we create a model by deploying the Weisfeiler Lehman graph kernel for graph classification on our labeled dataset. The model is able to predict whether a news article is real or fake based on how the corresponding graph of the retweets and followers are connected.;;978-1-6654-3483-6;10.1109/BigDataService52369.2021.00013;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9564094;Graph kernels,community detection,COVID-19,Weisfeiler Lehman kernel,graph classification,fake news;COVID-19,Deep learning,Social networking (online),Pandemics,Conferences,Blogs,Predictive models;graph theory,learning (artificial intelligence),pattern classification,social networking (online);graph classification,COVID-19 Twitter dataset,social network analysis,popular social media service,COVID-19 virus,graph embedding techniques,Weisfeiler Lehman graph kernel,news article,corresponding graph,fake news analysis;;1;;19;;18 Oct 2021;;;IEEE;IEEE Conferences
Statistical Analytics and Regional Representation Learning for COVID-19 Pandemic Understanding;S. Fazeli, B. Moatamed, M. Sarrafzadeh;University of California, Los Angeles (UCLA), University of California, Los Angeles (UCLA), University of California, Los Angeles (UCLA);2021 IEEE 9th International Conference on Healthcare Informatics (ICHI);15 Oct 2021;2021;;;248;257;The rapid spread of the novel coronavirus (COVID-19) has severely impacted almost all countries around the world. It not only has caused a tremendous burden on health-care providers to bear, but it has also brought severe impacts on the economy and social life. The presence of reliable data and the results of in-depth statistical analyses provide researchers and policymakers with invaluable information to understand this pandemic and its growth pattern more clearly. This paper combines and processes an extensive collection of publicly available datasets to provide a unified information source for representing geographical regions with regards to their pandemic-related behavior. The features are grouped into various categories to account for their impact based on the higher-level concepts associated with them. This work uses several correlation analysis techniques to observe value and order relationships between features, feature groups, and COVID-19 occurrences. Dimensionality reduction techniques and projection methodologies are used to elaborate on individual and group importance of these representative features. A specific RNN-based inference pipeline called DoubleWindowLSTM-CP is proposed in this work for predictive event modeling. It utilizes sequential patterns and enables concise record representation while using but a minimal amount of historical data. The quantitative results of our statistical analytics indicated critical patterns reflecting on many of the expected collective behavior and their associated outcomes. Predictive modeling with DoubleWindowLSTM-CP instance exhibits efficient performance in quantitative and qualitative assessments while reducing the need for extended and reliable historical information on the pandemic.;2575-2634;978-1-6654-0132-6;10.1109/ICHI52183.2021.00047;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9565762;machine learning,COVID-19,statistics,infectious disease,spatiotemporal representations,data science;COVID-19,Dimensionality reduction,Pandemics,Statistical analysis,Pipelines,Medical services,Predictive models;data preparation,health care,learning (artificial intelligence),medical computing,recurrent neural nets,statistical analysis;statistical analytics,regional representation learning,COVID-19 pandemic understanding,novel coronavirus,health-care providers,social life,in-depth statistical analyses,policymakers,growth pattern,unified information source,geographical regions,pandemic-related behavior,higher-level concepts,correlation analysis techniques,order relationships,feature groups,COVID-19 occurrences,dimensionality reduction techniques,individual group importance,representative features,specific RNN-based inference pipeline,predictive event modeling,sequential patterns,historical data,critical patterns,expected collective behavior,DoubleWindowLSTM-CP,historical information reliability,qualitative assessments,quantitative assessments;;;;39;IEEE;15 Oct 2021;;;IEEE;IEEE Conferences
The effect of COVID-19 on garlic prices;L. Lianlian, Z. Chao, W. Junmei, Z. Qing, L. Pingzeng, L. Chenyang, S. Yifei;Shandong Agricultural University,College of Information Science and Engineering,Taian,China, Shandong Agricultural University,College of Information Science and Engineering,Taian,China, Shandong Agricultural University,College of Information Science and Engineering,Taian,China, Xi ’an University of Science and Technology,College of energy,Xi ’an,China, Shandong Agricultural University,College of Information Science and Engineering,Taian,China, Shandong Agricultural University,College of Information Science and Engineering,Taian,China, Shandong Agricultural University,College of Information Science and Engineering,Taian,China;2021 IEEE International Conference on Smart Internet of Things (SmartIoT);12 Oct 2021;2021;;;322;326;This paper studied the impact of COVID-19 on garlic price and found a model with high accuracy to predict garlic price to provide reference for relevant personnel in the garlic industry. Through the analysis of the average weekly price of garlic over the years, and analysis of garlic prices at specific time points since the outbreak in 2020. It was found that the outbreak had a relatively large impact on garlic prices, which kept garlic prices low relative to previous years. In order to better respond to emergencies. Therefore, it is particularly important to find a better forecasting model for garlic price prediction. It can provide a reference for people engaged in garlic industry. The CEEDMAN-LSTM combined model is used to forecast the average weekly garlic price in 2020, and the prediction results show that the model is suitable for the prediction of garlic price.;;978-1-6654-4511-5;10.1109/SmartIoT52359.2021.00058;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9556156;COVID–19,Garlic price,LSTM model,CEEDMAN-LSTM combination model;Industries,Agricultural products,Fluctuations,Transportation,Predictive models,Market research;agricultural products,economic forecasting,epidemics,forecasting theory,pricing,recurrent neural nets;COVID-19,garlic industry,garlic price prediction,CEEDMAN-LSTM combined model,average weekly garlic price forecasting;;;;11;;12 Oct 2021;;;IEEE;IEEE Conferences
Deep Reinforcement Learning Interdependent Healthcare Critical Infrastructure Simulation model for Dynamically Varying COVID-19 scenario - A case study of a Metro City;G. Srikanth, N. Nukavarapu, S. Durbha;Centre of Studies in Resources Engineering, Indian Institute of Technology Bombay,Mumbai,India, Centre of Studies in Resources Engineering, Indian Institute of Technology Bombay,Mumbai,India, Centre of Studies in Resources Engineering, Indian Institute of Technology Bombay,Mumbai,India;2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS;12 Oct 2021;2021;;;8499;8502;Inability to respond to the growing trend of COVID -19 cases and the study and analysis of Healthcare Critical Infrastructure interdependencies during COVID-19 pandemic scenario is relatively new. One of the most frequently identified shortfalls in knowledge related to enhancing Healthcare Critical Infrastructure (HCI) preparedness during the COVID-19 pandemic scenario is the inability to forecast the growth trend of COVID-19 cases in a geographic area and incomplete understanding of interdependencies between Critical infrastructures related to HCI. As the number of cases surges at a healthcare facility, the facility, and its interdependent CI services should be prepared to handle the susceptible stress. The goal of the paper is to be able to predict the growth trend of COVID-19 cases using Spatiotemporal Long Short-Term Memory (ST-LSTM) for a geographic area. Based on the predicted growth trend of the COVID-19 cases a Multi-Agent Deep Reinforcement Learning (MADRL) simulation model will provide an accurate representation of healthcare critical infrastructure characteristics, operations, and interdependencies services. The Real-time information simulation would help frontline workers, government agencies, and disaster and emergency response personnel to respond to the question, ‘what if something else happens during the COVID-19 Pandemic?;2153-7003;978-1-6654-0369-6;10.1109/IGARSS47720.2021.9554875;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554875;Covid-19,ST-LSTM,Deep Reinforcement learning,Healthcare Critical Infrastructure,Geographic Information system;COVID-19,Human computer interaction,Pandemics,Medical services,Reinforcement learning,Predictive models,Market research;computer simulation,critical infrastructures,disasters,emergency services,epidemics,health care,learning (artificial intelligence),multi-agent systems,personnel;deep reinforcement learning interdependent healthcare critical infrastructure simulation model,dynamically varying COVID-19 pandemic scenario,Metro City,healthcare critical infrastructure preparedness,HCI,geographic area,susceptible stress,COVID-19 case growth trend prediction,ST-LSTM,multiagent deep reinforcement learning simulation model,MADRL,frontline workers,government agencies,disaster response personnel,emergency response personnel;;;;8;;12 Oct 2021;;;IEEE;IEEE Conferences
Convolutional LSTM Network for forecasting correlations between stocks based on spatiotemporal sequence;J. Sun, Y. Jiang, J. Lin;Tsinghua Shenzhen International,Graduate School,Shenzhen,China, Tsinghua Shenzhen International,Graduate School,Shenzhen,China, Tsinghua Shenzhen International,Graduate School,Shenzhen,China;2021 IEEE 19th International Conference on Industrial Informatics (INDIN);11 Oct 2021;2021;;;1;6;The correlation between stocks is important for investment portfolio pricing and evaluation, risk management, and formulating trading and hedging strategies. The COVID-19 has led to a general increase in the degree of correlation between stocks, the market-wide allocation has lost its meaning, and the hedging strategy has failed. It is more necessary and urgent to predict the correlation between stocks under the influence of the epidemic. However, previous studies mostly focused on traditional financial models. There are problems such as too many assumptions and restrictions, the dimensional disaster of the estimated parameters, and the poor effect of fitting nonlinearity and tail risk, which cannot provide reliable and accurate estimates. In this paper, the covariance matrix for stock return is considered as a sequence with both time and space characteristics, to transform the problem into the study of spatiotemporal sequence prediction. We Innovatively apply the end-to-end Convolutional LSTM (ConvLSTM) to the correlation prediction between stocks and use random matrix theory (RMT) to improve mean squared error (MSE) to eliminate the influence of noise. Experiments show that the performance of ConvLSTM on this problem is better than that of traditional financial model, especially after de-nosing by Random Matrix Theory (RMT). Compared with Fully Connected LSTM (FC-LSTM), ConvLSTM acquired a better out-of-sample MSE and RMT_MSE, which proves the effectiveness of the method. Finally, we repeat experiments with other stock dataset to verify the robustness of the model.;;978-1-7281-4395-8;10.1109/INDIN45523.2021.9557538;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9557538;ConvLSTM,stock correlation prediction,spatiotemporal,random matrix theory,Multiple-factor model;Correlation,Transforms,Pricing,Predictive models,Robustness,Spatiotemporal phenomena,Risk management;covariance matrices,diseases,estimation theory,investment,mean square error methods,pricing,recurrent neural nets,risk management,spatiotemporal phenomena,stock markets;convolutional LSTM network,investment portfolio pricing,risk management,formulating trading,hedging strategies,market-wide allocation,hedging strategy,financial model,reliable estimates,spatiotemporal sequence prediction,correlation prediction,random matrix theory,stock dataset,forecasting correlations between stocks,COVID-19,financial models,dimensional disaster,estimate parameters,covariance matrix,space characteristics,end-to-end convolutional LSTM,mean squared error,MSE,RMT;;;;20;;11 Oct 2021;;;IEEE;IEEE Conferences
Deep Learning with hyper-parameter tuning for COVID-19 Cough Detection;S. Rao, V. Narayanaswamy, M. Esposito, J. Thiagarajan, A. Spanias;Arizona State University,SenSIP Center,Tempe,AZ,85287, Arizona State University,SenSIP Center,Tempe,AZ,85287, Arizona State University,SenSIP Center,Tempe,AZ,85287, Lawrence Livermore National Labs, Arizona State University,SenSIP Center,Tempe,AZ,85287;2021 12th International Conference on Information, Intelligence, Systems & Applications (IISA);8 Oct 2021;2021;;;1;5;As the COVID-19 pandemic continues, rapid non-invasive testing has become essential. Recent studies and benchmarks motivates the use of modern artificial intelligence (AI) tools that utilize audio waveform spectral features of coughing for COVID-19 diagnosis. In this paper, we describe the system we developed for COVID-19 cough detection. We utilize features directly extracted from the coughing audio and use deep learning algorithms to develop automated diagnostic tools for COVID-19. In particular, we develop a unique modification of the VGG13 deep learning architecture for audio analysis that uses log-mel spectrograms and a combination of binary cross entropy and focal losses. This unique modification enabled the model to achieve highly robust classification of the DiCOVA 2021 COVID-19 data. We also explore the use of data augmentation and an ensembling strategy to further improve the performance on the validation and the blind test datasets. Our model achieved an average validation AUROC of 82.23% and a test AUROC of 78.3% at a sensitivity of 80.49%.;;978-1-6654-0032-9;10.1109/IISA52424.2021.9555564;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9555564;COVID-19,acoustics,machine learning,respiratory diagnosis,healthcare;COVID-19,Deep learning,Sensitivity,Pipelines,Tools,Predictive models,Feature extraction;entropy,epidemics,feature extraction,learning (artificial intelligence),medical diagnostic computing,patient diagnosis,pattern classification;unique modification,VGG13 deep learning architecture,hyperparameter tuning,noninvasive testing,artificial intelligence tools,audio waveform spectral features,coughing audio,COVID19 cough detection,log mel spectrograms,binary cross entropy,focal losses,data augmentation,DiCOVA 2021 COVID19 data;;2;;41;;8 Oct 2021;;;IEEE;IEEE Conferences
Challenges and Approaches to Time-Series Forecasting for Traffic Prediction at Data Centers;S. Jadon, A. Patankar, J. K. Milczek;Juniper Networks Inc,Sunnyvale,CA,USA, Juniper Networks Inc,Sunnyvale,CA,USA, Deepsense.ai,Sunnyvale,CA,USA;2021 International Conference on Smart Applications, Communications and Networking (SmartNets);5 Oct 2021;2021;;;1;8;Time-series forecasting has been an important research domain with significant applications, such as ECG predictions, sales forecasting, weather conditions, and recently COVID-19 spread predictions. Many researchers have investigated a multitude of modeling approaches to meet the requirements of these wide ranges of applications. In this context, our work focuses on reviewing different forecasting approaches for telemetry data collected in networks and data centers. Forecasting of telemetry data is a critical feature of network and data center management products. However, there are multiple options of forecasting approaches that range from a simple linear statistical model to high-capacity deep learning architectures. In this paper, we summarize and evaluate the performance of many well-known time series forecasting techniques. This research evaluation aims to provide a comprehensive summary for further innovation in forecasting approaches for telemetry data.;;978-1-6654-3545-1;10.1109/SmartNets50376.2021.9555422;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9555422;Time Series forecasting,capacity planning,networking,deep learning,machine learning;Deep learning,Data centers,Technological innovation,Time series analysis,Predictive models,Electrocardiography,Telemetry;computer centres,computer network management,forecasting theory,statistical analysis,telecommunication traffic,telemetry,time series;high-capacity deep learning architectures,telemetry data forecasting,time series forecasting techniques,simple linear statistical model,data center management products,telemetry data collection,forecasting approaches,traffic prediction;;;;29;;5 Oct 2021;;;IEEE;IEEE Conferences
Modelling the Case Fatality Ratio of COVID-19;V. Rema, K. Sikdar;Ramaiah Institute of Management,Department of Business Analytics & Data Science,Bengaluru,Karnataka,India, BMS Institute of Technology & Management,Department of Mathematics,Bengaluru,Karnataka,India;2021 2nd International Conference on Big Data Analytics and Practices (IBDAP);5 Oct 2021;2021;;;76;83;Mathematical modelling has been used extensively to predict COVID-19 cases across different countries. This research provides a micro perspective in understanding the progression of case fatality ratio in 20 districts of Karnataka State of India. The case fatality ratio is an indicator to suggest if the pandemic is seeing a declining trend and the focus of this study is assessing the progression of this metric. Panel data with 7060 observations, consisting of daily infected, recovered and deaths are considered from March 2020 to March 2021. Time series models of state space exponential smoothing (ETS) and Auto Regressive Integrated Moving Average (ARIMA) are applied and compared to forecast the CFR district-wise. ARIMA model performs better than the ETS model. Further, the model is validated using residual analysis. To get an overall perspective of CFR progression across the state, daily average CFR for Karnataka state is evaluated, models of ETS, ARIMA and Long Short-Term Memory (LSTM) are applied and compared. LSTM which handles long term dependencies, and ARIMA provide reliable forecasts. This study provides useful insights to the regulatory bodies to ensure strategic allocation of healthcare resources in required regions.;;978-1-6654-2841-5;10.1109/IBDAP52511.2021.9552168;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9552168;COVID-19,Case Fatality Ratio,mathematical modelling,exponential smoothing,ARIMA,LSTM;Measurement,COVID-19,Analytical models,Pandemics,Time series analysis,Sociology,Predictive models;autoregressive moving average processes,diseases,health care,regression analysis,time series;long short-term memory,residual analysis,pandemic,CFR progression,ETS model,ARIMA model,CFR district-wise,Auto Regressive Integrated Moving Average,state space exponential smoothing,time series models,COVID-19 cases,mathematical modelling,case fatality ratio;;;;16;;5 Oct 2021;;;IEEE;IEEE Conferences
Personalized Situation Adaptive Human-Vehicles-Interaction (HVI) Prediction in COVID-19 Context;N. Yin, A. K. Singh, H. Lv;Business School, Nanjing Xiaozhuang University, Nanjing 211171, China (e-mail: yinnan123456@126.com), Department of Computer Science and Engineering, National Institute of Technology, Patna, Patna 800005, India., North China Sea Offshore Engineering Survey Institute, Ministry of Natural Resources North Sea Bureau, Qingdao 266000, China.;IEEE Transactions on Intelligent Transportation Systems;;2021;PP;99;1;10;The purposes are to investigate the personalized situation adaptive Human-Computer Interaction (HCI) in the COVID-19 context, achieve accurate predictions for HCI in different urban transportation situations, and solve the urban intelligent transportation problems. Problems of Human-Vehicles-Interaction (HVI) in context awareness are analyzed. Historical traffic flow in three different situations, including novice user situation, mid user situation, and expert user situation, are taken as the data sources. The HVI data are preprocessed afterward. Next, Dilated Convolution (DC) and Long-Short Term Memory (LSTM) are integrated (DC-LSTM) to build an HVI model based on situation adaptive. The proposed model is simulated to analyze its performance. Simulation experiments suggest that the Root Mean Square Error (RMSE), Mean Absolute Error (MAE), and Mean Absolute Percentage Error (MAPE) of the proposed model are 4.64%, 5.34%, and 7.82%, respectively. Although these three metrics increase under the mid user and expert user situations, the proposed model can still provide a higher accuracy than LTSM, Convolutional Neural Network (CNN), Simple Recurrent Network (SRN), Support Vector Regression (SVR), and Multi-Layer Perceptron (MLP). Besides, the prediction velocity can maintain about 60 Frame-Per-Second (FPS) under all three user situations. Regarding the path guidance performance, the proposed model can suppress the traffic congestion and dredge the congested sections effectively. Hence, the HVI model based on situational adaptation constructed has high prediction accuracy and traffic congestion evacuation performance, which can provide an experimental basis for the later intelligent transportation field and improving situational self-adaptability.;1558-0016;;10.1109/TITS.2021.3115633;National Natural Science Foundation of China NSFC(grant numbers:61902203), Key Research and Development Pla--Major Scientific and Technological Innovation Projects of Shandong Province(grant numbers:2019JZZY020101), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9557760;COVID-19,situation adaptive,human-vehicles-interaction,transportation,prediction,DC-LSTM.;Transportation,Context-aware services,Adaptation models,COVID-19,Real-time systems,Mathematical models,Human computer interaction;;;;;;;IEEE;4 Oct 2021;;;IEEE;IEEE Early Access Articles
COVID-19 Fake News Prediction On Social Media Data;A. Ul Hussna, I. I. Trisha, M. S. Karim, M. G. R. Alam;BRAC University,Department of Computer Science and Engineering,Dhaka,Bangladesh, BRAC University,Department of Computer Science and Engineering,Dhaka,Bangladesh, BRAC University,Department of Computer Science and Engineering,Dhaka,Bangladesh, BRAC University,Department of Computer Science and Engineering,Dhaka,Bangladesh;2021 IEEE Region 10 Symposium (TENSYMP);4 Oct 2021;2021;;;1;5;It is, to tell the truth, that the COVID-19 pandemic has put the whole world in a tough time, and sensitive information concerning COVID-19 has grown tremendously online. Most importantly, the gradual spread of fake news and misleading information during these hard times can have dire consequences, causing widespread panic and exacerbating the apparent threat of a pandemic that we cannot ignore. Because of the time-consuming nature of evidence gathering and careful truth-checking, people get confused between fallacious and trustworthy statement. So, we need a way to keep track of misinformation on social media. Most people think that all social media information is real information though, at the same time, it is a shame that some people misuse this social media platform for their own benefit by spreading misinformation. Many individuals take advantage by playing with the weaknesses of others. As a result, people around the world not only are facing COVID-19, they are also facing infodemics. To get rid of this kind of fake news, we have proposed a research model that can predict fake news related to the COVID-19 issue on social media data using classical classification methods such as multinomial naïve bayes classifier, logistic regression classifier, and support vector machine classifier. Moreover, we have applied a deep learning based algorithm named distil BERT to accurately predict fake COVID-19 news. These approaches have been used in this paper to compare which technique is much more convenient for accurately predicting fake news about COVID-19 on social media posts. In addition, we have used a data-set that included 6424 social media posts.;2642-6102;978-1-6654-0026-8;10.1109/TENSYMP52854.2021.9550957;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9550957;COVID-19,distilBERT,TF-IDF,Multinomial Naïve Bayes classifier,Logistics Regression classifier,Support Vector Machine classifier,pandemic,infodemic;COVID-19,Deep learning,Social networking (online),Pandemics,Support vector machine classification,Prediction algorithms,Data models;Bayes methods,diseases,epidemics,learning (artificial intelligence),medical information systems,regression analysis,social networking (online),support vector machines;social media posts,careful truth checking,widespread panic,misleading information,sensitive information,tough time,COVID-19 pandemic,COVID-19 fake news prediction,fake COVID-19 news,social media data,COVID-19 issue,social media platform,social media information;;;;11;;4 Oct 2021;;;IEEE;IEEE Conferences
A-LSTM Model for Predicting the Deaths Caused by COVID-19 in U.S.;Y. Li, Y. Yang, C. Yang, B. Zhang;Air Force Engineering University,Fundamentals Department,Xi'an,China, Air Force Engineering University,Fundamentals Department,Xi'an,China, Air Force Engineering University,Fundamentals Department,Xi'an,China, Radar NCO School,Air Force Early Warning Academy,Wuhan,China;2021 4th International Conference on Pattern Recognition and Artificial Intelligence (PRAI);4 Oct 2021;2021;;;287;290;The epidemic caused by a new type of coronavirus has spread around the world since the end of 2019. As of March 4, 2021, over 114.65 million were infected and more than 2.55 million died, including 28.4 million confirmed cases with 0.51 million deaths in U.S. To predict the next 7-day deaths of COVID-19 in U.S. more accurately, we propose a neural network based on LSTM model with attention mechanism. Driven by the historical data provided by the COVID tracking project supported by the Atlantic, the A-LSTM model makes its prediction and its evaluation indexes of RMSE, MAPE, MAE and R-squared are 285.89, 0.0482%, 230.74 and 0.9954 respectively, which are better than the BPNN model's. The result shows that A-LSTM model we propose has a better prediction on the deaths of COVID-19 in U.S. than BPNN.;;978-1-6654-1322-0;10.1109/PRAI53619.2021.9551048;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9551048;A-LSTM,Attention mechanism,COVID-19;COVID-19,Epidemics,Obituaries,Neural networks,Predictive models,Data models,Pattern recognition;diseases,epidemics,medical computing,recurrent neural nets;A-LSTM model,COVID-19,COVID tracking project,BPNN model,epidemic,corona virus,neural network;;;;12;;4 Oct 2021;;;IEEE;IEEE Conferences
An Efficient Prediction Method for Coronary Heart Disease Risk Based on Two Deep Neural Networks Trained on Well-Ordered Training Datasets;T. Amarbayasgalan, V. -H. Pham, N. Theera-Umpon, Y. Piao, K. H. Ryu;Database and Bioinformatics Laboratory, School of Electrical and Computer Engineering, Chungbuk National University, Cheongju, South Korea, Faculty of Information Technology, Ton Duc Thang University, Ho Chi Minh City, Vietnam, Biomedical Engineering Institute, Chiang Mai University, Chiang Mai, Thailand, School of Medicine, Nankai University, Tianjin, China, Faculty of Information Technology, Ton Duc Thang University, Ho Chi Minh City, Vietnam;IEEE Access;7 Oct 2021;2021;9;;135210;135223;This study proposes an efficient prediction method for coronary heart disease risk based on two deep neural networks trained on well-ordered training datasets. Most real datasets include an irregular subset with higher variance than most data, and predictive models do not learn well from these datasets. While most existing prediction models learned from the whole or randomly sampled training datasets, our suggested method draws up training datasets by separating regular and highly biased subsets to build accurate prediction models. We use a two-step approach to prepare the training dataset: (1) divide the initial training dataset into two groups, commonly distributed and highly biased using Principal Component Analysis, (2) enrich the highly biased group by Variational Autoencoders. Then, two deep neural network classifiers learn from the isolated training groups separately. The well-organized training groups enable a chance to build more accurate prediction models. When predicting the risk of coronary heart disease from the given input, only one appropriate model is selected based on the reconstruction error on the Principal Component Analysis model. Dataset used in this study was collected from the Korean National Health and Nutritional Examination Survey. We have conducted two types of experiments on the dataset. The first one proved how Principal Component Analysis and Variational Autoencoder models of the proposed method improves the performance of a single deep neural network. The second experiment compared the proposed method with existing machine learning algorithms, including Naïve Bayes, Random Forest, K-Nearest Neighbor, Decision Tree, Support Vector Machine, and Adaptive Boosting. The experimental results show that the proposed method outperformed conventional machine learning algorithms by giving the accuracy of 0.892, specificity of 0.840, precision of 0.911, recall of 0.920, f-measure of 0.915, and AUC of 0.882.;2169-3536;;10.1109/ACCESS.2021.3116974;Basic Science Research Program through the National Research Foundation of Korea (NRF), Ministry of Science, ICT, and Future Planning(grant numbers:2019K2A9A2A06020672,2020R1A2B5B02001717), National Natural Science Foundation of China(grant numbers:61802209), Open Fund of Tianjin Central Hospital of Gynecology Obstetrics/Tianjin Key Laboratory of Human Development and Reproductive Regulation(grant numbers:2020XHY03), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9555589;Coronary heart disease,deep neural network,machine learning,principal component analysis,reconstruction error,variational autoencoder;Training,Heart,Principal component analysis,Predictive models,Diseases,Deep learning,Support vector machines;cardiology,decision trees,deep learning (artificial intelligence),diseases,medical computing,naive Bayes methods,nearest neighbour methods,pattern classification,principal component analysis,random forests,support vector machines;deep neural network classifiers,principal component analysis,single deep neural network,coronary heart disease risk,deep neural network training,well-ordered training datasets,variational autoencoder,Korean National Health,Nutritional Examination Survey,naive Bayes,random forest,k-nearest neighbor,decision tree,support vector machine,adaptive boosting;;;;41;CCBY;1 Oct 2021;;;IEEE;IEEE Journals
Smart Wearable Tag for monitoring cow using Convolutional neural network and long short-term memory;C. Nagasai, D. A. Krishna, B. J. Rani, K. S. Balamurugan;Sasi Institute of Technology and Engineering,Department of Electronics and Communication Engineering,Tadepalligudem,Andhra Pradesh,India,534101, Sasi Institute of Technology and Engineering,Department of Electronics and Communication Engineering,Tadepalligudem,Andhra Pradesh,India,534101, Sasi Institute of Technology and Engineering,Department of Electronics and Communication Engineering,Tadepalligudem,Andhra Pradesh,India,534101, Sasi Institute of Technology and Engineering,Department of Electronics and Communication Engineering,Tadepalligudem,Andhra Pradesh,India,534101;2021 Third International Conference on Inventive Research in Computing Applications (ICIRCA);1 Oct 2021;2021;;;153;158;Cattle farming is an important part of a farmer's life, and their products are becoming increasingly popular. Monitoring the food state, health condition, estrous cycle, calving time, and monitoring position of cattle are considered as the difficult challenges. With the advancement of IoT in modern farming and wearable technologies, several researchers have developed a solution for cow monitoring. The proposed approach includes a Convolutional neural network with long short-term memory, an algorithm for identifying cow behaviors, and a wearable sensor Tag for measuring biological data and monitoring the cow's location. Also, the sensed data gets stored in the cloud for analyzing the historical data and predict its future. The proposed method has observed 99.8% accuracy and also it provides the complete report when farmer needs to remotely know the health status. The proposed Wearable Tag for monitoring cow is essential to overcome the current pandemic scenario COVID-19 across the globe.;;978-1-6654-3877-3;10.1109/ICIRCA51532.2021.9544808;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9544808;Monitoring cow,Convolutional neural network,Sensors,Long short term memory;Dairy products,Pandemics,Cows,Solids,Prediction algorithms,Convolutional neural networks,Feeds;cloud computing,computerised monitoring,condition monitoring,convolutional neural nets,farming,Internet of Things,recurrent neural nets,wearable sensors;health status,smart wearable tag,convolutional neural network,short-term memory,cattle farming,farmer,food state,health condition,estrous cycle,modern farming,wearable technologies,cow monitoring,cow behaviors,wearable sensor Tag,biological data,sensed data,historical data;;;;12;;1 Oct 2021;;;IEEE;IEEE Conferences
Covid-19 Confirmed-Cases Prediction in SAARC Countries through Machine Learning;A. S. Saha, M. Haque, M. G. R. Alam;BRAC University,Department of Computer Science and Engineering,Dhaka,Bangladesh, BRAC University,Department of Computer Science and Engineering,Dhaka,Bangladesh, BRAC University,Department of Computer Science and Engineering,Dhaka,Bangladesh;2021 Third International Conference on Inventive Research in Computing Applications (ICIRCA);1 Oct 2021;2021;;;889;894;In December 2019, a new variant of the SARS virus named Severe Acute Respiratory Syndrome Coronavirus 2(SARS-CoV-2), began its outspread in Wuhan, China, and has since expanded throughout the whole planet. In this novel research, we predicted the number of confirmed cases of SARS-CoV-2 in the South Asian Association for Regional Cooperation (SAARC) Countries through the use of the numerous machine learning (ML) techniques and time series model. Furthermore, we made a comparative study on which technique performed better. The hugely popular Support Vector Machine(SVM) and Bayesian Ridge regression was taken into consideration for the predictions made. The time series analysis model, i.e. Seasonal Autoregressive Integrated Moving Average(SARIMA) model was further used to get even better predictions on the forecasts for the confirmed cases of SARS-CoV-2. Along with this, comparisons were conducted on the confirmed cases, followed by the deaths resulted from these cases, as well as on the number of recoveries made, the number of active cases, and mortality rate across these countries, from which nations were limited down to a handful that should take extreme steps to stop the virus from spreading.;;978-1-6654-3877-3;10.1109/ICIRCA51532.2021.9544964;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9544964;SARS-CoV-2,SAARC,SVM,Bayesian Ridge,SARIMA;COVID-19,Support vector machines,Deep learning,Analytical models,Planets,Pandemics,Time series analysis;autoregressive moving average processes,diseases,epidemics,health care,learning (artificial intelligence),medical computing,microorganisms,regression analysis,support vector machines,time series;SAARC countries,machine learning,SARS virus,Severe Acute Respiratory Syndrome Coronavirus 2,SARS-CoV-2,time series analysis,COVID-19 confirmed-cases prediction,South Asian Association for Regional Cooperation countries,support vector machine,Bayesian Ridge regression,autoregressive integrated moving average;;;;15;;1 Oct 2021;;;IEEE;IEEE Conferences
A COVID-19 Epidemics Trend Prediction Algorithm Based on LSTM;Y. Zhang, J. Sun;North China University of Technology,School of Information Science and Technology,Beijing,China, North China University of Technology,School of Information Science and Technology,Beijing,China;2021 IEEE 4th International Conference on Computer and Communication Engineering Technology (CCET);30-sep-21;2021;;;252;256;The polynomial regression algorithm can fit almost all data sequences by adding high-order terms of independent variables, but on long sequences, it can only reflect the development trends of the sequences, and the predicted value is not accurate enough. RNN has great advantages in predicting and fitting time sequence data, especially Long Short-Term Memory (LSTM) network has good performance in predicting long time sequence. This paper respectively adopts polynomial regression and LSTM analysis and predict the effect of epidemic prevention and control policies in various countries to control the epidemic and the economic recession. The experiment results show the Covid-19 epidemics trend prediction algorithm based on LSTM has better prediction effects, and is helpful in practical life.;;978-1-6654-3890-2;10.1109/CCET52649.2021.9544257;National Natural Science Fund(grant numbers:61371143), National Key Research and Development, ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9544257;Covid-19,LSTM,polynomial regression,epidemics trend prediction;COVID-19,Economics,Epidemics,Conferences,Fitting,Market research,Prediction algorithms;diseases,epidemics,medical computing,polynomials,recurrent neural nets,regression analysis;COVID-19 epidemics trend prediction algorithm,LSTM,polynomial regression algorithm,RNN,long time sequence prediction,time sequence data fitting,time sequence data prediction,epidemic prevention,long short-term memory network,high-order terms,data sequences;;;;6;;30-sep-21;;;IEEE;IEEE Conferences
Digital Twins in Unmanned Aerial Vehicles for Rapid Medical Resource Delivery in Epidemics;Z. Lv, D. Chen, H. Feng, H. Zhu, H. Lv;Department of Game Design, Faculty of Arts, Uppsala University, 752 36 Uppsala, Sweden., College of Computer Science and Technology, Qingdao University, Qingdao 266071, China., School of Information Engineering, Zhejiang A& F University, Hangzhou 311300, China (e-mail: hlfeng@zafu.edu.cn), College of Telecommunications and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing 210049, China., North China Sea Offshore Engineering Survey Institute, Ministry of Natural Resources North Sea Bureau, Qingdao 266061, China.;IEEE Transactions on Intelligent Transportation Systems;;2021;PP;99;1;9;The purposes are to explore the effect of Digital Twins (DTs) in Unmanned Aerial Vehicles (UAVs) on providing medical resources quickly and accurately during COVID-19 prevention and control. The feasibility of UAV DTs during COVID-19 prevention and control is analyzed. Deep Learning (DL) algorithms are introduced. A UAV DTs information forecasting model is constructed based on improved AlexNet, whose performance is analyzed through simulation experiments. As end-users and task proportion increase, the proposed model can provide smaller transmission delays, lesser energy consumption in throughput demand, shorter task completion time, and higher resource utilization rate under reduced transmission power than other state-of-art models. Regarding forecasting accuracy, the proposed model can provide smaller errors and better accuracy in Signal-to-Noise Ratio (SNR), bit quantizer, number of pilots, pilot pollution coefficient, and number of different antennas. Specifically, its forecasting accuracy reaches 95.58% and forecasting velocity stabilizes at about 35 Frames-Per-Second (FPS). Hence, the proposed model has stronger robustness, making more accurate forecasts while minimizing the data transmission errors. The research results can reference the precise input of medical resources for COVID-19 prevention and control.;1558-0016;;10.1109/TITS.2021.3113787;National Natural Science Foundation of China(grant numbers:61902203), Key Research and Development Plan---Major Scientific and Technological Innovation Projects of Shandong Province(grant numbers:2019JZZY020101), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9552619;Unmanned aerial vehicles,digital twins,epidemic,deep learning,medical resource,COVID-19 prevention and control.;COVID-19,Epidemics,Unmanned aerial vehicles,Predictive models,Forecasting,Inspection,Artificial intelligence;;;;1;;;IEEE;29-sep-21;;;IEEE;IEEE Early Access Articles
CAMISA: An AI Solution for COVID-19;B. G, K. A. Kandi, S. K, P. P. S, D. R, A. K. R;MVJ College of Engineering,Electronics and Communication,Bangalore,India, URSC, ISRO,Micro Electronics Design Facility,Bangalore,India, MVJ College of Engineering,Electronics and Communication,Bangalore,India, MVJ College of Engineering,Electronics and Communication,Bangalore,India, MVJ College of Engineering,Electronics and Communication,Bangalore,India, MVJ College of Engineering,Electronics and Communication,Bangalore,India;2021 International Conference on Design Innovations for 3Cs Compute Communicate Control (ICDI3C);27-sep-21;2021;;;216;222;The COVID-19 pandemic has created an unparalleled need for remote patient monitoring and has primarily impacted the world as the mortality rate has increased rapidly. As long as coronavirus exists, mutations of the virus continue to happen, which also insists on the need for remote monitoring. Healthcare sectors require the help of many new technologies such as IoT, Artificial Intelligence, Neural Networks, and sensor technology which can play an important role. The proposed system predicts the COVID-19 symptoms in a patient with the integration of sensor technology and AI. This system is effective in solving the crisis. It includes a shirt and a mask measuring the heart rate, blood oxygen level, and respiration rate. In addition to this is the predictable AI model, where the symptoms predict whether the patient is COVID-19 positive or not.;;978-1-6654-2569-8;10.1109/ICDI3C53598.2021.00051;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9545094;COVID-19,IoT,Contactless Health Monitoring,Neural Network,Sensor Technology,Lilypad Arduino,Pulse Oximeter;COVID-19,Patient monitoring,Technological innovation,Wearable computers,Speech recognition,Tools,Security;artificial intelligence,epidemics,health care,medical computing,medical information systems,microorganisms,patient monitoring;sensor technology,COVID-19 symptoms,heart rate,respiration rate,predictable AI model,CAMISA,AI solution,COVID-19 pandemic,remote patient monitoring,mortality rate,coronavirus,remote monitoring,healthcare sectors,artificial intelligence,neural networks;;1;;10;;27-sep-21;;;IEEE;IEEE Conferences
Prediction and Comparative Analysis of Air Pollution in Major cities of India using Deep Learning Techniques;B. B. G. Reddy, C. Praveen, M. V. S. Kumar, I. M. R. Reddy, D. L. R;Amrita Vishwa Vidyapeetham,Department Of Computer Science and Engineering,Amritapuri,India, Amrita Vishwa Vidyapeetham,Department Of Computer Science and Engineering,Amritapuri,India, Amrita Vishwa Vidyapeetham,Department Of Computer Science and Engineering,Amritapuri,India, Amrita Vishwa Vidyapeetham,Department Of Computer Science and Engineering,Amritapuri,India, Amrita Vishwa Vidyapeetham,Department Of Computer Science and Engineering,Amritapuri,India;2021 Second International Conference on Electronics and Sustainable Communication Systems (ICESC);23-sep-21;2021;;;1434;1439;Air pollution has been a widely discussed research topic since the start of the industrial revolution in the 18th century. Today major cities in the world are losing billions of dollars every day due to air pollution. When Covid-19 was labelled as a pandemic and countries were forced to go into lockdown, the entire world came to a standstill and as a consequence of this, air pollution levels fell drastically. Air purity levels were the highest during this period. The analysis of the pollutant level at major cities in India will occur at three stages - during lockdown, pre lockdown and post lockdown and thereafter the prediction of air pollutant levels can be achieved by using the time-series algorithms.;;978-1-6654-2867-5;10.1109/ICESC51422.2021.9532860;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9532860;Air pollution,RNN,LSTM,GRU,RMSE,MSE,Time Series Forecasting;Deep learning,COVID-19,Pandemics,Communication systems,Atmospheric modeling,Urban areas,Predictive models;air pollution,deep learning (artificial intelligence),diseases,environmental science computing,epidemics,time series;India,deep learning,lockdown stage,air pollution levels,air purity levels,air pollutant levels,air pollution prediction,air pollution comparative analysis,Covid-19,pandemic,pre-lockdown stage,psot lockdown stage,time-series;;;;15;;23-sep-21;;;IEEE;IEEE Conferences
Crowd Detection and Analysis for Surveillance Videos using Deep Learning;A. Ahmed, P. Bansal, A. Khan, N. Purohit;G H Raisoni College of Engineering,Department of Computer Science and Engineering,Nagpur,India, G H Raisoni College of Engineering,Department of Computer Science and Engineering,Nagpur,India, G H Raisoni College of Engineering,Faculty, Department of Computer Science and Engineering,Nagpur,India, G H Raisoni College of Engineering,Faculty, Department of Computer Science and Engineering,Nagpur,India;2021 Second International Conference on Electronics and Sustainable Communication Systems (ICESC);23-sep-21;2021;;;1;7;Crowd identification and analysis has drawn a lot of attention recently, owing to a wide variety of video surveillance applications. We present a detailed review of crowd analysis and management, focusing on state-of-the-art methods for both controlled and unconstrained conditions. The paper illustrates both the advantages as well as disadvantages of state-of-the-art methods. Mass or crowd gathering can be seen at a lot of places like airports, sports stadiums, at various religious, educational, and entertainment-related events, etc. When tens of thousands of people gather in limited space, a tragedy is probably bound to happen. Automated video surveillance has become the need of the day and supports the analysis and management of data on a massive scale. It is very important to identify the presence of a crowd and detect the number of people in the gathering. This can prove very useful for the detection of sudden troupe build-up to avoid riots. Moreover, it can also be very useful in the Covid-19 pandemic situation to avoid people gathering at a place. This paper presents a system to detect the presence of a crowd by counting unique people and then performing crowd analysis. The crowd is analyzed by detecting the gender and age of people in the crowd.;;978-1-6654-2867-5;10.1109/ICESC51422.2021.9532683;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9532683;Deep Learning,Crowd Density Estimation,CNN,MobileNets,Neural networks;Deep learning,COVID-19,Pandemics,Communication systems,Focusing,Aerospace electronics,Video surveillance;diseases,learning (artificial intelligence),sport,surveillance,video signal processing,video surveillance;unconstrained conditions,automated video surveillance,people gathering,crowd analysis,crowd detection,surveillance videos,video surveillance applications,controlled conditions;;;;37;;23-sep-21;;;IEEE;IEEE Conferences
Forecasting COVID-19 pandemic using an echo state neural network-based framework;J. H. Kleinübing Larcher, R. Gomes Da Silva, M. H. Dal Molin Ribeiro, L. Dos Santos Coelho, V. Cocco Mariani;Pontifical Catholic University of Parana (PUCPR),Mechanical Engineering Graduate Program (PPGEM),Curitiba,Parana,Brazil, Pontifical Catholic University of Parana (PUCPR),Industrial & Systems Engineering Graduate Program (PPGEPS),Curitiba,Parana,Brazil, Pontifical Catholic University of Parana (PUCPR),Mechanical Engineering Graduate Program (PPGEM),Curitiba,Parana,Brazil, Pontifical Catholic University of Parana (PUCPR),Mechanical Engineering Graduate Program (PPGEM),Curitiba,Parana,Brazil, Pontifical Catholic University of Parana (PUCPR),Mechanical Engineering Graduate Program (PPGEM),Curitiba,Parana,Brazil;2021 International Joint Conference on Neural Networks (IJCNN);20-sep-21;2021;;;1;8;Forecasts can help in the decision-making process. Epidemiological forecasts are no different, they can help to evaluate the scenario and possible direction of disease spread, for guiding possible interventions. In this work, Echo State Networks (ESNs) are evaluated for COVID-19 (Coronavirus Disease 2019) cases and deaths forecasting ten days ahead. The chosen locations for the experiment are five states in Brazil, namely Sao Paulo (SP), Bahia (BA), Minas Gerais (MG), Rio de Janeiro (RJ), and Ceara (CE), the states with the most COVID-19 cases as of December 31, 2020. The results are evaluated using performance indexes RMSE (Root-mean-square error), MAE (Mean absolute error), and MAPE (Mean absolute percentage error). Results are compared with a common forecasting technique called ARIMA (Autoregressive Integrated Moving Average). The error signals are compared using Wilcoxon Signed-Rank Test, to evaluate the difference statistically. ESNs presented overall good results for a ten day horizon forecast regarding used performance metrics, but for the number of cases, ARIMA outperformed ESNs regarding RMSE, MAE, and MAPE in all but one state. For the number of deaths however, ESNs outperformed ARIMA in most states when the MAE is taken into account. ESNs are shown to be a solid forecasting model when compared with ARIMA, presenting comparable results and in some cases outperforming it.;2161-4407;978-1-6654-3900-8;10.1109/IJCNN52387.2021.9533857;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9533857;Echo state networks,COVID-19,time series,forecasting,ARIMA;COVID-19,Wavelet transforms,Visualization,Time series analysis,Machine learning,Wavelet analysis,Solids;autoregressive moving average processes,diseases,epidemics,forecasting theory,load forecasting,mean square error methods,medical computing,neural nets,statistical analysis,statistical testing;COVID-19 pandemic forecasting,echo state neural network-based framework,decision-making process,epidemiological forecasts,ESNs,COVID-19 cases,Coronavirus Disease 2019,RMSE,root-mean-square error,MAE,mean absolute error,MAPE,mean absolute percentage error,ARIMA,autoregressive integrated moving average,error signals,Wilcoxon signed-rank test;;;;38;;20-sep-21;;;IEEE;IEEE Conferences
Theta Autoregressive Neural Network: A Hybrid Time Series Model for Pandemic Forecasting;A. Bhattacharyya, S. Chattopadhyay, M. Pattnaik, T. Chakraborty;University of Louisville,KY,USA, Indian Statistical Institute,Kolkata,India, Sambalpur University,Sambalpur,India, Center for Data Sciences IIIT,Bangalore,India;2021 International Joint Conference on Neural Networks (IJCNN);20-sep-21;2021;;;1;8;Forecasting time series present a perpetual topic of research in statistical machine learning for the last five decades. Due to the unprecedented outbreak of the novel coronavirus (COVID-19), forecasting the COVID-19 pandemic became a key research interest for both epidemiologists and statisticians. These future predictions are useful for the effective allocation of health care resources, stockpiling, and help in strategic planning for clinicians, government authorities, and public-health policymakers. This paper develops an effective forecasting model that can generate real-time short-term (ten days) and long-term (fifty days) out-of-sample forecasts of COVID-19 outbreaks for eight profoundly affected countries, namely the United States of America, Brazil, India, Russia, South Africa, Mexico, Spain, and Iran. A novel hybrid approach based on the Theta method and Autoregressive neural network (ARNN) model, named Theta-ARNN (TARNN) model, is proposed. The proposed method outperforms previously available single and hybrid forecasting models for COVID-19 predictions in most data sets. The ergodicity and asymptotic stationarity of the TARNN model are also studied.;2161-4407;978-1-6654-3900-8;10.1109/IJCNN52387.2021.9533747;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9533747;Forecasting,Hybrid model,Stationarity;COVID-19,Pandemics,Time series analysis,Neural networks,Medical services,Predictive models,Strategic planning;autoregressive processes,diseases,forecasting theory,health care,learning (artificial intelligence),neural nets,statistical mechanics,strategic planning,time series;hybrid time series model,forecasting time series,statistical machine,novel coronavirus,COVID-19 pandemic,epidemiologists,health care resources,public-health policymakers,COVID-19 outbreaks,forecasting models,hybrid forecasting models,COVID-19 predictions,TARNN model,Theta-ARNN model,theta autoregressive neural network;;;;40;;20-sep-21;;;IEEE;IEEE Conferences
Scheduling for Healthcare Centre for COVID-19: Deep Learning and Genetic Algorithmic Approach;R. Billa, M. A. Razzaq, I. Mukhopadhyay, S. Mandal;VIT-AP University,School of Computer Science and Engineering,Amaravati,India, VIT-AP University,School of Computer Science and Engineering,Amaravati,India, Indian Statistical Institute,Human Genetics Unit,Kolkata,India, VIT-AP University,School of Advanced Sciences,Amaravati,India;2021 IEEE International Conference on Health, Instrumentation & Measurement, and Natural Sciences (InHeNce);17-sep-21;2021;;;1;5;The world is facing a huge loss of both humans and the economy due to COVID-19. Utilizing limited health care facilities properly might help reduce this burden. We provide a pipeline that focuses to develop a scheduler to optimally allocate medical staff based on the predicted number of cases. First, we detect the flow of initial cases in terms of network transmission using networkx (Python package). We develop a model based on Bidirectional Long Short-Term Memory (Bi-LSTM), a deep learning technique to predict future cases using recurrent neural networks with average MSE (mean squared error) of 7.2174e-04 and a novel scheduling technique is proposed by genetic and constraint algorithm-based approach. Our tool can prepare an efficient work schedule for the medical staff at the care centers based on the predicted total COVID cases for next week(s). This is the first attempt to study the pandemic situation in a region from the above-mentioned major perspectives in an integrated way. Several graphical representations and simulation results are presented to validate the obtained results. We demonstrate our method using the data for the region of New Delhi, India. However, it is a general approach and can be applied to any region in the world.;;978-1-6654-4181-0;10.1109/InHeNce52833.2021.9537264;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9537264;COVID-19,Recurrent Neural Networks,Bi-LSTM,Machine Learning,Genetic Algorithm;COVID-19,Deep learning,Schedules,Pandemics,Simulation,Medical services,Predictive models;deep learning (artificial intelligence),diseases,epidemics,genetic algorithms,health care,mean square error methods,medical information systems,Python,recurrent neural nets,scheduling;COVID-19,health care facilities,medical staff,network transmission,Python package,bidirectional long short-term memory,Bi-LSTM,deep learning technique,recurrent neural networks,scheduling technique,genetic constraint algorithm-based approach,efficient work schedule,care centers,predicted total COVID cases,graphical representations,MSE,mean squared error,pandemic situation;;;;17;;17-sep-21;;;IEEE;IEEE Conferences
Short-Term Traffic Forecasting using LSTM-based Deep Learning Models;D. Haputhanthri, A. Wijayasiri;University of Moratuwa,Department of Computer Science and Engineering,Sri Lanka, University of Moratuwa,Department of Computer Science and Engineering,Sri Lanka;2021 Moratuwa Engineering Research Conference (MERCon);14-sep-21;2021;;;602;607;Accurate short-term traffic volume forecasting has become a component with growing importance in traffic management in intelligent transportation systems (ITS). A significant amount of related works on short-term traffic forecasting has been proposed based on traditional learning approaches, and deep learning-based approaches have also made significant strides in recent years. In this paper, we explore several deep learning models that are based on long-short term memory (LSTM) networks to automatically extract inherent features of traffic volume data for forecasting. A simple LSTM model, LSTM encoder-decoder model, CNN-LSTM model and a Conv-LSTM model were designed and evaluated using a real-world traffic volume dataset for multiple prediction horizons. Finally, the experimental results are analyzed, and the Conv-LSTM model produced the best performance with a MAPE of 9.03% for the prediction horizon of 15 minutes. Also, the paper discusses the behavior of the models with the traffic volume anomalies due to the Covid-19 pandemic.;2691-364X;978-1-6654-3753-0;10.1109/MERCon52712.2021.9525670;World Bank, University of Moratuwa, Sri Lanka, ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9525670;CNN-LSTM,Conv-LSTM,encoder-decoder,LSTM,traffic volume forecasting;Deep learning,COVID-19,Solid modeling,Pandemics,Predictive models,Feature extraction,Data models;convolutional neural nets,deep learning (artificial intelligence),forecasting theory,intelligent transportation systems,recurrent neural nets,road traffic,traffic engineering computing;traffic volume forecasting,MAPE,ITS,intelligent transportation systems,Conv-LSTM model,CNN-LSTM model,LSTM encoder-decoder model,long-short term memory,deep learning models,traffic management;;;;13;;14-sep-21;;;IEEE;IEEE Conferences
Empirical Study of Weight Initializations for COVID-19 Predictions in India;M. Narkhede, S. Mane, P. P. Bartakke, M. S. Sutaone;College of Engineering, Pune,Department of E&TC,Pune,India, College of Engineering, Pune,Department of E&TC,Pune,India, College of Engineering, Pune,Department of E&TC,Pune,India, College of Engineering, Pune,Department of E&TC,Pune,India;2021 National Conference on Communications (NCC);13-sep-21;2021;;;1;6;The first case of the novel Coronavirus disease (COVID-19) in India was recorded on 30<sup>th</sup> January 2020 in Kerela and it has spread across all states in India. The prediction of the number of COVID-19 cases is important for government officials to plan various control strategies. This paper presents a weekly prediction of cumulative number of COVID-19 cases in India. A graded lockdown feature, which describes the status of lockdown, is derived and incorporated in the input dataset as one of the features. For prediction, this paper proposes a model which is a stacking of different deep neural networks which have recurrent connections. Vanishing gradients is a common issue with such networks with recurrent connections. Proper weight initialization of the network is one of the solutions to overcome the vanishing gradients problem. Hence, the weight distributions and convergence performance of some state-of-the-art weight initialization techniques have been analyzed in this paper. The proposed model is initialized with the technique which would aid to avoid the vanishing gradients problem and converge faster to a lower loss. This paper also provides a comparison of the proposed model for univariate and multivariate prediction with other prediction models such as statistical model - Auto-Regressive Integrated Moving Average (ARIMA), and deep learning architectures long short term memory (LSTM), bidirectional LSTM (bi-LSTM) and gated recurrent unit (GRU). The results demonstrate that the proposed model gives better prediction results than these models.;;978-1-6654-4177-3;10.1109/NCC52529.2021.9530160;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9530160;Graded Lockdown,COVID-19 Prediction,Multivariate Prediction,Deep Learning,Weight Initialization;COVID-19,Deep learning,Stacking,Government,Predictive models,Logic gates,Long short term memory;convergence,deep learning (artificial intelligence),diseases,epidemics,forecasting theory,medical computing,recurrent neural nets;convergence performance,Kerela,Coronavirus disease,graded lockdown,multivariate prediction,univariate prediction,weight initialization,weight distributions,vanishing gradients problem,recurrent connections,deep neural networks,COVID-19 cases,India,COVID-19 predictions;;;;35;;13-sep-21;;;IEEE;IEEE Conferences
Consequences of Lockdown Caused by COVID-19 Outbreak on the Quality of Air in Dhaka;A. Alvi, M. Ahmed, S. N. M. A. Hoque;Independent University, Bangladesh,dept. of Computer Science and Engineering,Dhaka,Bangladesh, Independent University, Bangladesh,dept. of Computer Science and Engineering,Dhaka,Bangladesh, Independent University, Bangladesh,dept. of Physical Sciences,Dhaka,Bangladesh;2021 International Conference on Automation, Control and Mechatronics for Industry 4.0 (ACMI);8-sep-21;2021;;;1;6;Air pollution has become a worldwide problem that has a negative impact on both human health and the environment. The development of systems for predicting air pollutant severities ahead of time is being driven by this rising threat. In this paper, we proposed using a Long short-term memory (LSTM) model of an Artificial Neural Network (ANN) to predict air pollutant severity levels, as a time series during the COVID-19 lockdown period, providing an early warning. The research used three types of real time datasets of Dhaka city that included records of three gaseous pollutants (CO, NO2, PM2.5). Modeling of the dataset of each pollutant was carried out on hourly and minute-based intervals in two different locations, Mirpur and Baridhara. The predicted results were compared with the readings of the dataset and the model attained high accuracy in predicting air quality. Finally, the air pollutants data were analyzed with COVID 19 cases. Our analysis reviews that the concentrations of air pollutants are in agreement with the regional COVID 19 cases.;;978-1-6654-3843-8;10.1109/ACMI53878.2021.9528097;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9528097;Air pollution,Air quality prediction,Deep learning: LSTM,COVID-19;COVID-19,Mechatronics,Atmospheric modeling,Urban areas,Time series analysis,Artificial neural networks,Predictive models;aerosols,air pollution,air quality,atmospheric composition,atmospheric techniques,carbon compounds,neural nets,nitrogen compounds,time series;COVID-19 outbreak,air pollution,long short-term memory model,artificial neural network,air pollutant severity levels,time series,COVID-19 lockdown period,Dhaka city,gaseous pollutants,air quality,air pollutants,regional COVID 19 cases,Bangladesh,LSTM,PM2.5,Mirpur,Baridhara,CO,NO2;;;;22;;8-sep-21;;;IEEE;IEEE Conferences
Short-Term Electrical Load Forecasting Via Deep Learning Algorithms to Mitigate the Impact of Covid-19 Pandemic on Power Demand;B. Saha, K. F. Ahmed, S. Saha, M. T. Islam;American International University, Bangladesh,Electrical & Electronic Engineering,Dhaka,Bangladesh,1229, American International University, Bangladesh,Electrical & Electronic Engineering,Dhaka,Bangladesh,1229, American International University, Bangladesh,Electrical & Electronic Engineering,Dhaka,Bangladesh,1229, American International University, Bangladesh,Electrical & Electronic Engineering,Dhaka,Bangladesh,1229;2021 International Conference on Automation, Control and Mechatronics for Industry 4.0 (ACMI);8-sep-21;2021;;;1;6;The COVID-19 situation has created an exceptional challenge in the power management system (PMS). This work mainly focuses on the load management through load forecasting. Power generation and distribution is the most important part of PMS. Accurate load forecasting can help to secure electricity scheduling, supply, and reduce the wastage of power. Right now, social distancing has created a great challenge to the administrators to run the power system efficiently and uninterruptedly with minimum involvement of human. In the sector of load management, it can be done through a proper and faster load forecasting approach. Electrical Load Forecasting through deep learning algorithm can perform an effective role in Power Management System (PMS). In this research real data is collected from West Zone Power Distribution Company Limited (WZPDCL) and meteorological data like temperature and humidity are collected from the website of Bangladesh Meteorological Department to train and forecast electrical load using MATLAB. Long-Short Term Memory (LSTM), Feed Forward Back Propagation (FFBP) and ELMAN Neural Network (NN) are used to forecast electrical load. As exogenous data, the load factor (L.F.), power factor (P.F.), current and temperature were used to train algorithms in forecasting the electrical load. A comparative analysis is shown to indicate which is the best suitable method for load forecasting of WZPDCL. Electrical load forecasting results are evaluated through Root Mean Square Error (RMSE). In this research for short-term electrical load forecasting, Feed Forward Back Propagation has shown a minimum RMSE value.;;978-1-6654-3843-8;10.1109/ACMI53878.2021.9528182;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9528182;Neural Network,LSTM,FFBP,ELMAN,RMSE,MATLAB;Deep learning,COVID-19,Backpropagation,Temperature distribution,Load forecasting,Power system management,Weather forecasting;backpropagation,deep learning (artificial intelligence),diseases,epidemics,feedforward neural nets,load forecasting,power distribution,power engineering computing,power factor,power system management,recurrent neural nets;short-term electrical load forecasting,deep learning algorithm,Covid-19 pandemic,power demand,power management system,load management,power generation,electricity scheduling,power system,load factor,power factor,West Zone Power Distribution Company Limited,WZPDCL,meteorological data,Bangladesh Meteorological Department,MATLAB,long-short term memory,feedforward backpropagation,ELMAN neural network;;1;;24;;8-sep-21;;;IEEE;IEEE Conferences
NNR-GL: A Measure to Detect Co-Nonlinearity Based on Neural Network Regression Regularized by Group Lasso;M. Ohsaki, N. Kishimoto, H. Sasaki, R. Ikeura, S. Katagiri, K. Ohnishi, Y. Sebastian, P. Then;Graduate School of Science and Engineering, Doshisha University, Kyoto, Japan, Faculty of Science and Engineering, Doshisha University, Kyoto, Japan, Graduate School of Science and Engineering, Doshisha University, Kyoto, Japan, Faculty of Science and Engineering, Doshisha University, Kyoto, Japan, Graduate School of Science and Engineering, Doshisha University, Kyoto, Japan, Graduate School of Computer Science and Systems Engineering, Kyushu Institute of Technology, Fukuoka, Japan, College of Engineering, IT and Environment, Charles Darwin University, Northern Territory, Australia, Faculty of Engineering, Computing and Science, Swinburne University of Technology, Sarawak, Malaysia;IEEE Access;30-sep-21;2021;9;;132033;132052;For finding keys to understand and elucidate a phenomenon, it is essential to detect dependences among variables, and so measures for that have been proposed. Correlation coefficient and its variants are most common, but they only detect a linear dependence (co-linearity) between two variables. Some recent measures can detect a nonlinear dependence (co-nonlinearity) by means of kernelization or segmentation. They are supposed to handle two variables only and open to discussion with regard to performance in detection and difficulty in setup. There is room for a novel measure based on Neural Networks (NNs), since usual NNs aim at prediction but not at variable dependence detection. For the high-performance detection of co-nonlinearities among multi variables, we propose a measure called NNR-GL based on Neural Network Regression (NNR) regularized by Group Lasso (GL). NNR-GL embodies the detection through multi-input single-output regression by NNR and regularization on the input layer by GL. NNR-GL then calculates how strong the detected co-nonlinearities are by unifying the regression performance and the weights on input variables. We conducted experiments using artificial data to examine the behaviors and fundamental effectiveness of NNR-GL. The performance was estimated by a comprehensive detection performance criterion (CDP-AUC in short), which is the mean of area under curves representing true positive and true negative detections. NNR-GL achieved the values of CDP-AUC from 0.7472 to 0.9681, where 0 means complete failure and 1 means complete success in detection. These values were consistently higher than those from 0.5972 to 0.9259 of the conventional measures for all the different conditions of dependence, data size, and noise rate. Consequently, the effectiveness and robustness of NNR-GL were clearly confirmed.;2169-3536;;10.1109/ACCESS.2021.3111105;Japan Society for the Promotion of Science (JSPS) Grants-in-Aid for Scientific Research (KAKENHI)(grant numbers:21K12018), COVID-19 Research Project of Doshisha University, ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9530688;Machine learning,knowledge discovery,nonlinear dependence,measure to detect co-nonlinearity,regularization,robustness,neural network regression,group lasso;Artificial neural networks,Neural networks,Sea measurements,Correlation,Knowledge discovery,Robustness,Licenses;group theory,mathematics computing,neural nets,regression analysis;group lasso,nonlinear dependence,variable dependence detection,high-performance detection,NNR-GL,neural network regression,multiinput single-output regression,positive detections,true negative detections,detection performance criterion,co-nonlinearities detection;;;;75;CCBY;7-sep-21;;;IEEE;IEEE Journals
Raw Paper Material Stock Forecasting with Long Short-Term Memory;F. Kurniawan, D. E. Herwindiati, M. D. Lauro;Tarumanagara University,Faculty of Information Technology,Jakarta,Indonesia, Tarumanagara University,Faculty of Information Technology,Jakarta,Indonesia, Tarumanagara University,Faculty of Information Technology,Jakarta,Indonesia;2021 9th International Conference on Information and Communication Technology (ICoICT);6-sep-21;2021;;;342;347;The manufacturing business is one of the businesses in Indonesia that continues to show its development from year to year. Like a manufacturing business in general, one of the important efforts made in the printing business is the supply of raw paper materials to produce finished goods. The purpose of this research is making a forecasting of the raw paper material for printing company on 7 different types of 269 historical data with weekly intervals from January 2015 to February 2020 before the Covid19 pandemic season. Forecasting is done using the Long Short Term Memory method with Python language. The model architecture for training and testing is carried out using vanilla LSTM with single input, hidden and output layer with the configuration of 64 neurons in the hidden layer, 150 epoch, 12 batch size and Adam Optimizer (lr = 0.0001) which was repeated 10 times for best result. The test results show the best window size length in the model for each paper raw material differently from 4 to 16. All models was successfully forecasting the test data with an average MAPE of the overall forecast of 21.48%.;;978-1-6654-0447-1;10.1109/ICoICT52021.2021.9527528;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9527528;Forecasting,Long Short Term Memory,Machine Learning,Mean Absolute Percentage Error,Printing;Printing,Training,Neurons,Training data,Predictive models,Data models,Manufacturing;goods distribution,optimisation,printing industry,Python,raw materials,recurrent neural nets,supply chain management;raw paper material stock forecasting,manufacturing business,printing business,long short term memory method,covid19 pandemic season,Adam optimizer,finished goods,Indonesia,LSTM,python language,MAPE;;;;14;;6-sep-21;;;IEEE;IEEE Conferences
PM₂.₅ Monitoring: Use Information Abundance Measurement and Wide and Deep Learning;K. Gu, H. Liu, Z. Xia, J. Qiao, W. Lin, D. Thalmann;Faculty of Information Technology, Engineering Research Center of Intelligence Perception and Autonomous Control, Ministry of Education, Beijing Laboratory of Smart Environmental Protection, Beijing Key Laboratory of Computational Intelligence and Intelligent System, Beijing Artificial Intelligence Institute, Beijing University of Technology, Beijing, China, Faculty of Information Technology, Engineering Research Center of Intelligence Perception and Autonomous Control, Ministry of Education, Beijing Laboratory of Smart Environmental Protection, Beijing Key Laboratory of Computational Intelligence and Intelligent System, Beijing Artificial Intelligence Institute, Beijing University of Technology, Beijing, China, Faculty of Information Technology, Engineering Research Center of Intelligence Perception and Autonomous Control, Ministry of Education, Beijing Laboratory of Smart Environmental Protection, Beijing Key Laboratory of Computational Intelligence and Intelligent System, Beijing Artificial Intelligence Institute, Beijing University of Technology, Beijing, China, Faculty of Information Technology, Engineering Research Center of Intelligence Perception and Autonomous Control, Ministry of Education, Beijing Laboratory of Smart Environmental Protection, Beijing Key Laboratory of Computational Intelligence and Intelligent System, Beijing Artificial Intelligence Institute, Beijing University of Technology, Beijing, China, School of Computer Science and Engineering, Nanyang Technological University, Singapore, EPFL, CH, Lausanne, Switzerland;IEEE Transactions on Neural Networks and Learning Systems;5 Oct 2021;2021;32;10;4278;4290;This article devises a photograph-based monitoring model to estimate the real-time PM<sub>2.5</sub> concentrations, overcoming currently popular electrochemical sensor-based PM<sub>2.5</sub> monitoring methods’ shortcomings such as low-density spatial distribution and time delay. Combining the proposed monitoring model, the photographs taken by various camera devices (e.g., surveillance camera, automobile data recorder, and mobile phone) can widely monitor PM<sub>2.5</sub> concentration in megacities. This is beneficial to offering helpful decision-making information for atmospheric forecast and control, thus reducing the epidemic of COVID-19. To specify, the proposed model fuses Information Abundance measurement and Wide and Deep learning, dubbed as IAWD, for PM<sub>2.5</sub> monitoring. First, our model extracts two categories of features in a newly proposed DS transform space to measure the information abundance (IA) of a given photograph since the growth of PM<sub>2.5</sub> concentration decreases its IA. Second, to simultaneously possess the advantages of memorization and generalization, a new wide and deep neural network is devised to learn a nonlinear mapping between the above-mentioned extracted features and the groundtruth PM<sub>2.5</sub> concentration. Experiments on two recently established datasets totally including more than 100 000 photographs demonstrate the effectiveness of our extracted features and the superiority of our proposed IAWD model as compared to state-of-the-art relevant computing techniques.;2162-2388;;10.1109/TNNLS.2021.3105394;National Science Foundation of China(grant numbers:62076013,62021003,61890935), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9525039;DS transform space,information abundance (IA),photograph-based PM₂₅ monitoring,wide and deep learning;Feature extraction,Monitoring,Atmospheric modeling,COVID-19,Atmospheric measurements,Transforms,Temperature measurement;cameras,decision making,deep learning (artificial intelligence),electrochemical sensors,environmental science computing,feature extraction,learning (artificial intelligence),transforms;photograph-based monitoring model,low-density spatial distribution,time delay,photographs,camera devices,surveillance camera,automobile data recorder,helpful decision-making information,atmospheric forecast,photograph,wide network,deep neural network,above-mentioned extracted features,IAWD model,information abundance measurement,electrochemical sensor-based PM2.5 monitoring methods,COVID-19,DS transform space;Algorithms,COVID-19,Databases, Factual,Deep Learning,Environmental Monitoring,Humans,Nonlinear Dynamics,Particle Size,Particulate Matter,Photography,SARS-CoV-2;3;;81;IEEE;30-aug-21;;;IEEE;IEEE Journals
Peer To Peer Social Lending Default Prediction With Convolutional Neural Networks;K. Chengeta, E. R. Mabika;Artificial Intelligence Research, KaribuTechs AI Research Institute,Pretoria,South Africa, National University of Science and Technology,Department of Applied Mathematics,Bulawayo,Zimbabwe;2021 International Conference on Artificial Intelligence, Big Data, Computing and Data Communication Systems (icABCD);30-aug-21;2021;;;1;10;Social lending or peer to peer lending (P2P lending) is a social digital lending marketplace where borrowers and lenders are interlinked. With the emergency of coronavirus medical risks and travel limitations, this has come as a lucrative business. However with huge industry lay-offs and small companies going under, the verification of a potential borrower's creditworthiness is important. The objective of peer to peer lending was to eliminate middlemen or banks and create a personal touch of the borrower and lender, but results have shown that those running away from traditional banks do so because of unpaid loans, bad debts or other slow payment behaviour. Information asymmetry, lack of demand and money supply, poor income verification, inaccurate credit reports and employment details, high debt to income ratios as well as inadequate anti fraud systems are some of the challenges in peer to peer lending. To mitigate these myriad of problems, machine learning algorithms are used to predict default, slow payments and fraudulent application behaviour. The measurement by classification of such creditworthiness of peer to peer lending marketplaces is done with new frameworks like deep learning convolution neural networks, XGBoost, CatBoost and LightGBM. These new class of classifiers performed better than the c4.5 decision tree, ensemble voting classifier, random forest and k nearest neighbor classifiers. The deep learning algorithms were also optimized for overfitting leading to even better performance. The implementation was done using Weka, Keras and Tensorflow. The datasets used include Prosper and Lending Club peer to peer datasets managed by their respective online lending houses. The study also finds that purpose, employment status, age and credit grade or prosper score are the best predictors for defaulting of loans.;;978-1-7281-8592-7;10.1109/icABCD51485.2021.9519309;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9519309;Lending Club,CNN,XGBoost,Tensorflow;Deep learning,Employment,Redundancy,Neural networks,Parallel processing,Classification algorithms,Peer-to-peer computing;banking,data mining,decision trees,financial data processing,fraud,learning (artificial intelligence),pattern classification,peer-to-peer computing;respective online lending houses,social digital lending marketplace,borrowers,lenders,potential borrower,peer lending marketplaces,deep learning convolution neural networks,peer datasets,peer social lending default prediction;;;;30;;30-aug-21;;;IEEE;IEEE Conferences
Using Denoised LSTM Network for Tourist Arrivals Prediction;J. Wang, P. Ge, Z. Liu;Sichuan University,Business School,Chengdu,P.R.China,610064, Sichuan University,Business School,Chengdu,P.R.China,610064, Sichuan University,Business School,Chengdu,P.R.China,610064;2021 IEEE 2nd International Conference on Pattern Recognition and Machine Learning (PRML);26-aug-21;2021;;;176;182;Precise tourist arrivals prediction is required since tourism products are perishable and vulnerable to environmental change. Many studies have been pursuing more effective techniques to forecast tourist arrivals after the worldwide COVID-19. A hybrid method based on singular spectrum analysis (SSA) and long short-term memory network (LSTM) that incorporates various varieties of time series, containing historical tourist arrivals and search intensity indices (SII), is proposed to make tourist arrivals predictions. The proposed method is applied to the empirical studies and its results outperform all baseline models which verifies the effectiveness of the denoised deep learning method for high-frequency predictions. In addition, experimental results on independent SII variables reveal that SII data is of great significance to tourist arrivals predictions and provides practitioners with deeper comprehension of potential tourism forecasting factors.;;978-1-6654-4383-8;10.1109/PRML52754.2021.9520695;National Natural Science Foundation of China, ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9520695;Singular Spectrum Analysis,Search intensity indices,Long short-term memory network,denoised;Industries,Deep learning,Uncertainty,Time series analysis,Government,Predictive models,Pattern recognition;deep learning (artificial intelligence),forecasting theory,recurrent neural nets,time series,travel industry;denoised deep learning method,time series,tourism forecasting factors,SII data,COVID-19,SSA,singular spectrum analysis,search intensity indices,high-frequency predictions,historical tourist arrivals,long short-term memory network,precise tourist arrivals prediction,denoised LSTM network;;;;22;;26-aug-21;;;IEEE;IEEE Conferences
The Research of SEIJR Model With Time-Delay Based on 2019-nCov;S. Sun, Y. Zheng;Graduate School of Art and Science, New York University, New York, NY, USA, Department of Mathematics, University of Illinois at Urbana–Champaign, Urbana, IL, USA;IEEE Access;30-aug-21;2021;9;;117949;117956;A global epidemic disease known as the novel coronavirus (2019-nCov) had seriously hit the most area around the whole world causing unpredictable loss of manpower and finance during the past year. Modeling the spread and development of infectious diseases represented by new Coronavirus has become an important part of public health work in the world. Estimation of possible infection population and prospective suggestion of handling spread based on existing data is crucial. In this article, we build a more applicable model called SEIJR with a log-normal distributed time delay to forecast the trend of spreading considering the biology parameters obtained based on Chinese clinical data in Wuhan and the real spread feature of 2019-nCov in Italy. Adopting Particle Swarm Optimization (PSO), we estimate the early period average spreading velocity (<inline-formula> <tex-math notation=LaTeX>\boldsymbol {\alpha _{0}} </tex-math></inline-formula>) and implement inversion analysis of time point (<inline-formula> <tex-math notation=LaTeX>\boldsymbol {T_{0}} </tex-math></inline-formula>) when the virus first hit Italy. Based on fixed <inline-formula> <tex-math notation=LaTeX>\boldsymbol {\alpha _{0}} </tex-math></inline-formula> and <inline-formula> <tex-math notation=LaTeX>\boldsymbol {T_{0}} </tex-math></inline-formula>, we then obtained the average spreading velocity <inline-formula> <tex-math notation=LaTeX>\boldsymbol {\alpha _{1}} </tex-math></inline-formula> after the area lockdown using PSO. The result shows that it will help address the infection by generating the prediction trends of different <inline-formula> <tex-math notation=LaTeX>\boldsymbol {\alpha } </tex-math></inline-formula> which we considered. Finally, our research applies Logistic regression, Neural Network embedding LSTM layer, which is two representative machine learning algorithms, to directly predict future infection trends and compare the forecast with results yielded by mathematical model adopting differential equations. Not only solved the complex, nondifferentiable equation of the epidemic model, this research also performs well in inversion analysis based on PSO which conveys informative outcomes for further discussion on precautious action. The comparison with the machine learning algorithms shows that the 2019-nCov based epidemic dynamics assumption is reasonable and helpful to the mathematical model, which is better than the data-driven machine learning algorithms. Code can be freely downloaded from <uri>https://github.com/Summerwork/2019-nCov-Prediction</uri>.;2169-3536;;10.1109/ACCESS.2021.3107521;Natural Science Foundation of China(grant numbers:12071024), Ministry of Science and Technology of China(grant numbers:2019AAA0105103), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9521905;Epidemic modeling,PSO,parameter inversion analysis,epidemic disease modeling,time-delay differential equation;Mathematical model,Infectious diseases,Data models,Sociology,Market research,COVID-19,Sun;biology computing,delays,differential equations,diseases,epidemics,learning (artificial intelligence),medical computing,medical information systems,particle swarm optimisation,recurrent neural nets,regression analysis;2019-nCov based epidemic dynamics assumption,mathematical model,data-driven machine learning algorithms,SEIJR model,time-delay,global epidemic disease,coronavirus,unpredictable loss,manpower,finance,infectious diseases,public health work,possible infection population,prospective suggestion,applicable model,log-normal distributed time delay,biology parameters,Chinese clinical data,spread feature,particle swarm optimization,PSO,early period average,inversion analysis,area lockdown,prediction trends,representative machine,future infection trends,epidemic model,average spreading velocity;;;;22;CCBY;24-aug-21;;;IEEE;IEEE Journals
Predicting the Number of COVID-19 Cases Based on Deep Learning Methods;X. Li, J. Wang, C. Li, Z. Wang, J. Zhang;Zhengzhou University,School of Electrical Engineering,Zhengzhou,China, Zhengzhou University,School of Electrical Engineering,Zhengzhou,China, Zhengzhou University,International College of Zhengzhou University,Zhengzhou,China, Zhengzhou University,School of Life Sciences,Zhengzhou,China, Zhengzhou University,School of Life Sciences,Zhengzhou,China;2021 IEEE 4th International Conference on Big Data and Artificial Intelligence (BDAI);20-aug-21;2021;;;37;42;Coronavirus disease 2019 (COVID-19) broke out in Wuhan at the end of 2019 and quickly spread to other cities in China. Here, we provided a model to predict the number of COVID-19 infections in Wuhan based on deep learning methods. In addition to epidemic data, environmental and social factors including population migration, temperature and internet search data were considered. We compared the performance of long short-term memory (LSTM) model and convolutional neural network (CNN) model. The performance of the CNN model was 12.5% higher than that of the LSTM model. Moreover, population migration and internet search data can respectively improve the prediction performance of the model. We desire that the proposed model can predict the number of cases in the early stages of infectious disease outbreaks, and be extended to the prediction of other infectious diseases.;;978-1-6654-1270-4;10.1109/BDAI52447.2021.9515304;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9515304;deep learning,long short-term memory,convolutional neural network,coronavirus disease,disease prediction;COVID-19,Deep learning,Epidemics,Temperature distribution,Infectious diseases,Sociology,Predictive models;convolutional neural nets,deep learning (artificial intelligence),diseases,epidemics,Internet,medical computing,recurrent neural nets;LSTM model,population migration,Internet search data,prediction performance,infectious disease outbreaks,COVID-19 cases,deep learning methods,Coronavirus Disease 2019,Wuhan,COVID-19 infections,epidemic data,environmental factors,social factors,long short-term memory model,convolutional neural network model,CNN model;;;;32;;20-aug-21;;;IEEE;IEEE Conferences
Stock Price Analysis and Prediction;C. Vora, D. Sheth, B. Shah, N. B. Shah;K.J. Somaiya College of Engineering & Information Technology,Department of Information Technology,Mumbai, K.J. Somaiya College of Engineering & Information Technology,Department of Information Technology,Mumbai, K.J. Somaiya College of Engineering & Information Technology,Department of Information Technology,Mumbai, K.J. Somaiya College of Engineering & Information Technology,Department of Information Technology,Mumbai;2021 International Conference on Communication information and Computing Technology (ICCICT);12-aug-21;2021;;;1;7;Covid has taught a valuable lifelong lesson. During the pandemic, economies of countries collapsed and many nations had to undergo a complete lockdown. Individuals lost their sources of income and their savings dwindled trying to survive the lockdown. Many small-scale industries closed down for not being able to recover losses. Despite of the economic machine being slowed, the cog of stock market ran smoothly. The moral learnt was one must have multiple sources of income. During lockdown, the stock market collapsed hard. Now a year later, the market is stronger than before and has achieved new benchmarks. Stock market is erratic and most people relate it to gambling. There are other ways to invest money long term which are a safer bet, but for those who love playing with fire, stock market is a good investment. One might ask why to invest in stocks than going for safer options. No other investment provides potentially higher profits and losses than stock market does. Investing in stock market is purely on people's own risk. There is no such belief that a particular stock would always provide profit. Some people utilize the advancements of technology and computing resources in order to do algorithmic trading. One might say it's a fool's errand as there are some unfathomable factors which affect any stock. But could one gain an edge using these techniques? The proposed system explores this idea further by developing a Machine Learning model which accepts historic prices of stocks as input to predict futuristic prices with good accuracy to construct a portfolio of multiple stocks. The proposed project will help investors to gain an idea of whether investing in a stock may payout or not.;;978-1-6654-0430-3;10.1109/ICCICT50803.2021.9510159;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9510159;Machine Learning,LSTM,Stocks,Neural Networks;Industries,Ethics,Machine learning algorithms,Pandemics,Machine learning,Predictive models,Prediction algorithms;economics,investment,learning (artificial intelligence),pricing,profitability,stock markets;stock price analysis,stock market,particular stock,multiple stocks;;;;13;;12-aug-21;;;IEEE;IEEE Conferences
Advancing Deep Learning for Supply Chain Optimization of COVID-19 Vaccination in Rural Communities;M. Barajas, S. Bhatkande, P. Baskaran, H. Gohel, B. Pandey;University of Houston-Victoria,Department of Computer Science,Victoria,USA, University of Houston-Victoria,Department of Computer Science,Victoria,USA, University of Houston-Victoria,Department of Computer Science,Victoria,USA, University of Houston-Victoria,Department of Computer Science,Victoria,USA, Gyancity Research Lab,Center of Cyber Security,Motihari,India;2021 10th IEEE International Conference on Communication Systems and Network Technologies (CSNT);12-aug-21;2021;;;690;695;Covid19 is a global pandemic that brought lots of disruptions in day-to-day life, affected economies, closed millions of businesses, and took a lot of precious lives. Along with social distancing and wearing masks, the effective way to eradicate the virus is to administer vaccines. To prevent the spread of disease and avoid deaths, it is essential to prioritize vaccine distribution. At the request of CDC, National Academies of Science, Engineering and Medicine published the Framework for fair distribution of COVID-19 Vaccine. This paper focuses on studying the rate of vaccination in urban and rural communities and identifying gaps in the Covid19 vaccine supply chain using data science. Demand forecasting using deep learning is proposed for planning vaccine allocation and distribution. Deep learning refers to multilayer neural networks that can learn extremely complex patterns using hidden layers between inputs and outputs. Long Short-Term Memory neural networks will be used to forecast vaccine demand.;2329-7182;978-1-6654-2306-9;10.1109/CSNT51715.2021.9509710;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9509710;Demand forecasting,COVID vaccination,Time series forecasting,LSTM,ARIMA,Deep learning,and Neural Networks;COVID-19,Deep learning,Pandemics,Supply chains,Government,Demand forecasting,Data models;demand forecasting,health care,learning (artificial intelligence),neural nets,optimisation,supply chains;deep learning,vaccine allocation,supply chain optimization,rural communities,global pandemic,social distancing,vaccine distribution,urban communities,data science,multilayer neural networks,long short term memory,COVID19 vaccination;;;;6;;12-aug-21;;;IEEE;IEEE Conferences
An Intelligent System to Forecast COVID-19 Pandemic using Hybrid Neural Network;S. Vanahalli, P. N;Christ (Deemed to be University),Department of Data Science,Pune, Lavasa,India, Christ (Deemed to be University),Department of Data Science,Pune, Lavasa,India;2021 10th IEEE International Conference on Communication Systems and Network Technologies (CSNT);12-aug-21;2021;;;543;548;A current outbreak known as COVID-19 has been discovered from the coronavirus was informed by WHO. COVID-19 is a universal pandemic that has brought out the best and the worst of humanity. Due to an increase in the cases daily, COVID-19 is creating a menace to public health and establishes a disruption of the social and economic development of the countries. The problem is the hospitals are not able to provide proper facilities and treatments on time due to the lack of facilities in India. The purpose of this project to build an efficient hybrid deep learning model for forecasting the COVID-19 pandemic with multiple features that are responsible for the spread of COVID-19 in the top five states in India. In particular, a hybrid model that incorporates Auto-Regressive Integrated Moving Average and Long-term Short Memory is been used to forecast confirmed cases. The linear and non-linear dependencies in the dataset is been dealt with by an ARIMA-LSTM hybrid model. As a result, when compared to the outcomes of ARIMA, LSTM models independently, the hybrid model was giving better results and was performing well in forecasting COVID-19 cases. Through this, the policymakers will get prior information on COVID-19 cases in states which will help the government and healthcare departments to take prominent measures to prevent it.;2329-7182;978-1-6654-2306-9;10.1109/CSNT51715.2021.9509622;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9509622;COVID-19,forecasting,hybrid,ARIMA,LSTM;COVID-19,Economics,Pandemics,Hospitals,Neural networks,Government,Predictive models;autoregressive moving average processes,deep learning (artificial intelligence),health care,recurrent neural nets;nonlinear dependencies,autoregressive integrated moving average,healthcare departments,WHO,coronavirus,COVID-19 cases forecasting,ARIMA-LSTM hybrid model,efficient hybrid deep learning model,hybrid neural network,COVID-19 pandemic forecasting;;;;12;;12-aug-21;;;IEEE;IEEE Conferences
Review of Classifiers Used for Novel Corona Virus Foot-Print Detection;M. K. Assudani, N. Sahu;G. H. Raisoni University,Dept. of Computer Science and Engineering,Amravati,India, G. H. Raisoni University,Dept. of Computer Science and Engineering,Amravati,India;2021 10th IEEE International Conference on Communication Systems and Network Technologies (CSNT);12-aug-21;2021;;;865;871;Development in the field of Machine Learning and Artificial Intelligence are greatly simplifying the critical bio-medical engineering applications. The first outbreak of Covid'19 pandemic was observed in Mainland China and soon it spread over to remaining 214 countries. World Health Organization (WHO) came to forefront and named it as Corona Virus Disease 2019. This highly contagious disease causes serious impact due to Severe Acute Respiratory Syndrome (SARS)-COV Virus. In this article, we are about to disclose the detailed literature survey around how Machine Learning and Artificial Intelligence are momentously assisting the biomedical engineering segment to tackle with the situation created due to Covid'19 Pandemic. Subsequently, different classifiers, which are used by the researchers for effective diagnosis of Covid'19 infection, are studied for projecting the research in effective diagnosis of different strains of the Corona Virus.;2329-7182;978-1-6654-2306-9;10.1109/CSNT51715.2021.9509656;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9509656;COVID'19,SARS,Machine Learning,Artificial Intelligence,Data Science,Bio-Medical Engineering;COVID-19,Deep learning,Pandemics,Organizations,Predictive models,Corona,Coronaviruses;biomedical engineering,diseases,medical computing,microorganisms,patient diagnosis;Covid19 infection,machine learning,artificial intelligence,critical bio-medical engineering applications,Covid19 pandemic,World Health Organization,Corona Virus Disease-2019,Severe Acute Respiratory Syndrome-COV Virus,detailed literature survey,biomedical engineering segment,corona virus foot-print detection;;;;19;;12-aug-21;;;IEEE;IEEE Conferences
Rapid and Scalable COVID-19 Screening using Speech, Breath, and Cough Recordings;D. Grant, I. McLane, J. West;Johns Hopkins University,Electrical and Computer Engineering,Baltimore,Maryland,21218, Johns Hopkins University,Electrical and Computer Engineering,Baltimore,Maryland,21218, Johns Hopkins University,Electrical and Computer Engineering,Baltimore,Maryland,21218;2021 IEEE EMBS International Conference on Biomedical and Health Informatics (BHI);10-aug-21;2021;;;1;6;Over the course of the COVID-19 pandemic, efforts have been made to rapidly scale diagnostic tests to increase access and throughput. Though the primary mechanism for testing has been wet tests, several recent studies have shown that acoustic signatures of COVID-19 can be used to accurately discriminate between positive and negative subjects. These methods show promise of wide scale access and more regular and rapid testing, but are faced with several questions involving the robustness of the methods and the sanitary nature of forced cough recordings. Here we propose an alternative method to triage patients using acoustic signatures in speech and breathing sounds. Using a crowd-sourced database with sound recordings from self-identified COVID-19 positive and negative subjects, we develop a simple method that can be applied to analyze sounds that can be deployed in a system to unobtrusively detect COVID-19. Mel-frequency cepstral coefficients (MFCCs) and relAtive specTrA perceptual linear prediction (RASTA-PLP) features are evaluated independently and conjointly with two different classification techniques, random forests (RF) and deep neural networks (DNN). The optimal results are achieved for speech and breathing sounds using a combination of MFCC and RASTA-PLP, with an area-under-the-curve (AUC) of 0.7938 for detecting COVID-19 via speech sound analysis, and 0.7575 for detecting COVID-19 via breathing sound analysis. This is compared to an AUC of 0.6836 for cough sounds using MFCCs alone. These results show promise in future deployment of a rapid screening tool using speech recordings as the world moves to contain future outbreaks and accelerate vaccination efforts.;2641-3604;978-1-6654-0358-0;10.1109/BHI50953.2021.9508482;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9508482;;COVID-19,Radio frequency,Pandemics,Tools,Throughput,Robustness,Vaccines;bioacoustics,cepstral analysis,deep learning (artificial intelligence),diseases,epidemics,feature extraction,medical signal processing,neural nets,patient diagnosis,pattern classification,pneumodynamics,signal classification,speaker recognition,speech processing;rapid testing,forced cough recordings,acoustic signatures,breathing sounds,sound recordings,speech sound analysis,breathing sound analysis,cough sounds,rapid screening tool,speech recordings,COVID-19 pandemic,diagnostic tests,wet tests;;;;32;;10-aug-21;;;IEEE;IEEE Conferences
Research on Short-term Traffic Demand of Taxi in Large Cities Based on BP Neural Network Algorithm;D. Guo, J. Wang, S. Li;Guangzhou College of South China University of Technology,Guangzhou,China,510800, Soochow University,School of Computer Science and Technology,Suzhou,China,215006, China Agriculture University,College of Information and Electrical Engineering,Beijing,China,100083;2021 IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA);2-aug-21;2021;;;1161;1166;In this paper, a prediction model of urban taxi traffic demand based on BP neural network is proposed according to the characteristics of the increasing demand for public transportation. This model uses the method of zoning statistics to analyze the traffic demand of urban Taxis, and the traffic generation and traffic disappearance in a period are taken as the input of the network according to the statistical results. This paper extends the hidden layer to 2 layers and introduces the tanh activation function. Also, this paper selects passenger traffic data from 2016 to 2019 as the training set. After 1,000 epoch training, the training set Mean Square Error (MSE) is achieved 4.332 × 10<sup>-5</sup>and the test set loss is achieved 0.01139.;;978-1-6654-1867-6;10.1109/ICAICA52286.2021.9498158;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9498158;BP neural network,Short-term traffic demand,Urban traffic,Machine learning;Training,COVID-19,Roads,Neural networks,Urban areas,Predictive models,Prediction algorithms;backpropagation,mean square error methods,public administration,public transport,statistics;traffic generation,traffic disappearance,passenger traffic data,BP neural network algorithm,prediction model,urban taxi traffic demand,public transportation,taxi short-term traffic demand,mean square error,MSE,zoning statistics;;;;11;;2-aug-21;;;IEEE;IEEE Conferences
Predicting Satisfaction of Online Banking System in Bangladesh by Machine Learning;S. F. Shetu, I. Jahan, M. M. Islam, R. Ara Hossain, N. N. Moon, F. Narin Nur;Daffodil International University,Department of Computer Science & Engineering,Dhaka,Bangladesh, Daffodil International University,Department of Computer Science & Engineering,Dhaka,Bangladesh, Daffodil International University,Department of Computer Science & Engineering,Dhaka,Bangladesh, Daffodil International University,Department of Computer Science & Engineering,Dhaka,Bangladesh, Daffodil International University,Department of Computer Science & Engineering,Dhaka,Bangladesh, Notre Dame University,Department of Computer Science & Engineering,Dhaka,Bangladesh;2021 International Conference on Artificial Intelligence and Computer Science Technology (ICAICST);30-jul-21;2021;;;223;228;Online banking refers to using your smartphone, tablet, or another internet-connected computer to browse and access your bank account. It is quick and free, and it usually allows you to perform a variety of activities, such as paying bills and exchanging currency, without having to visit or call your branch. As a developing nation, Bangladesh is seeing an increase in online banking. People are still reliant on online banking because it makes a man's life much easier. During the Corona incident, the use of online banking increased at an unprecedented pace. Online banking services such as Rocket, bKash, and Nagad are now available in the region. While online banking makes life easier, third-party money laundering incidents do occur from time to time. As a result, some people are unhappy with online banking. However, some people say that they are happy with their online banking experience. This work tries to address this critique and give the right advice to the customer. Customer satisfaction and frustration with online banking have been predicted using Machine Learning techniques in this study. Seven traditional machine learning classification algorithms Logistic Regression, Random Forest, Naïve Bayes, support vector machine, Neural network, Decision tree, K nearest neighbor algorithms to complete this research work and find the concluded delimiter.;;978-1-6654-2404-2;10.1109/ICAICST53116.2021.9497796;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9497796;Banking System,Machine Learning and Prediction;Support vector machines,Rockets,Machine learning algorithms,Online banking,Social networking (online),Computational modeling,Predictive models;bank data processing,banking,customer satisfaction,decision trees,Internet,learning (artificial intelligence),mobile computing,pattern classification,regression analysis,smart phones,support vector machines;online banking services,online banking experience,online banking system;;3;;20;;30-jul-21;;;IEEE;IEEE Conferences
Safety-Critical Control of Compartmental Epidemiological Models with Measurement Delays;T. G. Molnár, A. W. Singletary, G. Orosz, A. D. Ames;University of Michigan,Department of Mechanical Engineering,Ann Arbor,MI,USA,48109, California Institute of Technology,Department of Mechanical and Civil Engineering,Pasadena,CA,USA,91125, University of Michigan,Department of Civil and Environmental Engineering,Ann Arbor,MI,USA,48109, California Institute of Technology,Department of Mechanical and Civil Engineering,Pasadena,CA,USA,91125;2021 American Control Conference (ACC);28-jul-21;2021;;;1052;1057;We introduce a methodology to guarantee safety against the spread of infectious diseases by viewing epidemiological models as control systems and by considering human interventions (such as quarantining or social distancing) as control input. We consider a generalized compartmental model that represents the form of the most popular epidemiological models and we design safety-critical controllers that formally guarantee safe evolution with respect to keeping certain populations of interest under prescribed safe limits. Furthermore, we discuss how measurement delays originated from incubation period and testing delays affect safety and how delays can be compensated via predictor feedback. We demonstrate our results by synthesizing active intervention policies that bound the number of infections, hospitalizations and deaths for epidemiological models capturing the spread of COVID-19 in the USA.;2378-5861;978-1-6654-4197-1;10.23919/ACC50511.2021.9482737;National Science Foundation(grant numbers:1932091), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9482737;;COVID-19,Sociology,Human factors,Control systems,Social factors,Time measurement,Delays;delays,diseases,occupational safety,safety-critical software;human interventions,social distancing,control input,generalized compartmental model,popular epidemiological models,design safety-critical controllers,safe evolution,prescribed safe limits,measurement delays,incubation period,testing delays,active intervention policies,safety-critical control,compartmental epidemiological models,infectious diseases,viewing epidemiological models,control systems;;;;35;;28-jul-21;;;IEEE;IEEE Conferences
Covid-19 Diagnosis Model Using Deep Learning with Focal Loss Technique;A. Y. A. Saeed, A. E. Ba Alawi;Taiz University,Department of Software Engineering,Taiz,Yemen, Taiz University,Department of Software Engineering,Taiz,Yemen;2021 International Congress of Advanced Technology and Engineering (ICOTEN);27-jul-21;2021;;;1;4;Coronavirus is an extreme virus, which spreads by human contact, now affects more than two hundred countries across the world. In comparison, new coronavirus signs are very close to the general seasonal influenza. The screening of infected people in the war against COVID-19 is seen as a crucial move. Since the positive case prediction tools of COVID-19 are not widely usable, the need for diagnostic support tools has increased. It is also of high priority that promising cases are identified earlier as possible to guarantee that this disease does not spread further. In this study, a deep learning model has been designed to diagnose Covid-19 with focal loss technique to overcome the imbalanced dataset. The results of these models have been evaluated using accuracy, recall, precision, and F1 score. The best performance achieved using the focal loss technique reached an accuracy of 89.41%, a recall of 92.6%, and a precision of 86.62%.;;978-1-6654-1224-7;10.1109/ICOTEN52080.2021.9493477;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9493477;Covid-19 Screening,AI,Deep Learning,Diagnosis;COVID-19,Deep learning,Measurement,Influenza,Tools,Coronaviruses;deep learning (artificial intelligence),diseases,medical diagnostic computing,microorganisms,patient diagnosis;Covid-19 diagnosis model,focal loss technique,extreme virus,human contact,coronavirus signs,general seasonal influenza,positive case prediction tools,diagnostic support tools,deep learning model;;;;14;;27-jul-21;;;IEEE;IEEE Conferences
The Prediction of E-Money Circulation: Backpropagation with Genetic Algorithm Adoption;E. Budianita, O. Okfalisa, M. R. Assiddiki;Universitas Islam Negeri Sultan Syarif Kasim Riau,Department of Informatics Engineering,Pekanbaru,Indonesia, Universitas Islam Negeri Sultan Syarif Kasim Riau,Department of Informatics Engineering,Pekanbaru,Indonesia, Universitas Islam Negeri Sultan Syarif Kasim Riau,Department of Informatics Engineering,Pekanbaru,Indonesia;2021 International Congress of Advanced Technology and Engineering (ICOTEN);27-jul-21;2021;;;1;6;Digital transformation forces the utilization of e-money during the economic transaction. Behind its advantages, e-money has been influenced by the inflation rate, thus accelerating the country’s money circulation. Moreover, the fragile Covid-19 economy triggers each country’s need to anticipate the circulation of e-money to deter future inflation. Therefore, this paper deployed the Backpropagation approach integrated with the Genetic Algorithm to forecast the dissemination of e-money in Indonesia by exploiting time-series Bank Indonesia (BI) data from January 2009 to December 2019. Here, 120 data with 12 variables are considered to thoroughly predict the Year 2020 circulation focusing on the previous 12 months. This study reveals that e-money circulation in Indonesia is increasing monthly in 2020. The testing result shows that the lowest mean square error (MSE) is found at 0.000035 for data training division at 90%:10%, learning rate parameter at 0.8, the combination of crossover probability and mutation at 0.4:0.6, and the total generation and population at 350 and 200, respectively. In a nutshell, Backpropagation with a Genetic Algorithm has been expected to a successful outcome for e-money circulation and provides large values compared with actual data and original BPNN.;;978-1-6654-1224-7;10.1109/ICOTEN52080.2021.9493468;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9493468;Backpropagation,genetic algorithm,e-money circulation forecast,prediction,artificial neural network;Backpropagation,Training,Sociology,Neural networks,Mean square error methods,Prediction algorithms,Pattern recognition;backpropagation,electronic money,financial data processing,genetic algorithms,inflation (monetary),mean square error methods,neural nets,probability,time series;backpropagation,e-money circulation,genetic algorithm adoption,time series bank Indonesia data,Covid-19 economy,BPNN,probability,mean square error,MSE,inflation,economic transaction;;;;26;;27-jul-21;;;IEEE;IEEE Conferences
Computer-Aided Diagnosis System for Early Prediction of Atherosclerosis using Machine Learning and K-fold cross-validation;B. Cherradi, O. Terrada, A. Ouhmida, S. Hamida, A. Raihani, O. Bouattane;Hassan II University of Casablanca,Stie Team, Crmef Casablanca-Settat. Ssdia Laboratory, Enset Mohammedia,Mohammedia,Morocco, Hassan II University of Casablanca,Ssdia Laboratory Enset Mohammedia,Mohammedia,Morocco, Hassan II University of Casablanca,Ssdia Laboratory Enset Mohammedia,Mohammedia,Morocco, Hassan II University of Casablanca,Ssdia Laboratory Enset Mohammedia,Mohammedia,Morocco, Hassan II University Casablanca,Ssdia Laboratory Enset Mohammedia,Mohammedia,Morocco, Hassan II University of Casablanca,Ssdia Laboratory Enset of Mohammedia,Mohammedia,Morocco;2021 International Congress of Advanced Technology and Engineering (ICOTEN);27-jul-21;2021;;;1;9;Atherosclerosis known as coronary artery disease (CAD) becomes epidemic in any society that relies on an industrial-technological system with an associated behavioral alteration in people's lifestyles as junk food consumerism and stressful habits. However, this disease residue the first cause of death in industrialized countries, despite many new therapeutic approaches and risk factors prevention. Moreover, atherosclerosis misdiagnosis has side costly effects. In this paper, we have proposed a computer-aided diagnosis system based on K-Nearest Neighbors (KNN) and Artificial Neural Network (ANN) algorithms. Then, we applied K-fold cross-validation in order to split the databases and reach the best model with the higher accuracy and fewer side effects. In this proposed work, we tested the reached model on 573 patients with several effective features which collecting from Cleveland and Z-Alizadeh Sani datasets. Then Area Under the Curve (AUC), F1-Score, and accuracy were used to enrich and determine the effectiveness of each predictive model. Using Machine Learning (ML) methods, K-fold cross-validation, and performance evaluation metrics, 96.78% average accuracy is achieved with the original training accuracy of 100%, which means the prediction system is obtained as the best predictive model comparing to the previous studies.;;978-1-6654-1224-7;10.1109/ICOTEN52080.2021.9493524;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9493524;Machine Learning Algorithms,Prediction Systems,Atherosclerosis Cardio-vascular Disease;Solid modeling,Computational modeling,Atherosclerosis,Machine learning,Artificial neural networks,Predictive models,Prediction algorithms;blood vessels,cardiovascular system,diseases,feature extraction,learning (artificial intelligence),medical diagnostic computing,nearest neighbour methods,neural nets,patient diagnosis;computer-aided diagnosis system,coronary artery disease,industrial-technological system,associated behavioral alteration,junk food consumerism,stressful habits,industrialized countries,risk factors prevention,atherosclerosis misdiagnosis,costly effects,artificial neural network algorithms,cross-validation,side effects,predictive model,machine learning methods,prediction system;;1;;44;;27-jul-21;;;IEEE;IEEE Conferences
Prediction of Covid-19 patients states using Data mining techniques;T. Alsmadi, N. Alqudah, H. Najadat;Jordan University of Science and Technology,Department of Computer Information Systems,Irbid,Jordan, Jordan University of Science and Technology,Department of Computer Information Systems,Irbid,Jordan, Jordan University of Science and Technology,Department of Computer Information Systems,Irbid,Jordan;2021 International Conference on Information Technology (ICIT);26-jul-21;2021;;;251;256;Covid-19 is an infectious disease caused by a newly discovered coronavirus. It was first identified in several people with symptoms of pneumonia in Wuhan, Hubei Province. Given the scale of the epidemic and its rapid spread, and given that there is currently no vaccine for the virus, health care workers need support, as it can sometimes be challenging to predict the patient's condition. This problem can be solved through data mining techniques. Anticipating recovery situations is essential in countries seeking to contain the virus, and these predictions can help public health experts track positive citizens of COVID-19, increase doctors ability to predict the general perception of the course of events over a period, and assess patients at early risk building on approaches New based on results data. This paper discusses supervised learning on the COVID-19 Corona Virus India dataset in particular, which contains 3,799 patients, which used to classify the patient data of COVID-19 into two types, recovered and deceased. Classification approaches have been used, Including Decision tree (DT), Support vector machine support (SVM), Logistic regression (LR), Random forest (RF), k-nearest neighbors (KNN), Naïve Bayes (NB), and Artificial Neural Network (ANN) model in the patient dataset, and choosing the best method based on the accuracy, precision and recall withhold-out or cross-validation.;;978-1-6654-2870-5;10.1109/ICIT52682.2021.9491716;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9491716;COVID-19,Decision tree,Support Vector Machine,Logistic regression,Random forest,k-nearest neighbors,Naïve Bayes,Neural Network,COVID-19 Corona Virus India dataset;COVID-19,Support vector machines,Radio frequency,Supervised learning,Artificial neural networks,Coronaviruses,Vaccines;data mining,decision trees,diseases,health care,learning (artificial intelligence),medical computing,microorganisms,neural nets,pattern classification,regression analysis,support vector machines;public health experts,results data,COVID-19 Corona Virus India dataset,patient data,patient dataset,covid-19 patients states,data mining techniques,infectious disease,newly discovered coronavirus,health care workers;;;;29;;26-jul-21;;;IEEE;IEEE Conferences
Modeling and Forecasting of Tourism Time Series Data using ANN-Fourier Series Model and Monte Carlo Simulation;S. J. Danbatta, A. Varol;Kano State Institute for Information Technology, Kura,Department of Computer Science,Kano,Nigeria, Maltepe University,College of Engineering and Natural Sciences,Department of Computer Engineering,Maltepe/Istanbul,Turkey,34857;2021 9th International Symposium on Digital Forensics and Security (ISDFS);20-jul-21;2021;;;1;6;Tourism is counted as one of the most sensitive sectors to crises such as the COVID-19 pandemic. By the first quarter of 2020, it brought the foreign visitors' travels to a sudden and unexpected halt. This has negatively affected the tourism sector. Due to the perishable nature of the tourism industry products, many researchers are calling for urgent development and implementation of a rescue plan that will help in predicting the future number of foreign visitors. In this paper, we proposed an approach to modeling and forecasting a tourism time-series data that have both trend and seasonality. This approach is a combination of the Fourier series and artificial neural network methods to capture the seasonality and trend components in data. We applied this method to the monthly foreign visitors to Turkey dataset. We studied the data for the periods before, and during the COVID-19 pandemic. To account for uncertainties in the model prediction during the COVID-19 pandemic, we employed the Monte Carlo simulation method. We run 100 Monte Carlo simulations within ±2σ from the model curve. The mean of these 100 Monte Carlo simulation paths is computed and used for presenting the Monte Carlo forecast result values of the data. To test the feasibility of this approach, we compared the model predictions with some other existing models in the literature. In each case, the model has demonstrated a decent prediction and outperformed the benchmarked models. The proposed model produces a statistically good fit and acceptable result that can be used to forecast other tourism-related attributes.;;978-1-6654-4481-1;10.1109/ISDFS52919.2021.9486325;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9486325;Fourier series,Artificial Neural Network,Monte Carlo simulation;COVID-19,Monte Carlo methods,Uncertainty,Pandemics,Computational modeling,Time series analysis,Predictive models;forecasting theory,Fourier series,mean square error methods,Monte Carlo methods,neural nets,time series,travel industry;tourism-related attributes,tourism time series data,ANN-Fourier series model,COVID-19 pandemic,tourism sector,tourism industry products,tourism time-series data,artificial neural network methods,Monte Carlo simulation method;;;;22;;20-jul-21;;;IEEE;IEEE Conferences
Examining the Factors Influencing the Mobile Learning Usage During COVID-19 Pandemic: An Integrated SEM-ANN Method;K. Alhumaid, M. Habes, S. A. Salloum;College of Education, Zayed University, Abu Dhabi, United Arab Emirates, Department of Radio and Television, Faculty of Mass Communication, Yarmouk University, Irbid, Jordan, School of Science, Engineering, Environment, University of Salford, Manchester, U.K;IEEE Access;26-jul-21;2021;9;;102567;102578;The way in which the emotion of fear affects the technology adoption of students and teachers amid the COVID-19 pandemic is examined in this study. Mobile Learning (ML) has been used in the study as an educational social platform at both public and private higher-education institutes. The key hypotheses of this study are based on how COVID-19 has influenced the incorporation of mobile learning (ML) as the pandemic brings about an increase in different kinds of fear. The major kinds of fear that students and teachers/instructors are facing at this time include: fear because of complete lockdown, fear of experiencing education collapse and fear of having to give up social relationships. The proposed model was evaluated by developing a questionnaire survey which was distributed among 280 students at Zayed University, on the Abu Dhabi Campus, in the United Arab Emirates (UAE) with the purpose of collecting data from them. This study uses a new hybrid analysis approach that combines SEM and deep learning-based artificial neural networks (ANN). The importance-performance map analysis is also used in this study to determine the significance and performance of every factor. Both ANN and IPMA research showed that Attitude (ATD) are the most important predictor of intention to use mobile learning. According to the empirical findings, perceived ease of use, perceived usefulness, satisfaction, attitude, perceived behavioral control, and subjective norm played a strongly significant role justified the continuous Mobile Learning usage. It was found that perceived fear and expectation confirmation were significant factors in predicting intention to use mobile learning. Our study showed that the use of mobile learning (ML) in the field of education, amid the coronavirus pandemic, offered a potential outcome for teaching and learning, however, this impact may be reduced by the fear of losing friends, a stressful family environment and fear of future results in school. Therefore, during the pandemic, it is important to examine students appropriately so as to enable them to handle the situation emotionally. The proposed model has theoretically given enough details as to what influences the intention to use ML from the viewpoint of internet service variables on an individual basis. In practice, the findings would allow higher education decision formers and experts to decide which factors should be prioritized over others and plan their policies appropriately. This study examines the competence of the deep ANN model in deciding non-linear relationships among the variables in the theoretical model, methodologically.;2169-3536;;10.1109/ACCESS.2021.3097753;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9488198;Artificial Neural Network Architecture,hybrid-model,mobile learning,Structural Equation Modeling,subjective norm;Mathematical model,Artificial neural networks,Technology acceptance model,Education,COVID-19,Uncertainty,Pandemics;computer aided instruction,deep learning (artificial intelligence),educational institutions,further education,Internet,mobile computing,neural nets,statistical analysis,teaching;COVID-19 pandemic,integrated SEM-ANN method,educational social platform,higher-education institutes,deep learning-based artificial neural networks,teaching,continuous mobile learning usage,United Arab Emirates,Zayed University,perceived ease of use,perceived usefulness,perceived behavioral control,subjective norm;;2;;86;CCBY;16-jul-21;;;IEEE;IEEE Journals
Wireless Channel Modelling for Identifying Six Types of Respiratory Patterns With SDR Sensing and Deep Multilayer Perceptron;U. Saeed, S. Y. Shah, A. Zahid, J. Ahmad, M. A. Imran, Q. H. Abbasi, S. A. Shah;Research Centre for Intelligent Healthcare, Coventry University, Coventry, U.K., School of Computing, Engineering and Built Environment, Glasgow Caledonian University, Glasgow, U.K., School of Engineering and Physical Sciences, Heriot-Watt University, Edinburgh, U.K., School of Computing, Edinburgh Napier University, Edinburgh, U.K., James Watt School of Engineering, University of Glasgow, Glasgow, U.K., James Watt School of Engineering, University of Glasgow, Glasgow, U.K., Research Centre for Intelligent Healthcare, Coventry University, Coventry, U.K.;IEEE Sensors Journal;15-sep-21;2021;21;18;20833;20840;Contactless or non-invasive technology has a significant impact on healthcare applications such as the prediction of COVID-19 symptoms. Non-invasive methods are essential especially during the COVID-19 pandemic as they minimise the burden on healthcare personnel. One notable symptom of COVID-19 infection is a rapid respiratory rate, which requires constant real-time monitoring of respiratory patterns. In this paper, Software Defined Radio (SDR) based Radio-Frequency sensing technique and supervised machine learning algorithm is employed to provide a platform for detecting and monitoring various respiratory: eupnea, biot, bradypnea, sighing, tachypnea, and kussmaul. The variations in Channel State Information produced by human respiratory were utilised to identify distinct respiratory patterns using fine-grained Orthogonal Frequency-Division Multiplexing signals. The proposed platform based on the SDR and the Deep Multilayer Perceptron classifier exhibits the ability to effectively detect and classify the afore-mentioned distinct respiratory with an accuracy of up to 99%. Moreover, the effectiveness of the proposed scheme in terms of diagnosis accuracy, precision, recall, F1-score, and confusion matrix is demonstrated by comparison with a state-of-the-art machine learning classifier: Random Forest.;1558-1748;;10.1109/JSEN.2021.3096641;Coventry University internal Ph.D. studentship program, ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9481241;COVID-19,abnormal respiratory,non-invasive,USRP,CSI,software defined radio,neural network;Sensors,COVID-19,Monitoring,Wireless fidelity,Wireless communication,OFDM,Wireless sensor networks;biomedical communication,health care,multilayer perceptrons,OFDM modulation,patient diagnosis,patient monitoring,personnel,pneumodynamics,random forests,software radio,supervised learning,wireless channels;COVID-19 pandemic,healthcare personnel,COVID-19 infection,rapid respiratory rate,real-time monitoring,software defined radio,supervised machine learning algorithm,channel state information,respiratory patterns,deep multilayer perceptron classifier,wireless channel modelling,SDR sensing,healthcare applications,COVID-19 symptoms,noninvasive methods,fine-grained orthogonal frequency-division multiplexing signals,radio-frequency sensing technique,confusion matrix,machine learning classifier,random forest;;3;;43;IEEE;12-jul-21;;;IEEE;IEEE Journals
Evaluation of Hybrid Unsupervised and Supervised Machine Learning Approach to Detect Self-Reporting of COVID-19 Symptoms on Twitter;M. Cai, J. Li, M. Nali, T. K. Mackey;University of California San Diego,Dept of Computer Science and Engineering,La Jolla,CA,USA, S-3 Research,San Diego,CA,USA, Global Health Program University of California, San Diego,La Jolla,CA,USA, Global Health Program University of California, San Diego,La Jolla,CA,USA;2021 IEEE International Conference on Communications Workshops (ICC Workshops);9-jul-21;2021;;;1;6;With over 127 million cases globally, the COVID-19 pandemic marks a sentinel event in global health. However, true case estimations have been elusive due to lack of testing and diagnostic capacity, asymptomatic cases, and individuals who do not get tested or seek care. Concomitantly, new digital surveillance tools to detect, characterize, and report COVID-19 cases are emerging, including using structured and unstructured data from users self-reporting COVID-19-related experiences on the Internet and social media platforms. In this study, we develop and evaluate a hybrid unsupervised and supervised machine learning approach to detect self-reported COVID-19-related symptoms on Twitter during the early stages of the pandemic. Tweets were collected from the public API stream from March 3<sup>rd</sup>-31<sup>st</sup> 2020, filtered for COVID-19-related terms. We used the biterm topic model to cluster tweets into theme-associated groups for the first 18 days of tweets, which were then extracted and manually annotated to identify users self-reporting suspected COVID-19 symptoms or status. Using this manually annotated data as a training set, we used an XLNet deep learning model for classifying symptom-related tweets from a larger corpus and also evaluated model performance. From 4,492,954 tweets collected, the unsupervised learning process yielded 3,465 (<, 1%) symptom tweets used to form our ground-truth COVID-19 symptoms dataset (n = 11,550). The XLNet text classifier achieved the highest accuracy (.91) and f1 (.62) compared to baseline models evaluated for classification. After re-training with adjusted loss function, we boosted the classifier's precision to 0.81 while maintaining a high f1 (0.66), resulting in identification of an additional 2,622 symptom-related tweets when applied to an additional 11 days of tweets collected. Our study used a hybrid machine learning approach to enable high precision identification of Twitter user-generated COVID-19 symptom discussions. The model is a digital epidemiology tool that can identify social media users who self-report symptoms during the early periods of an outbreak.;2694-2941;978-1-7281-9441-7;10.1109/ICCWorkshops50388.2021.9473830;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9473830;XLNet,Biterm Topic Model,social media,Twitter,COVID-19;COVID-19,Training,Social networking (online),Pandemics,Conferences,Blogs,Text categorization;application program interfaces,deep learning (artificial intelligence),diseases,epidemics,health care,Internet,medical computing,patient diagnosis,pattern classification,pattern clustering,social networking (online),supervised learning,text analysis,unsupervised learning;outbreak,digital epidemiology tool,hybrid machine learning,loss function,XLNet text classifier,symptom-related tweets classification,theme-associated groups,public API stream,Internet,diagnostic capacity,self-reporting,deep learning,Twitter,self-report symptoms,Twitter user-generated COVID-19 symptom discussions,COVID-19 symptoms dataset,tweet clustering,biterm topic model,COVID-19-related terms,COVID-19-related symptoms,hybrid unsupervised and supervised machine learning,social media platforms,unstructured data,structured data,COVID-19 cases,digital surveillance tools,asymptomatic cases,case estimations,global health,COVID-19 pandemic;;;;44;;9-jul-21;;;IEEE;IEEE Conferences
Prediction of COVID-19 Cases based on Human Behavior using DNN Regressor for Canada;D. Tripathy, S. G. Camorlinga;The University of Winnipeg,Applied Computer Science,Winnipeg,Canada, The University of Winnipeg,Winnipeg,Canada;2021 IEEE International Conference on Communications Workshops (ICC Workshops);9-jul-21;2021;;;1;6;The proposed work utilizes Deep Neural Network (DNN) regression model to predict the total number of cases, new cases, and death cases in Canada. It is evaluated based on human behavior such as isolation, wearing mask outside home, contact with symptomatic person, washing hands, and other behaviors. The dataset is collected for the period of March 9<sup>th</sup>, 2020 to November 2<sup>nd</sup>, 2020 for Canada. The proposed methodology uses multiple-input deep neural network regression model with Rectified Linear Unit (Re LU) Function as the activation function, five non-linear dense layers of 64 Unit and a single unit of last layer as output for the curve fitting. The dataset is split into train and test sets with test size 20% and training size 80%. A nonlinear regression model is applied to the normalized data for making accurate predictions. The model performance is evaluated based on Root Mean Square Error (RMSE). Also, the Mean Absolute Error (MAE) is estimated for the model to quantify the error between predicted and true values. The results show that the proposed machine learning (ML) method predicts with high accuracy and can also be a convenient tool in making predictions for other countries.;2694-2941;978-1-7281-9441-7;10.1109/ICCWorkshops50388.2021.9473812;University of Winnipeg, ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9473812;COVID-19,Human Behavior,Machine Learning,DNN Regressor,Tensor flow;COVID-19,Training,Conferences,Neural networks,Machine learning,Predictive models,Tools;behavioural sciences computing,curve fitting,deep learning (artificial intelligence),diseases,epidemics,mean square error methods,medical computing,regression analysis;COVID-19 cases prediction,human behavior,DNN regressor,Canada,death cases,symptomatic person,rectified linear unit function,activation function,nonlinear dense layers,nonlinear regression,root mean square error,mean absolute error,multiple-input deep neural network regression,ReLU,curve fitting,RMSE,MAE,machine learning;;;;16;;9-jul-21;;;IEEE;IEEE Conferences
Data-driven COVID-19 growth prediction;Y. Fang;College of Engineering & Computer Science, Australian National University,Canberra,Australia;2021 2nd International Conference on Computing and Data Science (CDS);5-jul-21;2021;;;64;72;COVID-19 disease become the most influential public health event in 2020. It has affected more than two hundred countries and regions. The prediction and analysis of the epidemic is extremely important. It can help governments and international organizations control the development of the epidemic. In our study, we use three different models, namely, autoregressive integrated moving average (ARIMA), multilayer perceptron (MLP) and long short-term memory (LSTM). We made predictions based on the data from 20 countries, which reported the largest confirmed cases until June 30, 2020. We find that the ARIMA model achieves the lowest error. For Turkey, the forecast root mean square error (RMSE) from June 3 to June 30, 2020 is only 95.049. Our research will help the government to follow up the future development of COVID-19 and make decisions. It will also play a role in the outbreak of major diseases that may appear in the future.;;978-1-6654-0428-0;10.1109/CDS52072.2021.00018;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9463197;COVID-19 growth prediction,ARIMA,MLP,LSTM;COVID-19,Deep learning,Epidemics,Computational modeling,Government,Predictive models,Multilayer perceptrons;autoregressive moving average processes,data analysis,decision making,diseases,epidemics,mean square error methods,medical computing,multilayer perceptrons,public administration,recurrent neural nets;decision making,root mean square error,multilayer perceptron,autoregressive integrated moving average,data driven COVID-19 growth prediction,ARIMA model,long short term memory,international organizations,government,epidemic,public health,COVID-19 disease;;;;24;;5-jul-21;;;IEEE;IEEE Conferences
Zero-shot Text Classification via Knowledge Graph Embedding for Social Media Data;Q. Chen, W. Wang, K. Huang, F. Coenen;School of Advanced Technology, Xi’an Jiaotong Liverpool University, China., School of Advanced Technology, Xi’an Jiaotong Liverpool University, China. (e-mail: wei.wang03@xjtlu.edu.cn), School of Advanced Technology, Xi’an Jiaotong Liverpool University, China., Department of Computer Science, University of Liverpool, Liverpool, UK.;IEEE Internet of Things Journal;;2021;PP;99;1;1;The idea of ‘citizen sensing’ and ‘human as sensors’ is crucial for social Internet of Things, an integral part of cyber-physical-social systems (CPSS). Social media data, which can be easily collected from the social world, has become a valuable resource for research in many different disciplines, e.g. crisis/disaster assessment, social event detection, or the recent COVID-19 analysis. Useful information, or knowledge derived from social data, could better serve the public if it could be processed and analyzed in more efficient and reliable ways. Advances in deep neural networks have significantly improved the performance of many social media analysis tasks. However, deep learning models typically require a large amount of labeled data for model training, while most CPSS data is not labeled, making it impractical to build effective learning models using traditional approaches. In addition, the current state-of-the-art, pre-trained Natural Language Processing (NLP) models do not make use of existing knowledge graphs, thus often leading to unsatisfactory performance in real-world applications. To address the issues, we propose a new zero-shot learning method which makes effective use of existing knowledge graphs for the classification of very large amounts of social text data. Experiments were performed on a large, real-world tweet dataset related to COVID-19, the evaluation results show that the proposed method significantly outperforms six baseline models implemented with state-of-the-art deep learning models for NLP.;2327-4662;;10.1109/JIOT.2021.3093065;Xian JiaotongLiverpool University(grant numbers:RDF-16-01-34), Natural Science Foundation of Jiangsu Province(grant numbers:BE2020006-4B,BK20181189), National Natural Science Foundation of China(grant numbers:no.61876155), Key Program Special Fund in XJTLU(grant numbers:KSF-E-05,KSF-T-06), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9466939;Natural language processing,knowledge graph,zero-shot learning,internet of things,social media data analysis.;Social networking (online),Data models,Task analysis,Sensors,Internet of Things,Bit error rate,Predictive models;;;;;;;IEEE;29-jun-21;;;IEEE;IEEE Early Access Articles
Optimizing Neural Network Performance to Predict Coronary Heart Disease;A. Kabdullin, M. Kabdullin, L. Naizabayeva;Satbayev University,Kazakhstan, Satbayev University,Kazakhstan, International IT University,Kazakhstan;2021 IEEE International Conference on Smart Information Systems and Technologies (SIST);29-jun-21;2021;;;1;4;Coronary heart disease is a disease that causes the death of most people in the worldwide. According to the WHO, 9.43 million people died from ischemic stroke in 2018.Residents of some CIS countries (Belarus, Kazakhstan, Kyrgyzstan, Russia and Ukraine) have a higher cardiovascular mortality rate at the age of 55-59 than the French at the age of 75-79. Premature mortality rates in women in European countries are lower than in men, but have similar dynamics [12], [13].The constant increase in the amount of information in cardiology makes the development of new methods for data analysis urgent. Using existing risk assessment approaches, it is impossible to predict about half of the episodes of acute coronary syndrome. Big data machine learning can lead to better diagnostic and treatment outcomes at a lower cost. The inductive approach allows you to identify patterns arising from data analysis and develop algorithms that can learn on their own. Although machine learning models for cardiovascular risk assessment are superior to traditional methods, to date, no large-scale machine learning studies have been conducted to prove a predictive role in the general population using routine clinical data. In addition, there is no clear recommendation which of the algorithms will work better in a given situation. The use of an empirical approach when choosing a machine learning method and the principle of black box make it difficult to conduct large-scale studies and implement machine learning methods in clinical practice. This work is devoted to the study of the optimization of neural networks using a correlation analysis of signs to predict the possibility of coronary heart disease. As a result of the analysis of literary sources, the shortcomings of previously developed software tools were identified, seriously limiting the use of these programs in the medical field.;;978-1-7281-7470-9;10.1109/SIST50301.2021.9465925;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9465925;Coronary Heart Disease,neural network,prediction system,machine learning,optimization of neural networks,medicine,Python,Keras;Heart,Machine learning algorithms,Data analysis,Neural networks,Machine learning,Predictive models,Prediction algorithms;Big Data,cardiology,cardiovascular system,data analysis,diseases,learning (artificial intelligence),medical diagnostic computing,risk management;ischemic stroke,CIS countries,cardiovascular mortality rate,premature mortality rates,European countries,data analysis,risk assessment,acute coronary syndrome,Big Data machine learning,diagnostic treatment outcomes,cardiovascular risk assessment,routine clinical data,correlation analysis,coronary heart disease prediction,neural network performance optimization,Belarus,Kazakhstan,Kyrgyzstan,Russia,Ukraine;;;;17;;29-jun-21;;;IEEE;IEEE Conferences
Automatic Hyperparameter Optimization for Arbitrary Neural Networks in Serverless AWS Cloud;A. Kaplunovich, Y. Yesha;University of Maryland,Department of Computer Science,Baltimore,USA, University of Maryland,Department of Computer Science,Baltimore,USA;2021 12th International Conference on Information and Communication Systems (ICICS);28-jun-21;2021;;;69;76;Deep Neural Networks are the most efficient method to solve many challenging problems. The importance of the subject can be demonstrated by the fact that the 2019 Turing Award was given to the godfathers of AI (and Neural Networks) Yoshua Bengio, Geoffrey Hinton, and Yann LeCun. In spite of the numerous advancements in the field, most of the models are being tuned manually. Accurate models became especially important during the novel coronavirus pandemic.Many day-to-day decisions depend on the model predictions affecting billions of people. We implemented a flexible automatic real-time hyperparameter tuning approach for arbitrary DNN models written in Python and Keras without manual steps. All of the existing tuning libraries require manual steps (like hyperopt, Scikit-Optimize or SageMaker). We provide an innovative methodology to automate hyper-parameter tuning for an arbitrary Neural Network model source code, utilizing Serverless Cloud and implementing revolutionary microservices, security, interoperability and orchestration. Our methodology can be used in numerous applications, including Information and Communication Systems.;2573-3346;978-1-6654-3351-8;10.1109/ICICS52457.2021.9464618;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9464618;Neural Networks,Cloud,Hyperparameter,Automation,Optimization,Server-less,Machine Learning,Data Science,AWS;Communication systems,Neural networks,Manuals,Predictive models,Real-time systems,Libraries,Security;cloud computing,deep learning (artificial intelligence),diseases,epidemics,open systems,Python,security of data,source code (software),Web services;automatic hyperparameter optimization,arbitrary neural networks,deep neural networks,coronavirus pandemic,arbitrary DNN models,hyper-parameter tuning,revolutionary microservices,revolutionary security,revolutionary interoperability,revolutionary orchetration,arbitrary neural network model source code,serverless AWS cloud,information and communication systems,Python,Keras;;;;33;;28-jun-21;;;IEEE;IEEE Conferences
Distance Estimation in Thermal Cameras Using Multi-Task Cascaded Convolutional Neural Network;E. M. F. Caliwag, A. Caliwag, B. -K. Baek, Y. Jo, H. Chung, W. Lim;Department of Aeronautics, Mechanical and Electronic Convergence Engineering, Kumoh National Institute of Technology, Gumi, South Korea, Department of Aeronautics, Mechanical and Electronic Convergence Engineering, Kumoh National Institute of Technology, Gumi, South Korea, Department of 2sensor and Department of i3system, Inc., Gumi, South Korea, Department of 2sensor and Department of i3system, Inc., Gumi, South Korea, Department of Aeronautics, Mechanical and Electronic Convergence Engineering, Kumoh National Institute of Technology, Gumi, South Korea, Department of Aeronautics, Mechanical and Electronic Convergence Engineering, Kumoh National Institute of Technology, Gumi, South Korea;IEEE Sensors Journal;31-aug-21;2021;21;17;18519;18525;The rapid growth of the current pandemic (COVID-19) requires the use of thermal cameras that can perform fast and automatic body temperature measurement. The accuracy of the temperature measurement is affected by its distance from a person. Conventional distance estimation methods utilize the coordinates of the bounding box provided by several face detection algorithms such as YOLOv3 and SSD. The bounding box output of these methods varies which causes inaccurate distance estimation results. In this study, we propose a distance estimation method for thermal camera applications based on the coordinates of the facial key points extracted using multi-task cascaded convolutional neural network. The result obtained in this study proves that the proposed method exhibits higher accuracy (root mean square error of 2.9695 cm in comparison with an RMSE of 25.26 cm using other methods) and the least CPU and memory consumption in comparison with conventional methods.;1558-1748;;10.1109/JSEN.2021.3092382;Ministry of Small and Medium Enterprises (SMEs) and Start-ups, South Korea(grant numbers:S2829065,S3010704), National Research Foundation of Korea(grant numbers:2020R1A4A101777511,2021R1I1A3056900), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9465113;Deep learning,distance estimation,face detection,MTCNN,thermal camera;Cameras,Estimation,Faces,Face detection,Temperature measurement,Face recognition,Task analysis;cameras,face recognition,mean square error methods,neural nets,temperature measurement;thermal cameras,multitask,convolutional neural network,current pandemic,automatic body temperature measurement,conventional distance estimation methods,face detection algorithms,YOLOv3,bounding box output,methods varies,inaccurate distance estimation results,distance estimation method,thermal camera applications,facial key points,higher accuracy,size 2.9695 cm,size 25.26 cm;;;;15;IEEE;25-jun-21;;;IEEE;IEEE Journals
BinaryCoP: Binary Neural Network-based COVID-19 Face-Mask Wear and Positioning Predictor on Edge Devices;N. Fasfous, M. -R. Vemparala, A. Frickenstein, L. Frickenstein, M. Badawy, W. Stechele;Technical University of Munich, BMW Group, BMW Group, Technical University of Munich, Technical University of Munich, Technical University of Munich;2021 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW);24-jun-21;2021;;;108;115;Face masks have long been used in many areas of everyday life to protect against the inhalation of hazardous fumes and particles. They also offer an effective solution in healthcare for bi-directional protection against air-borne diseases. Wearing and positioning the mask correctly is essential for its function. Convolutional neural networks (CNNs) offer an excellent solution for face recognition and classification of correct mask wearing and positioning. In the context of the ongoing COVID-19 pandemic, such algorithms can be used at entrances to corporate buildings, airports, shopping areas, and other indoor locations, to mitigate the spread of the virus. These application scenarios impose major challenges to the underlying compute platform. The inference hardware must be cheap, small and energy efficient, while providing sufficient memory and compute power to execute accurate CNNs at a reasonably low latency. To maintain data privacy of the public, all processing must remain on the edge-device, without any communication with cloud servers. To address these challenges, we present BinaryCoP, a low-power binary neural network classifier for correct facial-mask wear and positioning. The classification task is implemented on an embedded FPGA accelerator, performing high-throughput binary operations. Classification can take place at up to ~6400 frames-per-second and 2W power consumption, easily enabling multi-camera and speed-gate settings. When deployed on a single entrance or gate, the idle power consumption is reduced to 1.65W, improving the battery-life of the device. We achieve an accuracy of up to 98% for four wearing positions of the MaskedFace-Net dataset. To maintain equivalent classification accuracy for all face structures, skin-tones, hair types, and mask types, the algorithms are tested for their ability to generalize the relevant features over a diverse set of examples using the Grad-CAM approach.;;978-1-6654-3577-2;10.1109/IPDPSW52791.2021.00024;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9460602;;COVID-19,Power demand,Pandemics,Face recognition,Neural networks,Memory management,Logic gates;biomedical communication,convolutional neural nets,data privacy,diseases,field programmable gate arrays,health care,medical computing,pattern classification;convolutional neural networks,face recognition,COVID-19 pandemic,edge-device,BinaryCoP,low-power binary neural network classifier,binary operations,idle power consumption,face structures,binary neural network-based COVID-19 face-mask wear,positioning predictor,edge devices,bidirectional protection,air-borne diseases,power 2.0 W,power 1.65 W;;29;;24-jun-21;;;IEEE;IEEE Conferences;;
A Novel Statistical and Neural Network Combined Approach for the Cloud Spot Market;G. J. Portella, G. N. Rodrigues, E. Y. Nakano, A. Boukerche, A. C. M. Melo;Department of Computer Science, University of Brasilia, 28127 Brasilia, Distrito Federal, Brazil, 70910-900 (e-mail: gustavo.portella@aluno.unb.br), Computer Science, University of Braslia, Braslia, DF, Brazil, (e-mail: genaina@cic.unb.br), Department of Statistics, University of Brasilia, 28127 Brasilia, DF, Brazil, (e-mail: nakano@unb.br), SITE, University of Ottawa, Ottawa, Ontario, Canada, K1N-6N5 (e-mail: boukerch@site.uottawa.ca), Computer Science, University of Brasilia, Brasilia, DF, Distrito Federal, Brazil, CEP: 70910-900 (e-mail: alves@unb.br);IEEE Transactions on Cloud Computing;;2021;PP;99;1;1;The instance price in the Amazon EC2 spot model is often much lower than in the on-demand counterpart. However, this price reduction comes with a decrease in the availability guarantees. To our knowledge, there is no work that accurately captures the short-term trade-off between spot price and availability, and does long-term analysis for spot price tendencies in favor of user decision making. In this work, we propose a utility-based strategy, that balances cost and availability of spot instances and is targeted to short-term analysis, and a LSTM neural network framework for long term spot price tendency analysis. Our experiments show that, for r4.2xlarge, 90% of spot bid suggestions ensured at least 5.73 hours of availability, with a bid price of approximately 38% of the on-demand price. The LSTM experiments predicted spot price tendencies for several instance types with low error. Our LSTM framework predicted an average value of 0.19 USD/hour for the r5.2xlarge instance type, which is about 37% of the on-demand price. Finally, we used our combined mechanism on an application that compares thousands of SARS-CoV-2 sequences and show that our approach is able to provide good choices of instances, with low bids and very good availability.;2168-7161;;10.1109/TCC.2021.3091936;Fundao de Apoio Pesquisa do Distrito Federal(grant numbers:Call 01-2019 / number 23106.014035/2020-03), Conselho Nacional de Desenvolvimento Cientfico e Tecnolgico(grant numbers:CNPq/AWS 440014/2020-4), Coordenao de Aperfeioamento de Pessoal de Nvel Superior(grant numbers:CAPES / Pandemias), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9463698;cloud computing,utility estimation,neural network;Cloud computing,Computational modeling,Pricing,Long short term memory,Time series analysis,Recurrent neural networks,Analytical models;;;;;;;IEEE;23-jun-21;;;IEEE;IEEE Early Access Articles
Coronavirus Epidemic (COVID-19) Prediction and Trend Analysis Based on Time Series;Z. Liu, J. Zuo, R. Lv, S. Liu, W. Wang;Shenyang Aerospace University,Shenyang,110136, Tongji University,Department of Computer Science and Technology,Shanghai,201804, Shenyang Aerospace University,Shenyang,110136, Shenyang Aerospace University,Shenyang,110136, Shenyang Aerospace University,Shenyang,110136;2021 IEEE International Conference on Artificial Intelligence and Industrial Design (AIID);23-jun-21;2021;;;35;38;In the global fight against the novel corona-virus pneumonia epidemic (COVID-19), a reasonable prediction of the spread of the epidemic has important reference significance for epidemic prevention and control. In order to solve the problem of time series prediction and analysis of the epidemic with limited sample data, nonlinear and high-dimensional features, this study applies the Nonlinear Auto-Regressive neural network (NAR) model for machine learning. The paper predicts the development of the epidemic in the two dimensions of the number of confirmed cases and the number of deaths in major countries in the world, and compares NAR with the traditional Logistic Regression (LR), the classic time series model ARIMA and the SEIR infectious disease dynamic model. This research provides rapid decision-making and new ideas for countries to respond to the “post-epidemic era”.;;978-1-6654-1537-8;10.1109/AIID51893.2021.9456463;The 2020 National College Student Innovation and Entrepreneurship Training Program(grant numbers:202010143017), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9456463;COVID-19,time series,dynamic prediction,machine learning,forecast analysis;COVID-19,Epidemics,Analytical models,Correlation,Pulmonary diseases,Time series analysis,Neural networks;data analysis,diseases,epidemics,health care,learning (artificial intelligence),medical computing,microorganisms,neural nets,regression analysis,time series;coronavirus epidemic,COVID-19 prediction,COVID-19 trend analysis,novel corona-virus pneumonia epidemic,reference significance,epidemic prevention,time series prediction,nonlinear autoregressive neural network,NAR,time series analysis,machine learning;;1;;12;;23-jun-21;;;IEEE;IEEE Conferences
Long Short-Term Memory based RNN for COVID-19 disease prediction;S. Bahri, M. Kdayem, N. Zoghlami;National School of Engineering of Tunis,LTSIRS Laboratory,Tunis,Tunisia,1002, National School of Engineering of Sousse, National School of Engineering of Tunis,LTSIRS Laboratory,Tunis,Tunisia,1002;2021 22nd IEEE International Conference on Industrial Technology (ICIT);18-jun-21;2021;1;;901;906;Currently, the global health system is suffering from an overwhelming issue affecting a large number of individuals all around the world. The novel coronavirus, called COVID-19, has continued to claim more than one million lives. In such cases, it is of vital importance to develop alternatives addressing this health issue and saving more lives. Artificial Intelligence were among the efficient tools that can address this global threat. In this study, we propose to test a recurrent neural network named Long Short-Term Memory (LSTM-RNN) for estimating the number of future fatality cases in USA, India and Italy. Our experimentations proved the effectiveness of LSTM-RNN in predicting the number of deceased cases with minimum of loss ranging from 1.37% to 2.7%.;;978-1-7281-5730-6;10.1109/ICIT46573.2021.9453534;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9453534;Artificial Intelligence,LSTM,LightGBM,Forecasting models;COVID-19,Recurrent neural networks,Temperature,Pandemics,Organizations,Humidity,Tools;artificial intelligence,diseases,epidemics,medical computing,recurrent neural nets;global threat,LSTM-RNN,fatality cases,long short-term memory,COVID-19 disease prediction,global health system,artificial intelligence;;;;45;;18-jun-21;;;IEEE;IEEE Conferences
CNN-based Mask Detection System Using OpenCV and MobileNetV2;G. Harriat Christa, J. J, A. K, K. M. Sagayam;Karunya Institute of Technology and Sciences,Electronics and Communication Engineering,Coimbatore,India, Karunya Institute of Technology and Sciences,Electronics and Communication Engineering,Coimbatore,India, Karunya Institute of Technology and Sciences,Electronics and Communication Engineering,Coimbatore,India, Karunya Institute of Technology and Sciences,Electronics and Communication Engineering,Coimbatore,India;2021 3rd International Conference on Signal Processing and Communication (ICPSC);15-jun-21;2021;;;115;119;this paper establishes a `Safety system for mask detection during this COVID-19 pandemic'. Face mask detection has seen an overwhelming growth in the realm of Computer vision and deep learning, since the unprecedented COVID-19 global pandemic that has mandated wearing masks in public places. To tackle the situation, machine learning engineers have come up with several algorithms and techniques to identify unmasked individuals using various mask detection models. The proposed approach in this paper adopts frameworks of deep learning, TensorFlow, Keras, and OpenCV libraries to detect face masks in real time. The trained MobileNet model, presented in this paper, yielded an accuracy score of 0.99 and an F1 score of 0.99 in the training data. This user-friendly model can be incorporated with several existing technologies such as face detection, biometric authentication and facial expression detection for further advancements in the future.;;978-1-6654-2864-4;10.1109/ICSPC51351.2021.9451688;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9451688;Convolution Neural Network,MobileNetV2,OpenCV,Keras;Deep learning,COVID-19,Pandemics,Biological system modeling,Training data,Signal processing algorithms,Predictive models;biometrics (access control),computer vision,convolutional neural nets,face recognition,learning (artificial intelligence),medical computing;COVID-19 pandemic,face mask detection,overwhelming growth,computer vision,deep learning,unprecedented COVID-19,public places,machine learning engineers,mask detection models,OpenCV libraries,face masks,trained MobileNet model,user-friendly model,face detection,facial expression detection,CNN-based mask detection system,safety system,biometric authentication;;;;8;;15-jun-21;;;IEEE;IEEE Conferences
PI-Net: Pose Interacting Network for Multi-Person Monocular 3D Pose Estimation;W. Guo, E. Corona, F. Moreno-Noguer, X. Alameda-Pineda;Inria, Univ. Grenoble Alpes,CNRS, Grenoble INP, LJK,Grenoble,France,38000, Institut de Robotica i Informatica Industrial,CSIC-UPC,Barcelona,Spain, Institut de Robotica i Informatica Industrial,CSIC-UPC,Barcelona,Spain, Inria, Univ. Grenoble Alpes,CNRS, Grenoble INP, LJK,Grenoble,France,38000;2021 IEEE Winter Conference on Applications of Computer Vision (WACV);14-jun-21;2021;;;2795;2805;Recent literature addressed the monocular 3D pose estimation task very satisfactorily. In these studies, different persons are usually treated as independent pose instances to estimate. However, in many every-day situations, people are interacting, and the pose of an individual depends on the pose of his/her interactees. In this paper, we investigate how to exploit this dependency to enhance current - and possibly future - deep networks for 3D monocular pose estimation. Our pose interacting network, or PI-Net, inputs the initial pose estimates of a variable number of interactees into a recurrent architecture used to refine the pose of the person-of-interest. Evaluating such a method is challenging due to the limited availability of public annotated multi-person 3D human pose datasets. We demonstrate the effectiveness of our method in the MuPoTS dataset, setting the new state-of-the-art on it. Qualitative results on other multi-person datasets (for which 3D pose ground-truth is not available) showcase the proposed PI-Net. PI-Net is implemented in PyTorch and the code will be made available upon acceptance of the paper.;2642-9381;978-1-6654-0477-8;10.1109/WACV48630.2021.00284;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9423075;;Computer vision,Three-dimensional displays,Conferences,Pose estimation,Computer architecture,Bidirectional control,Task analysis;deep learning (artificial intelligence),neural net architecture,pose estimation,recurrent neural nets;PI-Net,pose interacting network,multiperson monocular 3D pose estimation,deep networks,person-of-interest,multiperson datasets,3D pose ground-truth,pose instances,recurrent architecture,multiperson 3D human pose datasets,MuPoTS dataset,PyTorch;;1;;57;;14-jun-21;;;IEEE;IEEE Conferences
Optimization of the Containment Levels for the Reopening of Mexico City due to COVID-19;L. Miralles-Pechuan, H. Ponce, L. Martinez-Villasenor;Centre for Applied Data Analytics Research, University College Dublin, Universidad Panamericana, Facultad de Ingenieria, Universidad Panamericana;IEEE Latin America Transactions;10-jun-21;2021;19;6;1065;1073;One of the main problems that governments face in a pandemic is preserving the public health of the country whilst reducing the negative effects on the economy. In tackling the COVID-19 pandemic, there is an implicit trade-off between the economy and the reduction in the number of cases and deaths by the virus. If governmental restrictions to combat the pandemic are very strong, the economy could be seriously damaged. Conversely, if restrictions are very mild to minimize economic losses, it would be very difficult to stop the spread of the virus. It is necessary to find an optimization model to support government decisions balancing the impacts of COVID-19 in health and economic aspects. In this paper, we propose a methodology to find out the optimal number of days per contingency phase, in such a way that public health is prioritized and the damage to the economic impact is reduced. Then, our methodology is applied to one of the most densely populated areas in the world, Mexico City. Our methodology uses an SEIR (Susceptible-Exposed-Infected-Removed) model to simulate the evolution of the pandemic, and it can be implemented utilizing either a genetic algorithm or a Deep Q-Learning algorithm. For the experiments, we propose two scenarios in which the number of days for each phase is predicted within a 120-day period. The first experiment guarantees that the number of beds is not exceeded, considering the economic impact less relevant. By contrast, the second experiment reduces the number of days in which beds are exceeded as long as the economic losses are not higher than 20%, prioritizing the economy. According to the experiments, the implementation based on genetic algorithms has a higher performance.;1548-0992;;10.1109/TLA.2021.9451253;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9451253;COVID-19,rein,deep q-learning,Genetic Algorithms,model simulation;COVID-19,Coronaviruses,Economics,Pandemics,Optimization,Genetic algorithms,Urban areas;deep learning (artificial intelligence),diseases,epidemics,genetic algorithms,medical computing;genetic algorithm,containment levels,Mexico City,public health,COVID-19 pandemic,implicit trade-off,virus,governmental restrictions,economic losses,optimization model,government decisions,contingency phase,economic impact,densely populated areas,deep Q-learning algorithm,pandemic,susceptible-exposed-infected-removed,SEIR model;;1;;;;10-jun-21;;;IEEE;IEEE Journals
EvalSeer: An Intelligent Gamified System for Programming Assignments Assessment;R. Nabil, N. E. Mohamed, A. Mahdy, K. Nader, S. Essam, E. Eliwa;Misr International University,Faculty of Computer Science,Cairo,Egypt, Misr International University,Faculty of Computer Science,Cairo,Egypt, Misr International University,Faculty of Computer Science,Cairo,Egypt, Misr International University,Faculty of Computer Science,Cairo,Egypt, Misr International University,Faculty of Computer Science,Cairo,Egypt, Misr International University,Faculty of Computer Science,Cairo,Egypt;2021 International Mobile, Intelligent, and Ubiquitous Computing Conference (MIUCC);9-jun-21;2021;;;235;242;Continuous evaluation of computer programs and providing informative assessments are crucial for computer programming students. However, swift and formative feedback can be challenging to achieve as it is usually a stressful and tedious task for professors merely through manual grading. There is an urgent need for a Learning management system (LMS) that offers instant and detailed feedback in a competitive environment for a better education experience. In this study, we introduce the EvalSeer learning management system. EvalSeer is an LMS equipped with an intelligent auto-grading engine to keep learners motivated and help them move forward. The code evaluation process covers various criteria that strengthen coding abilities and provides learners with the directions they need to improve. These criteria include coding style, code features, dynamic test cases, and successful compilation. EvalSeer uses Long short-term memory (LSTM) networks for code analysis to detect syntax errors and predict potential fixes. Also, the system shall explain suggested fixes backed up with related references. EvalSeer is an easy-to-use cloud-based system with a learner-first approach that can be applied both on-campus and in elearning systems. This work is timely with the dramatic education change, with a notable rise of e-learning due to the COVID-19 pandemic.;;978-1-6654-1243-8;10.1109/MIUCC52538.2021.9447629;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9447629;Automated assessment,programming education,gamification,competitive learning,formative feedback,Deep learning;Deep learning,Learning management systems,Electronic learning,Education,Syntactics,Ubiquitous computing,Encoding;cloud computing,computer science education,diseases,educational courses,epidemics,learning management systems,programming,recurrent neural nets,serious games (computing);intelligent gamified system,programming assignments assessment,computer programming students,code analysis,cloud based system,computer program evaluation,intelligent autograding engine,EvalSeer,learning management system,long short term memory networks,syntax error detection,e-learning systems,COVID-19 pandemic;;;;38;;9-jun-21;;;IEEE;IEEE Conferences
An Application of Data Envelopment Analysis and Machine Learning Approach to Risk Management;S. Jomthanachai, W. -P. Wong, C. -P. Lim;Faculty of Management Sciences, Prince of Songkla University, Hat Yai, Thailand, School of Management, Universiti Sains Malaysia (USM), Penang, Malaysia, Institute for Intelligent Systems, Research and Innovation, Deakin University, Geelong, VIC, Australia;IEEE Access;18-jun-21;2021;9;;85978;85994;An integrated method comprising DEA and machine learning for risk management is proposed in this paper. Initially, in the process of risk assessment, the DEA cross-efficiency method is used to evaluate a set of risk factors obtained from the FMEA. This FMEA-DEA cross-efficiency method not only overcomes some drawbacks of FMEA, but also eliminates several limitations of DEA to offer a high discrimination capability of decision units. For risk treatment and monitoring processes, an ML mechanism is utilized to predict the degree of remaining risk depending on simulated data corresponding to the risk treatment scenario. Prediction using ML is more accurate since the predictive power of this model is better than that of DEA which potentially contains errors. The motivation for this study is that the combination of the DEA and ML approaches gives a flexible and realistic choice in risk management. Based on a case study of logistics business, the results ascertain that the short-term and urgent solutions in service cost and performance are necessary to sustainable logistics operations under the COVID-19 pandemic. The prediction findings show that the risk of skilled personnel is the next concern once the service cost and performance strategies have been prioritised. This approach allow decision-makers to assess the risk level for handling forthcoming events in unusual conditions. It also serves as a useful knowledge repository such that appropriate risk mitigation strategies can be planned and monitored. The outcome of our empirical evaluation indicates that the proposed approach contributes towards robustness in sustainable business operations.;2169-3536;;10.1109/ACCESS.2021.3087623;British Academy and the Academy of Sciences Malaysia Newton Ungku Omar(grant numbers:304 /PMGT /650912 /B130), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9448528;Data envelopment analysis (DEA),DEA cross-efficiency,machine learning (ML),artificial neural network (ANN),failure mode and effect analysis (FMEA),risk management;Risk management,Monitoring,Computational modeling,Standards,Machine learning,Data envelopment analysis,Tools;data envelopment analysis,decision making,learning (artificial intelligence),logistics,risk analysis;data envelopment analysis,machine learning approach,risk management,risk assessment,risk factors,FMEA-DEA cross-efficiency method,risk treatment scenario,predictive power,ML approaches,risk level,risk mitigation strategies,risk monitoring processes,sustainable business operations,decision makers,personnel,COVID-19 pandemic,sustainable logistics operations;;1;;67;CCBY;8-jun-21;;;IEEE;IEEE Journals
Customized Impression Prediction from Radiology Reports Using BERT and LSTMs;B. Gundogdu, U. Pamuksuz, J. H. Chung, J. M. Telleria, P. Liu, F. Khan, P. J. Chang;University of Chicago, 2462 Chicago, Illinois, United States, (e-mail: gundogdu@uchicago.edu), University of Illinois at Urbana-Champaign, 14589 Urbana, Illinois, United States, (e-mail: pamuksu2@illinois.edu), University of Chicago, 2462 Chicago, Illinois, United States, (e-mail: JChung@radiology.bsd.uchicago.edu), University of Chicago, 2462 Chicago, Illinois, United States, (e-mail: Jessica.Telleria@uchospitals.edu), University of Chicago, 2462 Chicago, Illinois, United States, (e-mail: pliu@radiology.bsd.uchicago.edu), Inference Analytics Inc., Chicago, Illinois, United States, (e-mail: farrukh@inferenceanalytics.com), Radiology Informatics, School of Medicine, University of Chicago, 2462 Chicago, Illinois, United States, (e-mail: pchang@radiology.bsd.uchicago.edu);IEEE Transactions on Artificial Intelligence;;2021;PP;99;1;1;Clinical language processing has become an attractive field with the improvements of deep learning applications and the abundance of large unstructured narratives in the healthcare records. The capability to extract unstructured information from raw text to provide actionable information for healthcare personnel plays a vital role in healthcare workflows. In this study, we introduce a deep learning approach to automate the generation of radiology impressions by analyzing radiology findings and patient background information of each examination. Since the impression section of a radiology report is an essential conclusion, any errors can prove to be detrimental. Thus, we developed a deep learning system to prevent important clinical findings from being overlooked by using almost 1 million de-identified radiology reports obtained from the University of Chicago Medicine over the last twelve years. We propose to automate the generation of radiology reports by incorporating sequence to sequence neural network models with the power of Bidirectional Encoder Representations from Transformers (BERT). We tested our model in a real-time experimental setup with radiologists in a top tier academic institution and statistically validated the performance by using ROUGE metrics. Clinical validations have shown that 76 percent of our predictions are at least as accurate as human-generated impressions by radiologists. Furthermore, statistical validation metrics demonstrated higher ROUGE scores compared to previously published studies over two different test sets.;2691-4581;;10.1109/TAI.2021.3086435;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9447166;BERT,Clinical Language Processing,Deep Learning,LSTM,Neural Networks,Impression,Radiology;Radiology,Medical services,Predictive models,COVID-19,Deep learning,Task analysis,Natural language processing;;;;;;;IEEE;4-jun-21;;;IEEE;IEEE Early Access Articles
Depression Intensity Estimation via Social Media: A Deep Learning Approach;S. Ghosh, T. Anwar;Department of Computer Science and Engineering, IIT Ropar, Rupnagar, India, Department of Computing, Macquarie University, Sydney, NSW, Australia;IEEE Transactions on Computational Social Systems;1-dec-21;2021;8;6;1465;1474;Depression has become a big problem in our society today. It is also a major reason for suicide, especially among teenagers. In the current outbreak of coronavirus disease (COVID-19), the affected countries have recommended social distancing and lockdown measures. Resulting in interpersonal isolation, these measures have raised serious concerns for mental health and depression. Generally, clinical psychologists diagnose depressed people via face-to-face interviews following the clinical depression criteria. However, often patients tend to not consult doctors in their early stages of depression. Nowadays, people are increasingly using social media to express their moods. In this article, we aim to predict depressed users as well as estimate their depression intensity via leveraging social media (Twitter) data, in order to aid in raising an alarm. We model this problem as a supervised learning task. We start with weakly labeling the Twitter data in a self-supervised manner. A rich set of features, including emotional, topical, behavioral, user level, and depression-related <inline-formula> <tex-math notation=LaTeX>n </tex-math></inline-formula>-gram features, are extracted to represent each user. Using these features, we train a small long short-term memory (LSTM) network using Swish as an activation function, to predict the depression intensities. We perform extensive experiments to demonstrate the efficacy of our method. We outperform the baseline models for depression intensity estimation by achieving the lowest mean squared error of 1.42 and also outperform the existing state-of-the-art binary classification method by more than 2% of accuracy. We found that the depressed users frequently use negative words such as stress and sad, mostly post during late nights, highly use personal pronouns and sometimes also share personal events.;2329-924X;;10.1109/TCSS.2021.3084154;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9447025;COVID-19,deep learning,depression intensity estimation,mental health,social media mining;Depression,Social networking (online),Blogs,Feature extraction,COVID-19,Mental health,Deep learning;;;;;;55;IEEE;4-jun-21;;;IEEE;IEEE Journals
A Review of Various Mathematical and Deep Learning based Forecasting Methods for COVID-19 Pandemic;R. Katarya, Anjum, A. Gupta, S. Sachdeva, T. Dhamija, S. Gupta, A. Gupta, P. Kedia, V. Rai;Delhi Technological University,Department of Computer Science,New Delhi,India, Delhi Technological University,Department of Computer Science,New Delhi,India, Delhi Technological University,Department of Computer Science,New Delhi,India, National Institute of Technology,Department of Computer Science,New Delhi,India, Delhi Technological University,Department of Electronics and Communication Engineering,New Delhi,India, Delhi Technological University,Department of Civil Engineering,New Delhi,India, Delhi Technological University,Department of Electrical Engineering,New Delhi,India, Delhi Technological University,Department of Electrical Engineering,New Delhi,India, Delhi Technological University,Department of Electronics and Communication Engineering,New Delhi,India;2021 7th International Conference on Advanced Computing and Communication Systems (ICACCS);3-jun-21;2021;1;;874;878;With over a hundred million cases worldwide and thousands coming daily, the outbreak of COVID-19 has seriously affected many countries' healthcare and economic situations. A precise and efficient model for predicting new COVID-19 cases and the pandemic's future dynamics can be highly beneficial in such distressing conditions. These predictions might help the hospitals and the concerned authorities to devise necessary and preliminary arrangements for the patients in advance. This will be able to positively prevent the second or third wave of the pandemic spread. In the following study, we have composed a brief analysis of the appropriate and recent tools used for forecasting COVID-19. In this study, we have categorized these forecasting techniques into two broad classes, viz. Mathematical modeling based and Deep Learning-based. These predictions prepare us against any future threat and consequence that may occur in the future.;2575-7288;978-1-6654-0521-8;10.1109/ICACCS51430.2021.9441966;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9441966;COVID-19,Deep Learning,Mathematical Modeling,Time Series Forecasting;COVID-19,Deep learning,Pandemics,Computational modeling,Predictive models,Tools,Market research;deep learning (artificial intelligence),diseases,epidemics,health care,hospitals,medical computing;hospitals,healthcare situations,COVID-19 forecasting,economic situations,COVID-19 pandemic,deep learning,mathematical modeling;;;;21;;3-jun-21;;;IEEE;IEEE Conferences
Healthcare Operations and Black Swan Event for COVID-19 Pandemic: A Predictive Analytics;J. P. Devarajan, A. Manimuthu, V. R. Sreedharan;Operations and Supply Chain Management area, National Institute of Industrial Engineering (NITIE), Mumbai 400087 India (e-mail: jinilpersis@gmail.com)., Nanyang Technological University, Singapore 639798 Singapore (e-mail: arunmozhi.m@ntu.edu.sg)., BEAR Lab, Rabat Business School, Université Internationale de Rabat, Rabat 11103 Morocco (e-mail: raja.sreedharan@uir.ac.ma).;IEEE Transactions on Engineering Management;;2021;PP;99;1;15;COVID-19 pandemic has questioned the way healthcare operations take place globally as the healthcare professionals face an unprecedented task of controlling and treating the COVID-19 infected patients with a highly straining and draining facility due to the erratic admissions of infected patients. However, COVID-19 is considered as a white swan event. Yet, the impact of the COVID-19 pandemic on healthcare operations is highly uncertain and disruptive making it as a black swan event. Therefore, the study explores the impact of the COVID-19 outbreak on healthcare operations and develops machine learning-based forecasting models using time series data to foresee the progression of COVID-19 and further using predictive analytics to better manage healthcare operations. The prediction error of the proposed model is found to be 0.039 for new cases and 0.006 for active COVID-19 cases with respect to mean absolute percentage error. The proposed simulated model further could generate predictive analytics and yielded future recovery rate, resource management ratios, and average cycle time of a patient tested COVID-19 positive. Further, the study will help healthcare professionals to devise better resilience and decision-making for managing uncertainty and disruption in healthcare operations.;1558-0040;;10.1109/TEM.2021.3076603;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9445568;COVID-19 (novel corona),data analytics,deep learning,extreme learning machine (ELM),long short-term memory (LSTM),multilayer perceptron,prediction,time series;Medical services,COVID-19,Time series analysis,Predictive models,Pandemics,Data models,Corona;;;;;;;IEEE;2-jun-21;;;IEEE;IEEE Early Access Articles
Performance Evaluation of Machine Learning Approaches for COVID-19 Forecasting by Infectious Disease Modeling;H. Khaloofi, J. Hussain, Z. Azhar, H. F. Ahmad;CCSIT, King Faisal University,Computer Science Department,Al-Ahsa,Saudi Arabia,31982, Sejong University,Department of Data Science,South Korea, University of California,Santa Cruz,USA, CCSIT, King Faisal University,Computer Science Department,Al-Ahsa,Saudi Arabia,31982;2021 International Conference of Women in Data Science at Taif University (WiDSTaif );24 May 2021;2021;;;1;6;The use of data analytics in virology is a rapidly growing means to provide accurate and reliable information to healthcare providers. Its mechanisms allow for deeper comprehension and characterization of pathogens (i.e., virus transmission rate and behavior). Artificial intelligence and machine learning technology have shown the potential to forecast and subdue the spread of coronaviruses. When applied to extended periods, however, the ability of these prediction models to anticipate disease spread is not promising. The development of superior algorithms is essential to improving COVID-19 forecasting accuracy. This drawback has motivated us to conduct this study with the objective of developing a COVID-19 forecasting algorithm that functions over an extended period of time. This paper highlights the mechanism of the coronavirus forecast: the Deep Learning (DL) approach. The combined utilization of online data sets and the DL approach was employed in the investigation of the life cycle and spread of COVID-19 in the Kingdom of Saudi Arabia and the Kingdom of Bahrain.;;978-1-6654-4948-9;10.1109/WiDSTaif52235.2021.9430192;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9430192;COVID-19,artificial intelligent,machine learning,deep learning,time-series;COVID-19,Deep learning,Machine learning algorithms,Biological system modeling,Linear regression,Predictive models,Prediction algorithms;data analysis,deep learning (artificial intelligence),diseases,epidemics,forecasting theory,health care,Internet,medical administrative data processing;Kingdom of Bahrain,Kingdom of Saudi Arabia,deep learning approach,coronavirus disease spreading,artificial intelligence,healthcare providers,infectious disease modeling,machine learning approaches,performance evaluation,DL approach,online data sets,COVID-19 forecasting algorithm,virus transmission rate,virology,data analytics;;;;14;;24 May 2021;;;IEEE;IEEE Conferences
Predicting the Existence of COVID-19 using Machine Learning Based on Laboratory Findings;H. Turabieh, W. Ben Abdessalem Karaa;College of computer and Information Technology, Taif University,saudi arabia, High Institute of Management of Tunis, Tunis University,Tunisia;2021 International Conference of Women in Data Science at Taif University (WiDSTaif );24 May 2021;2021;;;1;7;Since December 2019, a new coronavirus disease (COVID-19) was detected in Wuhan, China, spread all over the world. Many research papers have been published to study this disease and help humans to overcome this pandemic. Here, we highlighted the prediction process of COVID-19 based on a combination between wrapper feature selected (FS) algorithm and four different classifiers, namely Convolutional Neural Network (CNN), decision trees (C4.5), nearest neighbors (kNN) and, Naïve Bayes (NB). A real dataset has been used in this paper generated by Hospital Israelita Albert Einstein at Sao Paulo, Brazil. The obtained results show an excellent performance of BGA with CNN compared to other methods with accuracy 76%.;;978-1-6654-4948-9;10.1109/WiDSTaif52235.2021.9430233;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9430233;COVID-19,Classification,Feature Selection,Machine Learning;COVID-19,Hospitals,Pandemics,Machine learning,Data science,Feature extraction,Prediction algorithms;convolutional neural nets,decision trees,diseases,learning (artificial intelligence),patient diagnosis,pattern classification;Naive Bayes classifier,COVID-19,coronavirus disease,wrapper feature,convolutional neural network,machine learning,nearest neighbors classifier,decision trees classifier;;;;30;;24 May 2021;;;IEEE;IEEE Conferences
Prediction of COVID-19 Cases in Malaysia by Using Machine Learning: A Preliminary Testing;A. N. Akramin Kamarudin, Z. Zainol, N. F. Abu Kassim, R. Sharif;School of Computer Science, Universiti Sains Malaysia,Georgetown,Malaysia, School of Computer Science, Universiti Sains Malaysia,Georgetown,Malaysia, School of Biological Science, Universiti Sains Malaysia,Georgetown,Malaysia, Universiti Kebangsaan Malaysia,Faculty of Health Science,Kuala Lumpur,Malaysia;2021 International Conference of Women in Data Science at Taif University (WiDSTaif );24 May 2021;2021;;;1;6;Estimating the spread of disease like COVID-19 is a crucial task that can reduce its impact and help the authorities to respond. Currently, the number of active cases in Malaysia is less than 50% of the accumulated points. This paper will present the most accurate machine learning model to predict the number of new possibilities for 01/04-15/04/2020 (15 days). Notably, four machine learning models and one traditional statistical prediction analysis ARIMA have been trained, tested and evaluated. The results are compared to the actual data. We found that the multilayer perceptron neural network has outperformed all models in estimating the number of new positive cases in a specific time range. However, the ARIMA model performs better in predicting recovered and death cases than the machine learning models. We have applied the root mean square error (RMSE) and mean absolute predictive error (MAPE) evaluation metrics to assess the model performance. The proposed approach can be viewed as a feasible alternative to forecast the new COVID-19 cases in Malaysia, where there is no constant seasonal trend and no past data sources for comparison. The proposed methodology is easily tractable and computationally efficient to demonstrate the number of new cases that are useful and beneficial in terms of control management.;;978-1-6654-4948-9;10.1109/WiDSTaif52235.2021.9430222;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9430222;SARS-CoV-2,pandemic,machine learning,neural network,ARIMA,time-series prediction;COVID-19,Measurement,Neural networks,Machine learning,Predictive models,Multilayer perceptrons,Market research;autoregressive moving average processes,diseases,epidemics,learning (artificial intelligence),mean square error methods,medical computing,multilayer perceptrons,neural nets,statistical analysis;COVID-19 cases,Malaysia,preliminary testing,machine learning,multilayer perceptron neural network,ARIMA model,death cases,statistical prediction analysis;;;;20;;24 May 2021;;;IEEE;IEEE Conferences
A Novel Machine Learning Based Screening Method For High-Risk Covid-19 Patients Based On Simple Blood Exams;N. Darapaneni, M. Gupta, A. R. Paduri, R. Agrawal, S. Padasali, A. Kumari, P. Purushothaman;AIML Great Learning, Northwestern University,Illinois,USA, AIML Great Learning,Bengaluru,India, AIML Great Learning,Bengaluru,India, AIML Great Learning,Bengaluru,India, AIML Great Learning,Bengaluru,India, AIML Great Learning,Bengaluru,India, AIML Great Learning,Bengaluru,India;2021 IEEE International IOT, Electronics and Mechatronics Conference (IEMTRONICS);14 May 2021;2021;;;1;6;This paper presents a predictive model to potentially identify high-risk COVID-19 infected patients based on easily analyzed circulatory blood markers. These findings can enable effective and efficient care programs for high-risk patients and periodic monitoring for the low-risk ones, thereby easing the hospital flow of patients and can further be utilized for hospital bed utilization assessment. The present machine learning-based SV-LAR model results in a high 87% f1 score, harmonic mean of 91% precision, and 83% recall to classify COVID-19, infected patients, as high-risk patients needing hospitalization.;;978-1-6654-4067-7;10.1109/IEMTRONICS52119.2021.9422534;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9422534;COVID-19,SARS-CoV-2,pandemic,patient outcomes,machine learning models;COVID-19,Deep learning,Machine learning algorithms,Hospitals,Sociology,Data models,Biomedical monitoring;blood,diseases,hospitals,learning (artificial intelligence),medical computing,patient monitoring;high-risk COVID-19 infected patients,hospital bed utilization assessment,machine learning-based SV-LAR model,circulatory blood markers,blood exams,hospitalization;;;;26;;14 May 2021;;;IEEE;IEEE Conferences
Context-Aware Speech Stress Detection in Hospital Workers Using Bi-LSTM Classifiers;A. Gaballah, A. Tiwari, S. Narayanan, T. H. Falk;Institut national de la recherche scientifique (INRS-EMT),Montreal,Canada, Institut national de la recherche scientifique (INRS-EMT),Montreal,Canada, University of Southern California,Signal Analysis and Interpretation Laboratory,Los Angeles,CA, Institut national de la recherche scientifique (INRS-EMT),Montreal,Canada;ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP);13 May 2021;2021;;;8348;8352;Hospital workers are known to work long hours in a highly stressful environment. The COVID-19 pandemic has increased this burden multi-fold. Pre-COVID statistics already showed that one in every three nurses reported burnout, thus affecting patient satisfaction and the quality of their provided service. Real-time monitoring of burnout, and other underlying factors, such as stress, could provide feedback not only to the clinical staff, but also to hospital administrators, thus allowing for supportive measures to be taken early. In this paper, we present a context-aware speech-based system for stress detection. We consider data from 144 hospital workers who were monitored during their daily shifts over a 10-week period, subjective stress readings were collected daily. Wearable devices measured speech features and physiological readings, such as heart rate. Environment sensors, in turn, were used to track staff movement within the hospital. Here, we show the importance of context-awareness for stress level detection based on a bidirectional LSTM deep neural network. In particular, we show the importance of hospital location and circadian rhythm based contextual cues for stress prediction. Overall, we show improvements as high as 14% in F1 scores once context is incorporated, relative to using the speech features alone.;2379-190X;978-1-7281-7605-5;10.1109/ICASSP39728.2021.9414666;Office of the Director of National Intelligence, Intelligence Advanced Research Projects Activity, ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9414666;;Hospitals,Tracking,Wearable computers,Signal processing,Real-time systems,Sensors,Speech processing;acoustic signal processing,circadian rhythms,diseases,health care,hospitals,medical signal processing,personnel,recurrent neural nets,signal classification,speech recognition,statistics,ubiquitous computing;COVID-19 pandemic,pre-COVID statistics,real-time monitoring,hospital administrators,context-aware speech-based system,speech features,stress level detection,bidirectional LSTM deep neural network,hospital location,circadian rhythm,stress prediction,context-aware speech stress detection,Bi-LSTM classifiers;;;;37;;13 May 2021;;;IEEE;IEEE Conferences
Data Science to Fight Against COVID-19;;;2021 IEEE Virtual Reality and 3D User Interfaces (VR);10 May 2021;2021;;;xxiv;xxiv;Summary form only given, as follows. The complete presentation was not made available for publication as part of the conference proceedings. In my talk, I will describe the work that we have done as Commissioner on AI and COVID-19 for the President of the Valencian Region. Since March 2020, I have been leading a multi-disciplinary team of 20+ volunteer scientists been working on 4 large areas: (1) human mobility modeling, (2) computational epidemiological models (both metapopulation, individual and LSTM-based models), (3) predictive models, and (4) citizen surveys via the COVID19impactsurvey (https://covid19impactsurvey.org) with over 500,000 answers worldwide. I will describe the results that we have produced in each of these areas and will share the lessons learned in this very special initiative of collaboration between the civil society at large (through the survey), the scientific community (through the Expert Group) and a public administration (through the Commissioner at the Presidency level).;2642-5254;978-1-6654-1838-6;10.1109/VR50410.2021.00014;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9417637;;;;;;;;10 May 2021;;;IEEE;IEEE Conferences;;
Evaluation of Time Series Forecasting Models for Estimation of PM2.5 Levels in Air;S. Garg, H. Jindal;Jaypee University of Information Technology,Department of Computer Science,Solan, Jaypee University of Information Technology,Department of Computer Science,Solan;2021 6th International Conference for Convergence in Technology (I2CT);10 May 2021;2021;;;1;8;Air contamination in urban areas has risen consistently over the past few years. Due to expanding industrialization and increasing concentration of toxic gases in the climate, the air is getting more poisonous step by step at an alarming rate. Since the arrival of the Coronavirus pandemic, it is getting more critical to lessen air contamination to reduce its impact. The specialists and environmentalists are making a valiant effort to gauge air contamination levels. However, it's genuinely unpredictable to mimic sub-atomic communication in the air, which brings about off-base outcomes. There has been an ascent in using machine learning and deep learning models to foresee the results on time series data. This study adopts ARIMA, FBProphet, and deep learning models such as LSTM, 1D-CNN, to estimate the concentration of PM2.5 in the environment. Our predicted results convey that all adopted methods give comparative outcomes in terms of average root mean squared error. However, the LSTM outperforms all other models with reference to mean absolute percentage error.;;978-1-7281-8876-8;10.1109/I2CT51068.2021.9418215;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9418215;Air pollution,PM2.5,Forecasting,Time series,Machine learning,LSTM,CNN,ARIMA,FBProphet;Deep learning,Gases,Pandemics,Atmospheric modeling,Time series analysis,Urban areas,Predictive models;air pollution,forecasting theory,learning (artificial intelligence),mean square error methods,time series;time series forecasting models,urban areas,toxic gases,poisonous step,alarming rate,Coronavirus pandemic,air contamination levels,machine learning,deep learning models,time series data;;1;;22;;10 May 2021;;;IEEE;IEEE Conferences
Content-based Clothing Recommender System using Deep Neural Network;N. Yarahmadi Gharaei, C. Dadkhah, L. Daryoush;K. N. Toosi university of Technology,Faculty of Computer Engineering,Tehran,Iran, K. N. Toosi university of Technology,Faculty of Computer Engineering,Tehran,Iran, Amirkabir University of Technology (TehranPolytechnic),Amirkabir Robotic Research Institute(ARRI),Tehran,Iran;2021 26th International Computer Conference, Computer Society of Iran (CSICC);7 May 2021;2021;;;1;6;A recommender system primary purpose is to provide a series of item suggestions on a topic to its user. Deep learning is used in many fields and solved difficult and complex problems with large volumes of data. Deep learning can also be used in referral systems. Today, online shopping systems are looking for a method that can recommend items according to the user preference and interest in order to increase their sales. Clothing sales systems offer a set of recommendation based on the needs and interests of the users. Today, due to the current situation caused by the Coronavirus, the majority of tasks are done online. In this paper, we propose a content-based clothing recommender system using deep neural network. In content-based systems, product features are required for prediction of unobserved items ratings. In our proposed system by using a deep neural network, the cloth category is obtained and the need to manually extract the product features is eliminated by producing the required features with a large and useful volume. The advantage of this system is that it uses the same network to specify gender as a feature in making suggestions then shows the results to the user. Different machine learning algorithms are tested and analyzed with and without considering demographic information such as gender. The experimental results show that the loss of our proposed system is lower than the other related systems and solves the cold start problem for new items. Our proposed system also recommends novel, relevant and unexpected items.;;978-1-6654-1241-4;10.1109/CSICC52343.2021.9420544;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9420544;Clothing,Recommender System,Deep learning,Demographic,Feature Extraction,Cold start,Content,Coronavirus;Deep learning,Measurement,Machine learning algorithms,Computational modeling,Clothing,Neural networks,Feature extraction;clothing,convolutional neural nets,deep learning (artificial intelligence),recommender systems,retail data processing;content-based clothing recommender system,deep neural network,deep learning,online shopping systems,user preference,clothing sales systems,content-based systems,product features,machine learning algorithms,demographic information;;;;17;;7 May 2021;;;IEEE;IEEE Conferences
Optimal ATM Cash Replenishment Planning in a Smart City using Deep Q-Network;M. Kiyaei, F. Kiaee;University of Tehran,Faculty of Management & Accounting Farabi Campus,Finance Dept.,Qom,Iran, Technical and Vocational University (TVU),Faculty of Shariaty,Dept. of Electrical & Computer Engineering,Tehran,Iran;2021 26th International Computer Conference, Computer Society of Iran (CSICC);7 May 2021;2021;;;1;5;ATMs are no longer just machines, these connected devices are smart, intelligent things in the Internet of Things (IoT). Access to cash for many in society is remaining essential during the current COVID-19 lock-down around the globe. A cash inventory management system is necessary to decide whether ATM should be replenished on each day of the week. In this paper, we study the real-time cash replenishment planning problem under outflow uncertainty where the fee of the security companies grows if the replenishment ends up falling on a weekends/holidays. Our model is based by the Double Deep Q-Network (DQN) algorithm which combines popular Q-learning with a deep neural network. The proposed method is used to control replenishment operation in order to minimize replenishment cost where the cash demand changes dynamically at each day. Experiment results show that our proposed method can work effectively on the real outflow time-series and it is able to reduce the ATM operational cost compared with the other state-of-the-art cash demand prediction schemes.;;978-1-6654-1241-4;10.1109/CSICC52343.2021.9420561;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9420561;cash replenishment planning,deep learning,ATM,reinforcement learning,double Q-network;Learning systems,Uncertainty,Online banking,System dynamics,Smart cities,Neural networks,Real-time systems;automatic teller machines,banking,Internet of Things,inventory management,neural nets,optimisation,smart cities,time series;optimal ATM cash replenishment planning,smart city,intelligent things,COVID-19 lock-down,cash inventory management system,real-time cash replenishment planning problem,outflow uncertainty,double deep Q-network algorithm,deep neural network,outflow time-series,ATM operational cost,Internet of Things,cash demand prediction schemes,security companies,DQN algorithm,Q-learning;;;;18;;7 May 2021;;;IEEE;IEEE Conferences
ANN based COVID -19 Prediction and Symptoms Relevance Survey and Analysis;D. N, K. K. G;Vel Tech Rangarajan Dr. Sagunthala R&D Institute of Science and Technology, Avadi,Department of ECE,Chennai,India, Vel Tech Rangarajan Dr. Sagunthala R&D Institute of Science and Technology, Avadi,Department of ECE,Chennai,India;2021 5th International Conference on Computing Methodologies and Communication (ICCMC);6 May 2021;2021;;;1805;1808;The main focus of this Research is to see how one can easily predict if he/she has been infected by COVID-19. Another aspect is deciding which COVID-19 symptom is more likely to show positive result of virus contamination. The virus has been declared as a pandemic and has affected more than 66,729,375 people across 220 countries and has also cost the lives of 1,535,982 people [source : who.int] as of the time this paper is being written. Research still predicts that another second wave is to hit soon. The required objective is obtained using complex machine learning algorithms that are able to predict, up to an extent the probability that the person has covid-19 and also if the related covid-19 symptoms provided are relevant to the condition or not. The algorithm used is a LOGISTIC REGRESSION algorithm that is used as a classification tool to separate the data into binary results, which in our case is if the person has covid-19 or not (YES OR NO). The dataset used to train this machine learning algorithm is obtained from online resources and a public survey.The machine learning model as of now has been able to predict the probability of virus contamination by 66.89% accuracy, further the model is able to relate if a given symptom is valid or not. With this we are able to conclude that the model is working fine and only fine tuning of the model is required in order to improve and enhance the accuracy and probability of exact results. The result were then improved using ANN( Artificial Neural Networks) but as it is computational expensive and due to lack of resources the expected performance cannot be met. The maximum accuracy achieved with ANNs was about 71%.;;978-1-6654-0360-3;10.1109/ICCMC51019.2021.9418448;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9418448;Artificial Neural Networks,machine learning model,Relu,ADAM;COVID-19,Machine learning algorithms,Computational modeling,Artificial neural networks,Machine learning,Predictive models,Prediction algorithms;diseases,epidemics,learning (artificial intelligence),medical computing,neural nets,probability,regression analysis;logistic regression,machine learning,COVID-19 prediction,symptoms relevance survey,classification tool,virus contamination probability,ANN,artificial neural network;;;;15;;6 May 2021;;;IEEE;IEEE Conferences
An Advanced Fog based Health Care System Using ANN for the prediction of Asthma;C. K. Priya, M. Sudhakar, J. Lingampalli, C. Z. Basha;Central University of Andhra Pradesh,Department of CSE,Ananthapur,AP,India, Marri Laxman Reddy Institute of Technology and Management,Department of EEE,Hyderabad,Telangana,India, Koneru Lakshmaiah Education Foundation,Department of CSE,Vaddeswaram,AP,India, Koneru Lakshmaiah Education Foundation,Department of CSE,Vaddeswaram,AP,India,522502;2021 5th International Conference on Computing Methodologies and Communication (ICCMC);6 May 2021;2021;;;1138;1145;Around 300 million people have Asthma throughout the world. Asthma is one of the very common health issues among adults and children. As per the present situation of covid-19, asthma patients are very much prone to be affected. Around 1000 to 1500 people die per day due to asthma. Deaths can be avoided if asthma patients are taken care of in the initial stages. Much care has to be taken especially in the present scenario. There is a need for continuous monitoring for asthma patients. A fog-based system for health care is proving to be the best for providing a high quality of monitoring and control of the disease. Here a framework that is based on the IoT(Internet of Things) is proposed for assessing the asthma levels in the patients and to avoid the risk of being hospitalized. Here the artificial neural network-based system is proposed which helps in predicting asthma as well as sending the alerts to the respective patient and the family concerns. And this achieves a high accuracy level of 86%.;;978-1-6654-0360-3;10.1109/ICCMC51019.2021.9418248;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9418248;;COVID-19,Pediatrics,Medical services,Artificial neural networks,Respiratory system,Monitoring;diseases,distributed processing,health care,Internet of Things,medical diagnostic computing,neural nets,patient diagnosis,patient monitoring;artificial neural network,fog based health care system,asthma patient monitoring,IoT,Internet of Things;;6;;24;;6 May 2021;;;IEEE;IEEE Conferences
Neural Network based Real Time Sign Language Interpreter for Virtual Meet;D. A. Janeera, K. Mukilan Raja, U. K. R. Pravin, M. Krishor Kumar;Sri Krishna College of Engineering and Technology,Department ECE,Coimbatore,India, Sri Krishna College of Engineering and Technology,Department of ECE,Coimbatore,India, Sri Krishna College of Engineering and Technology,Department of ECE,Coimbatore,India, Sri Krishna College of Engineering and Technology,Department of ECE,Coimbatore,India;2021 5th International Conference on Computing Methodologies and Communication (ICCMC);6 May 2021;2021;;;1593;1597;Due to the Covid-19 pandemic, people were forced to stay home, and most professions switched to Work From Home mode. The world switched to Video Conferencing to stay connected from remote environment. This made Translators unavailable to the hearing impaired. This makes it challenging for deaf-mute people to communicate with other people since there are no credible tools present to translate it real-time in these applications. So, a Translator built within these video conferencing applications would be helpful in communication for these people. Neural Network algorithm is used in our model to predict the signs and translate them. This model is implemented in a video conferencing application which will make the use of the Sign Gesture Translation feature and the other person using the application will receive the translation in text on a real time basis.;;978-1-6654-0360-3;10.1109/ICCMC51019.2021.9418238;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9418238;Deaf-mute,Video Conferencing,Neural Network,Sign Gesture Translation,Work from Home,Translator;COVID-19,Pandemics,Assistive technology,Neural networks,Switches,Streaming media,Tools;emergency services,epidemics,handicapped aids,human computer interaction,neural nets,program interpreters,real-time systems,sign language recognition,teleconferencing;real time sign language interpreter,virtual meet,Covid-19 pandemic,remote environment,deaf-mute people,translator,video conferencing,neural network,real time basis,sign gesture translation feature,work from home mode;;;;15;;6 May 2021;;;IEEE;IEEE Conferences
Performance Comparison of Machine Learning Algorithms for Prediction of Students’ Social Engagement;J. B. Prajapati, S. K. Patel;Ganpat University,Acharya Motibhai Patel Institute of Computer Studies,Gujarat,India, Ganpat University,Acharya Motibhai Patel Institute of Computer Studies,Gujarat,India;2021 5th International Conference on Computing Methodologies and Communication (ICCMC);6 May 2021;2021;;;947;951;The various techniques and algorithms of ML & DL are becoming popular for prediction with different level of accuracy. This paper includes performance comparison of few machine learning algorithms in the reference of student social engagement during covid-19 pandemic period. In this study, the comparison of Naïve Bayes, J48 tree, REPTree and Random forest algorithm is carried on structured dataset of 1200+ instance. In this paper, study proposes & scrutinizes commonly used social app & platform. Further, it compares them with the various ML approach. The objective of this study is to foreseeing the correlation between student social engagement for one the most popular social engagement platform during covid-19 pandemic. This paper focusses on accuracy, F-measure and time to summarize comparison result. The findings of the study and dynamic analysis indicate ML/Deep learning algorithm can lead better accuracy and other factor for preprocessed student social engagement dataset. The finding can predict engagement of students for most popular social media platform with performance comparison of ML algorithm.;;978-1-6654-0360-3;10.1109/ICCMC51019.2021.9418260;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9418260;Students,Social Media Platform,Machine Learning,Classification;COVID-19,Freeware,Machine learning algorithms,Social networking (online),Pandemics,Heuristic algorithms,Multimedia Web sites;learning (artificial intelligence),random forests,social networking (online),social sciences computing,trees (mathematics);preprocessed student social engagement dataset,social media platform,ML algorithm,machine learning algorithms,covid-19 pandemic period,random forest algorithm,social app,social engagement platform,DL algorithm,dynamic analysis,Naïve Bayes,J48 tree,REPTree;;;;18;;6 May 2021;;;IEEE;IEEE Conferences
Pay Attention to Evolution: Time Series Forecasting with Deep Graph-Evolution Learning;G. Spadon, S. Hong, B. Brandoli, S. Matwin, J. F. Rodrigues-Jr, J. Sun;Computer Science, University of Sao Paulo, Sao Carlos, Sao Paulo, Brazil, 13560-970 (e-mail: spadon@usp.br), National Institute of Health Data Science, Peking University, Beijing, China, 100191, Institute of Medical Technology, Peking University, Beijing, China, 100191 (e-mail: hongshenda@pku.edu.cn), Computer Science, Dalhousie University, Halifax, Nova Scotia, Canada, B3H1W5 (e-mail: brunobrandoli@dal.ca), Computer Science, Dalhousie University, Halifax, Nova Scotia, Canada, B3H1W5 (e-mail: stan@cs.dal.ca), Computer Science, University of Sao Paulo, Sao Carlos, Sao Paulo, Brazil, 13560-970 (e-mail: junio@icmc.usp.br), Computer Science, Georgia Institute of Technology, Atlanta, Georgia, United States, 30332 (e-mail: jsun@cc.gatech.edu);IEEE Transactions on Pattern Analysis and Machine Intelligence;;2021;PP;99;1;1;Time-series forecasting is one of the most active research topics in artificial intelligence. A still open gap in that literature is that statistical and ensemble learning approaches systematically present lower predictive performance than deep learning methods. They generally disregard the data sequence aspect entangled with multivariate data represented in more than one time series. Conversely, this work presents a novel neural network architecture for time-series forecasting that combines the power of graph evolution with deep recurrent learning on distinct data distributions, we named our method Recurrent Graph Evolution Neural Network (ReGENN). The idea is to infer multiple multivariate relationships between co-occurring time-series by assuming that the temporal data depends not only on inner variables and intra-temporal relationships (i.e., observations from itself) but also on outer variables and inter-temporal relationships (i.e., observations from other-selves). An extensive set of experiments was conducted comparing ReGENN with dozens of ensemble methods and classical statistical ones, showing sound improvement of up to 64.87% over the competing algorithms. Furthermore, we present an analysis of the intermediate weights arising from ReGENN, showing that by looking at inter and intra-temporal relationships simultaneously, time-series forecasting is majorly improved if paying attention to how multiple multivariate data synchronously evolve.;1939-3539;;10.1109/TPAMI.2021.3076155;Conselho Nacional de Desenvolvimento Cientfico e Tecnolgico(grant numbers:167967/2017-7,305580/2017-5,406550/2018-2), National Science Foundation(grant numbers:CCF-1533768,IIS-1418511,IIS-1838042), Fundao de Amparo Pesquisa do Estado de So Paulo(grant numbers:2014/25337-0,2016/17078-0,2017/08376-0,2018/17620-5,2019/04461-9,2020/07200-9), National Institute of Health(grant numbers:NIH R01 1R01NS107291-01,R56HL138415), Coordenao de Aperfeioamento de Pessoal de Nvel Superior, ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9416768;Time Series,Graph Evolution,Representation Learning;Forecasting,Time series analysis,COVID-19,Predictive models,Evolution (biology),Sun,Recurrent neural networks;;;;2;;;CCBY;27-apr-21;;;IEEE;IEEE Early Access Articles
Collaborative city digital twin for the COVID-19 pandemic: A federated learning solution;J. Pang, Y. Huang, Z. Xie, J. Li, Z. Cai;College of Computer Science and Technology, Qingdao University, Qingdao 266000, China, Business School, Qingdao University, Qingdao 266000, China, College of Computing and Software Engineering, Kennesaw State University, Atlanta, GA 30060, USA, College of Computer Science and Technology, Jilin University, Changchun 130012, China, College of Computer Science and Technology, Qingdao University, Qingdao 266000, China, Department of Computer Science, Georgia State University, Atlanta, GA 30303, USA;Tsinghua Science and Technology;20-apr-21;2021;26;5;759;771;The novel coronavirus, COVID-19, has caused a crisis that affects all segments of the population. As the knowledge and understanding of COVID-19 evolve, an appropriate response plan for this pandemic is considered one of the most effective methods for controlling the spread of the virus. Recent studies indicate that a city Digital Twin (DT) is beneficial for tackling this health crisis, because it can construct a virtual replica to simulate factors, such as climate conditions, response policies, and people's trajectories, to help plan efficient and inclusive decisions. However, a city DTsystem relies on long-term and high-quality data collection to make appropriate decisions, limiting its advantages when facing urgent crises, such as the COVID-19 pandemic. Federated Learning (FL), in which all clients can learn a shared model while retaining all training data locally, emerges as a promising solution for accumulating the insights from multiple data sources efficiently Furthermore, the enhanced privacy protection settings removing the privacy barriers lie in this collaboration. In this work, we propose a framework that fused city DT with FL to achieve a novel collaborative paradigm that allows multiple city DTs to share the local strategy and status quickly. In particular, an FL central server manages the local updates of multiple collaborators (city DTs), providing a global model that is trained in multiple iterations at different city DT systems until the model gains the correlations between various response plans and infection trends. This approach means a collaborative city DT paradigm fused with FL techniques can obtain knowledge and patterns from multiple DTs and eventually establish a global view of city crisis management. Meanwhile, it also helps improve each city's DT by consolidating other DT's data without violating privacy rules. In this paper, we use the COVID-19 pandemic as the use case of the proposed framework. The experimental results on a real dataset with various response plans validate our proposed solution and demonstrate its superior performance.;1007-0214;;10.26599/TST.2021.9010026;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9409764;COVID-19,Digital Twin (DT),Federated Learning (FL),deep learning;Urban areas,COVID-19,Data models,Collaboration,Predictive models,Pandemics,Training;data privacy,diseases,emergency management,groupware,learning (artificial intelligence);COVID-19 pandemic,federated learning solution,appropriate response plan,city DTsystem,high-quality data collection,appropriate decisions,multiple data sources,novel collaborative paradigm,multiple city DTs,multiple collaborators,response plans,collaborative city DT paradigm,city crisis management,DT's data,collaborative city digital twin;;5;;;;20-apr-21;;;TUP;TUP Journals
Optimizing Broad Learning System Hyper-parameters through Particle Swarm Optimization for Predicting COVID-19 in 184 Countries;C. Zhan, Z. Wu, Q. Wen, Y. Gao, H. Zhang;School of Computing, South China Normal University,Guangzhou,China, School of Electrical and Computer Engineering, Nanfang College of Sun Yat-Sen University,Guangzhou,China, School of Computer Science and Engineering, South China University of Technology,Guangzhou,China, School of Computer Science and Engineering, South China University of Technology,Guangzhou,China, Shenzhen Graduate School, Harbin Institute of Technology,Shenzhen,China;2020 IEEE International Conference on E-health Networking, Application & Services (HEALTHCOM);14-apr-21;2021;;;1;6;The Coronavirus Disease 2019 (COVID-19) began to outbreak since December 2019 and widely spread over the world. How to accurately predict the spread of COVID-19 is one of the essential issues for controlling the pandemic. This study establishes a general model that can predict the trend of COVID-19 in a country based on historical COVID-19 data in 184 countries. First, Savitzky-Golay (S-G) filter is utilized to detect multiple waves of COVID-19 in a country. Then, a PSO-SIR (particle swarm optimization susceptible-infected-recovery) model is provided for data augmentation. Finally, a novel PSO-BLS (particle swarm optimization broad learning system) is proposed for predicting the trend of COVID-19. Experimental results show that compared with the deep learning models (ANN, CNN, LSTM, and GRU), the PSO-BLS algorithm has higher accuracy and stability in predicting the number of active infected cases and removed cases.;;978-1-7281-6267-6;10.1109/HEALTHCOM49281.2021.9399020;National Science Foundation of China(grant numbers:61703355), Science and Technology Program of Guangzhou, China(grant numbers:201904010224,201804010292), Natural Science Foundation of Guangdong Province, China(grant numbers:2020A1515010761), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9399020;Covid-19,Broad Learning,Particle Swarm Optimization,Epidemiological model,Forecasting;COVID-19,Learning systems,Heuristic algorithms,Predictive models,Prediction algorithms,Market research,Particle swarm optimization;diseases,learning (artificial intelligence),medical computing,particle swarm optimisation;PSO-BLS algorithm,particle swarm optimization susceptible-infected-recovery model,Savitzky-Golay filter,Coronavirus Disease 2019,broad learning system hyper-parameter optimization,particle swarm optimization broad learning system,PSO-SIR model,historical COVID-19 data,COVID-19 prediction;;1;;20;;14-apr-21;;;IEEE;IEEE Conferences
Deep Neural Architecture for Face mask Detection on Simulated Masked Face Dataset against Covid-19 Pandemic;A. Negi, K. Kumar, P. Chauhan, R. S. Rajput;National Institute of Technology,Department of Computer Science and Engineering,Srinagar,Uttarakhand,India,246174, National Institute of Technology,Department of Computer Science and Engineering,Srinagar,Uttarakhand,India,246174, G.B. Pant University of Agriculture and Technology,College of Technology,Uttarakhand,India,263153, G.B. Pant University of Agriculture and Technology,Statistics and Computer Science,Department of Mathematics,Uttarakhand,India,263153;2021 International Conference on Computing, Communication, and Intelligent Systems (ICCCIS);12-apr-21;2021;;;595;600;The dangerous COVID-19 (SARS-CoV-2) is rising steadily and globally, with more than 72,851,747 confirmed cases observed to WHO including 1,643,339 deaths till 17 December 2020. The country's economy is now almost fully halted, people are stuck up and investment becomes deteriorating. So, this is turning to worry of the government for a development and health. Health organizations are often desperate for evolving decision-making innovations to overcome this viral virus and encourage people to receive rapid and effective responses in real-time. Thus, it is important to create auto-mechanisms as a preventive shield to ensure healthy humanity against SARS-CoV-2. Advanced analytics methods and other strategies could also empower researchers, learners and the pharmaceutical industry to acknowledge the hazardous COVID-19 and speed it up care procedures by efficiently testing vast volumes of research data. The prevention method consequence is being used to effectively manage, calculate, forecast and monitor current infected people and future potential cases. Therefore, we proposed CNN and VGG16 based deep learning models to incorporate and enforce AI-based precautionary measures to detect the face mask on Simulated Masked Face Dataset (SMFD). This technique is capable of recognizing masked and unmasked faces to help monitor safety breaches, facilitate the use of face masks, and maintain a secure working atmosphere.;;978-1-7281-8529-3;10.1109/ICCCIS51004.2021.9397196;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9397196;CNN,Deep Learning,Data Augmentation,Face Mask Detection,Simulated Masked Face Dataset (SMFD),VGG 16,WHO;COVID-19,Pandemics,Face recognition,Biological system modeling,Atmospheric modeling,Monitoring,Testing;convolutional neural nets,decision making,diseases,learning (artificial intelligence),medical computing,microorganisms,neural net architecture,object detection,patient diagnosis,safety;deep neural architecture,face mask detection,covid-19 pandemic,dangerous COVID-19,SARS-CoV-2,country,health organizations,decision-making innovations,rapid responses,effective responses,preventive shield,advanced analytics methods,hazardous COVID-19,prevention method consequence,current infected people,future potential cases,deep learning models,simulated masked face dataset;;2;;15;;12-apr-21;;;IEEE;IEEE Conferences
Comparative Analysis of Approaches to Prediction of Quantitative Parameters During a Pandemic;V. Kolomensiy, G. Firsov;National Research Nuclear University MEPhI,(Moscow Engineering Physics Institute),Moscow,Russia, National Research Nuclear University MEPhI,(Moscow Engineering Physics Institute),Moscow,Russia;2021 IEEE Conference of Russian Young Researchers in Electrical and Electronic Engineering (ElConRus);9-apr-21;2021;;;464;467;The purpose of this paper is to study and compare several approaches to predict quantitative parameters of an epidemiological situation. These parameters change in time is not stochastic and chaotic. For instance, the number of total infection cases increases exponentially in the beginning but tends to have a linear trend later. Such processes can be modeled in a variety of ways, for example, with the SEIR model or its modifications. This paper also compares time series models, like exponential smoothing, autoregressive models, and a neural network in application to the target task. This article describes a result of a comparison of these algorithms, and an explanation of obtained results, for instance how some characteristics of target features describe a more accurate prediction of future values by the modified SEIR model, rather than an exponential smoothing process or Holt-Winters method.;2376-6565;978-1-6654-0476-1;10.1109/ElConRus51938.2021.9396350;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9396350;epidemic,forecasting,mathematical modeling,exponential smoothing,compartmental model,autoregressive model,neural network;COVID-19,Training,Smoothing methods,Pandemics,Predictive models,Data models,Mathematical model;autoregressive processes,diseases,epidemics,neural nets,time series;pandemic,epidemiological situation,total infection cases,time series,autoregressive models,SEIR,exponential smoothing,comparative analysis,quantitative parameters,neural network,Holt-Winters method,susceptible-exposed-infectious-recovered;;;;8;;9-apr-21;;;IEEE;IEEE Conferences
Quantification of Compensatory Torso Motion in Post-Stroke Patients Using Wearable Inertial Measurement Units;G. Nguyen, J. Maclean, L. Stirling;Department of Aeronautics and Astronautics, Massachusetts Institute of Technology, Cambridge, MA, USA, Department of Occupational Therapy, Massachusetts General Hospital, Boston, MA, USA, Department of Industrial and Operations Engineering, University of Michigan, Ann Arbor, MI, USA;IEEE Sensors Journal;30-jun-21;2021;21;13;15349;15360;Occupational Therapy (OT) tasks performed at home are not usually observable by a clinician. For remote environments, wearable sensor technologies could provide quantitative assessment of movement strategies to support clinical evaluation via telemedicine. This work presents an algorithm for estimating torso orientation and an individualized metric of compensatory torso motion for upper extremity tasks using an Inertial Measurement Unit (IMU) worn on the sternum. Two post-stroke males with hemiparesis and two healthy age-matched males were evaluated during a series of OT assessments, including active range of motion, pinch strength, standing balance, Moberg pick-up test, Nine-hole peg test, and a custom peg board grasp task. Torso orientation was estimated by decomposing IMU orientation into angles (pitch, roll, yaw) in each anatomical plane (sagittal, coronal, transverse) and referenced against standing balance posture. For each participant, a threshold of nominal torso motion was created from the variance in orientation for tasks performed with the Dominant or Unaffected arm. A percentage of time out of range (PTOR) of nominal variation was developed to distinguish operationally relevant differences. In this study, large PTOR values (greater than 30%) were consistent with OT observations of notable compensatory movement. IMU sensitivity to sensor-to-torso alignment was also evaluated in simulation and demonstrated interactions between pitch and roll angles when an IMU misalignment existed about the yaw axis. These case studies support the use of wearable IMUs to quantitatively assess compensatory torso motions and convey operationally relevant information about movement strategy to a clinician without the use of visual observation.;1558-1748;;10.1109/JSEN.2021.3072010;National Science Foundation, NSF CAREER(grant numbers:IIS-1453141), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9398950;Compensatory motion,hemiparesis,IMU,occupational therapy,wearable sensors;Task analysis,Torso,Sensors,Read only memory,Wearable sensors,Muscles,Measurement;biomechanics,body sensor networks,diseases,mechanoception,medical disorders,patient rehabilitation,telemedicine;compensatory torso motion,post-stroke patients,wearable inertial measurement units,wearable sensor technologies,torso orientation,upper extremity tasks,nine-hole peg test,IMU orientation,nominal torso motion,compensatory movement,sensor-torso alignment,occupational therapy tasks,sternum,percentage-of-time-out-of-range,PTOR,Moberg pick-up test,peg board grasp task,anatomical plane,roll angles,pitch angles,standing balance,active range-of-motion,pinch strength;;;;47;IEEE;8-apr-21;;;IEEE;IEEE Journals
Obstacle Avoidance Prediction System of Hospital Distribution Robot Based on Deep Learning;J. Li, B. Song, J. Li;Shenyang University,School of Information Engineering,Shenyang,China, Shenyang University,School of Information Engineering,Shenyang,China, Shenyang University,School of Information Engineering,Shenyang,China;2021 IEEE 5th Advanced Information Technology, Electronic and Automation Control Conference (IAEAC);5-apr-21;2021;5;;939;943;With the global outbreak of COVID-19, the normalization of epidemic is a serious fact that people have to deal with. In this paper, obstacle avoidance prediction system based on deep learning is designed to forecast and avoid obstacles. The system firstly is used the bidirectional cyclic neural network to predict pedestrian trajectory to generate dynamic obstacle information. With dynamic obstacle information into global information, the hospital distribution robot with the system can load static obstacle information and merge. The effectiveness of the system is verified through simulation experiments in two scenarios of complex areas and straight corridors in the hospital. Simulation experiments show that it realizes global path planning through dynamic window method. The obstacle avoidance prediction system of this paper can avoid direct contact between doctors and mild patients and reduce the workload of medical staff and the risk of infection effectively.;2689-6621;978-1-7281-8028-1;10.1109/IAEAC50856.2021.9390593;Natural Science Foundation of Liaoning Province, ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9390593;hospital delivery robot,deep learning,robot path planning,trajectory prediction,dynamic window method;Deep learning,Hospitals,Robot kinematics,Simulation,Trajectory,Collision avoidance,Load modeling;collision avoidance,deep learning (artificial intelligence),hospitals,medical control systems,mobile robots,neurocontrollers,path planning;obstacle avoidance prediction system,hospital distribution robot,deep learning,dynamic obstacle information,static obstacle information,global path planning,dynamic window method,COVID-19 outbreak,epidemic normalization;;;;5;;5-apr-21;;;IEEE;IEEE Conferences
Periodic Weather-Aware LSTM with Event Mechanism for Parking Behavior Prediction;F. Zhang, Y. Liu, N. Feng, C. Yang, J. Zhai, S. Zhang, B. He, J. Lin, X. Zhang, X. Du;Key Laboratory of Data Engineering and Knowledge Engineering, Renmin University of China, 12471 Beijing, Beijing, China, (e-mail: zhangfeng.thu.hpc@gmail.com), Key Laboratory of Data Engineering and Knowledge Engineering, Renmin University of China, 12471 Beijing, Beijing, China, (e-mail: liuyn1999@gmail.com), Key Laboratory of Data Engineering and Knowledge Engineering, Renmin University of China, 12471 Beijing, Beijing, China, (e-mail: whitycatty@gmail.com), Computer Science, Beijing University of Posts and Telecommunications, 12472 Beijing, Beijing, China, 100088 (e-mail: albertyang33@gmail.com), Department of Computer Science & Technology, Tsinghua University, Beijing, Beijing, China, 100084 (e-mail: zhaijidong@gmail.com), Database Systems and Information Management Group (DIMA), Technische Universitt Berlin, 26524 Berlin, Berlin, Germany, (e-mail: shuhao.zhang@tu-berlin.de), Computer Science, National University of Singapore, 37580 Singapore, Singapore, Singapore, 119260 (e-mail: hebs@comp.nus.edu.sg), Department of Information Management, Peking University, 12465 Beijing, Beijing, China, (e-mail: linjz@pku.edu.cn), School of Information, Renmin University of China, Beijing, Beijing, China, (e-mail: zhangxiao@ruc.edu.cn), School of Information, Renmin University of China, Beijing, Beijing, China, (e-mail: duyong@ruc.edu.cn);IEEE Transactions on Knowledge and Data Engineering;;2021;PP;99;1;1;There are plenty of parking spaces in big cities, but we often find nowhere to park. The reason is the lack of prediction of parking behavior. If we could provide parking behavior in advance, we can ease this parking problem that affects human well-being. We observe that parking lots have periodic parking patterns, which is an important factor for parking behavior prediction. Unfortunately, existing work ignores such periodic parking patterns in parking behavior prediction, and thus incurs low accuracy. To solve this problem, we propose PewLSTM, a novel periodic weather-aware LSTM model that successfully predicts the parking behavior based on historical records, weather, environments, weekdays, and events. PewLSTM consists of two parts: a periodic weather-aware LSTM prediction module and an event prediction module, for predicting parking behaviors in regular days and events. Based on 910,477 real parking records in 904 days from 13 parking lots, PewLSTM yields 93.84% parking prediction accuracy, which is about 30% higher than the state-of-the-art parking behavior prediction method. We have also analyzed parking behaviors in events like holidays and COVID-19, PewLSTM can also handle parking behavior prediction in events and reaches 90.68% accuracy.;1558-2191;;10.1109/TKDE.2021.3070202;National Natural Science Foundation of China(grant numbers:61802412), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9392279;;Meteorology,Predictive models,COVID-19,Logic gates,Urban areas,Recurrent neural networks,Mathematical model;;;;;;;IEEE;31 Mar 2021;;;IEEE;IEEE Early Access Articles
Toward Combatting COVID-19: A Risk Assessment System;Q. Wang, Y. Guo, T. Ji, X. Wang, B. Hu, P. Li;Department of Computer and InformationSciences, Towson University, Towson, MD, USA, Department of Electrical, Computer, and Systems Engineering, Case Western Reserve University, Cleveland, OH, USA, Department of Electrical, Computer, and Systems Engineering, Case Western Reserve University, Cleveland, OH, USA, Department of Electrical, Computer, and Systems Engineering, Case Western Reserve University, Cleveland, OH, USA, School of Medicine, Case Western Reserve University, Cleveland, OH, USA, Department of Electrical, Computer, and Systems Engineering, Case Western Reserve University, Cleveland, OH, USA;IEEE Internet of Things Journal;25 Oct 2021;2021;8;21;15953;15964;The coronavirus disease 2019 (COVID-19) has rapidly become a significant public health emergency all over the world since it was first identified in Wuhan, China, in December 2019. Until today, massive disease-related data have been collected, both manually and through the Internet of Medical Things (IoMT), which can be potentially used to analyze the spread of the disease. On the other hand, with the help of IoMT, the analysis results of the current status of COVID-19 can be delivered to people in real time to enable situational awareness, which may help mitigate the disease spread in communities. However, current accessible data on COVID-19 are mostly at a macrolevel, such as for each state, county, or metropolitan area. For fine-grained areas, such as for each city, community, or geographical coordinate, COVID-19 data are usually not available, which prevents us from obtaining information on the disease spread in closer neighborhoods around us. To address this problem, in this article, we propose a two-level risk assessment system. In particular, we define a “risk index.” Then, we develop a risk assessment model, called MK-DNN, by taking advantage of the multikernel density estimation (MKDE) and deep neural network (DNN). We train MK-DNN at the macrolevel (for each metro area), which subsequently enables us to obtain the risk indices at the microlevel (for each geographic coordinate). Moreover, a heuristic validation method is further designed to help validate the obtained microlevel risk indices. Simulations conducted on real-world data demonstrate the accuracy and validity of our proposed risk assessment system.;2327-4662;;10.1109/JIOT.2021.3070042;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9392001;Coronavirus disease 2019 (COVID-19),deep neural network (DNN),Internet of Medical Things (IoMT),kernel density estimation (KDE),risk assessment;Diseases,COVID-19,Data models,Risk management,Urban areas,Predictive models,Indexes;deep learning (artificial intelligence),diseases,epidemics,mobile computing,risk management;COVID-19,coronavirus disease,public health emergency,IoMT,risk assessment system,risk index,Wuhan,China,Internet of Medical Things,multikernel density estimation,MKDE,MK-DNN,deep neural network,heuristic validation method;;;;43;IEEE;31 Mar 2021;;;IEEE;IEEE Journals
A Deep-Learning-Based Edge-Centric COVID-19-Like Pandemic Screening and Diagnosis System within a B5G Framework Using Blockchain;G. Muhammad, M. S. Hossain;Chair of Pervasive and Mobile Computing, King Saud University, Chair of Pervasive and Mobile Computing, King Saud University;IEEE Network;26 Mar 2021;2021;35;2;74;81;Beyond 5G (B5G) has the potential of realizing all three pillars of 5G, which are massive type communication, ultra-reliable low latency communication, and enhanced mobile broadband. Currently, a COVID-19-like pandemic can utilize B5G to combat the pandemic by using real-time processing of massive volumes of test data at the edge of hospitals and by leveraging seamless communication between the edge and a global core cloud to update any diagnosis or predicting model globally. In this article, we propose an artificial-intelligence-enabled edge-centric COVID-19 screening and diagnosis system using the B5G network. Furthermore, we use blockchain-based secure transmission of patients' data in the edge. The proposed system uses screening and diagnosis in the edge by using powerful edge devices that can run deep learning (DL) models. The DL models can be downloaded from the core cloud to the edge server or uploaded to the core cloud when necessary.;1558-156X;;10.1109/MNET.011.2000326;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9387708;;COVID-19,Pandemics,Hospitals,Ultra reliable low latency communication,Predictive models,Real-time systems,Servers,Deep learning;5G mobile communication,biology computing,blockchains,cloud computing,deep learning (artificial intelligence),diseases,distributed processing,epidemics,patient diagnosis;deep-learning-based edge-centric COVID-19-like pandemic screening,edge server,deep learning models,powerful edge devices,blockchain-based secure transmission,artificial-intelligence-enabled edge-centric COVID-19 screening,global core cloud,seamless communication,real-time processing,enhanced mobile broadband,ultra-reliable low latency communication,massive type communication,B5G framework,diagnosis system;;6;;15;;26 Mar 2021;;;IEEE;IEEE Magazines
When CVaR Meets With Bluetooth PAN: A Physical Distancing System for COVID-19 Proactive Safety;M. S. Munir, D. H. Kim, A. K. Bairagi, C. S. Hong;Department of Computer Science and Engineering, Kyung Hee University, Yongin, Republic of Korea, Department of Computer Science and Engineering, Kyung Hee University, Yongin, Republic of Korea, Department of Computer Science and Engineering, Kyung Hee University, Yongin, Republic of Korea, Department of Computer Science and Engineering, Kyung Hee University, Yongin, Republic of Korea;IEEE Sensors Journal;14-jun-21;2021;21;12;13858;13869;In this work, we propose a risk-aware physical distancing system to assure a private safety distance from others for reducing the chance of being affected by the COVID-19 or such kind of pandemic. In particular, we have formulated a physical distancing problem by capturing Conditional Value-at-Risk (CVaR) of a Bluetooth-enabled personal area network (PAN). To solve the formulated risk-aware physical distancing problem, we propose two stages solution approach by imposing control flow, linear model, and curve-fitting schemes. Notably, in the first stage, we determine a PAN creator's safe movement distance by proposing a probabilistic linear model. This scheme can effectively cope with a tail-risk from the probability distribution by satisfying the CVaR constraint for estimating safe movement distance. In the second stage, we design a Levenberg-Marquardt (LM)-based curve fitting algorithm upon the recommended safety distance and current distances between the PAN creator and others to find an optimal high-risk trajectory plan for the PAN creator. Finally, we have performed an extensive performance analysis using state-of-the-art Bluetooth data to establish the proposed risk-aware physical distancing system's effectiveness. Our experimental results show that the proposed solution approach can effectively reduce the risk of recommending safety distance towards ensuring private safety. In particular, for a 95% CVaR confidence, we can successfully deal with 45.11% of the risk for measuring the PAN creator's safe movement distance.;1558-1748;;10.1109/JSEN.2021.3068782;Institute of Information and Communications Technology Planning and Evaluation (IITP) Grant by the Korean Government through MSIT (Evolvable deep learning model generation platform for edge computing)(grant numbers:2019-0-01287), MSIT Korea through the Grand Information Technology Research Center Support Program supervised by the Institute of Information and Communications Technology Planning and Evaluation (IITP)(grant numbers:IITP-2020-2015-0-00742), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9386066;Physical distancing,conditional value-at-risk (CVaR),personal area network (PAN),Bluetooth,COVID-19;COVID-19,Safety,Bluetooth,Sensors,Trajectory,Particle measurements,Atmospheric measurements;Bluetooth,curve fitting,epidemics,optimisation,patient monitoring,probability,risk analysis;Levenberg-Marquardt-based curve fitting algorithm,probability distribution,personal area networks,recommended safety distance,safe movement distance,CVaR constraint,probabilistic linear model,conditional value-at-risk,private safety distance,COVID-19 proactive safety,Bluetooth PAN,CVaR,risk-aware physical distancing system,Bluetooth data,high-risk trajectory plan,PAN creator;;2;;40;IEEE;24 Mar 2021;;;IEEE;IEEE Journals
Multi-scale Sparse Graph Convolutional Network for the Assessment of Parkinsonian Gait;R. Guo, X. Shao, C. Zhang, X. Qian;School of Biomedical Engineering, Shanghai Jiao Tong University, 12474 Shanghai, China, (e-mail: graymm@sjtu.edu.cn), School of Electrical and Electronic Engineering, Changchun University of Technology, 177552 Changchun, Jilin, China, (e-mail: shaoxiangxin@ccut.edu.cn), Department of Functional Neurosurgery, Ruijin Hospital, Shanghai Jiao Tong University School of Medicine, 56694 Shanghai, China, (e-mail: i@cczhang.org), School of Biomedical Engineering, Shanghai Jiao Tong University, 12474 Shanghai, China, 200030 (e-mail: xiaohua.qian@sjtu.edu.cn);IEEE Transactions on Multimedia;;2021;PP;99;1;1;Automated assessment of patients with Parkinson's disease (PD) is urgently required in clinical practice to improve the diagnostic efficiency and objectivity and to remotely monitor the motor disorder symptoms and general health of these patients, especially in view of the travel restrictions due to the recent coronavirus epidemic. Gait motor disorder is one of the critical manifestations of PD, and automated assessment of gait is vital to realize automated assessment of PD patients. To this end, we propose a novel two-stream spatial-temporal attention graph convolutional network (2s-ST-AGCN) for video assessment of PD gait motor disorder. Specifically, the skeleton sequence of human body is extracted from videos to construct spatial-temporal graphs of joints and bones, and a two-stream spatial-temporal graph convolutional network is then built to simultaneously model the static spatial information and dynamic temporal variations. The multi-scale spatial-temporal attention-aware mechanism is also designed to effectively extract the discriminative spatial-temporal features. The deep supervision strategy is then embedded to minimize classification errors, thereby guiding the weight update process of the hidden layer to promote significant discriminative features. Besides, two model-driven terms are integrated into this deep learning framework to strengthen multi-scale similarity in the deep supervision and realize sparsification of discriminative features. Extensive experiments on the clinical video dataset show that the proposed model exhibits good performance with an accuracy of 65.66% and an acceptable accuracy of 98.90%, which is much better than that of the existing sensor- and vision-based methods for Parkinsonian gait assessment. Thus, the proposed method is potentially useful for assessing PD gait motor disorder in clinical practice.;1941-0077;;10.1109/TMM.2021.3068609;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9385969;Parkinson's disease,Gait motor disorder,Video-based assessment,Graph convolutional network,Model-driven deep learning;Feature extraction,Deep learning,Pose estimation,Bones,Legged locomotion,Joints,Correlation;;;;2;;;IEEE;24 Mar 2021;;;IEEE;IEEE Early Access Articles
Research on the Early-Warning Model of Network Public Opinion of Major Emergencies;L. -J. Peng, X. -G. Shao, W. -M. Huang;School of Mathematics and Statistics Science, Ludong University, Yantai, China, School of Mathematics and Statistics Science, Ludong University, Yantai, China, School of Mathematics and Statistics Science, Ludong University, Yantai, China;IEEE Access;24 Mar 2021;2021;9;;44162;44172;The rapid development of Internet in recent years has led to a proliferation of social media networks as people who can gather online to share information, knowledge, and opinions. However, the network public opinion tends to generate strongly misleading and a large number of messages can cause shocks to the public once major emergencies appear. Therefore, we need to make correct prediction regarding and timely identify a potential crisis in the early warning of network public opinion. In view of this, this study fully considers the features of development and the propagation characteristics, so as to construct a network public opinion early warning index system that includes 4 first-level indicators and 13 second-level indicators. The weight of each indicator is calculated by the “CRITIC” method, so that the comprehensive evaluation value of each time point can be obtained and the early warning level of internet public opinion can be divided. Then, the Back Propagation neural network based on Genetic Algorithm (GA-BP) is used to establish a network public opinion early warning model. Finally, the major public health emergency, COVID-19 pandemic, is taken as a case for empirical analysis. The results show that by comparing with the traditional classification methods, such as BP neural network, decision tree, random forest, support vector machine and naive Bayes, GA-BP neural network has a higher accuracy rate for early warning of network public opinion. Consequently, the index system and early warning model constructed in this study have good feasibility and can provide references for related research on internet public opinion.;2169-3536;;10.1109/ACCESS.2021.3066242;Shandong Province Social Science Planning and Research Project(grant numbers:20CSDJ10), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9380384;Major emergencies,internet public opinion,early warning index system,COVID-19,CRITIC,GA-BP neural network;Indexes,Neural networks,Blogs,Web and internet services,Sensitivity,Internet,COVID-19;backpropagation,decision trees,genetic algorithms,Internet,neural nets,pattern classification,social networking (online),support vector machines;early-warning model,network public opinion early warning,early warning level,internet public opinion,early warning model;;1;;26;CCBY;17 Mar 2021;;;IEEE;IEEE Journals
Which Machine Learning method for outbreaks predictions?;P. L. Bokonda, K. Ouazzani-Touhami, N. Souissi;Mohammed V University in Rabat. EMI, Siweb team,Department of Computer Science,Rabat,Morocco, MINES-RABAT School,Department of Computer Science,Rabat,Morocco, MINES-RABAT School,Department of Computer Science,Rabat,Morocco;2021 IEEE 11th Annual Computing and Communication Workshop and Conference (CCWC);17 Mar 2021;2021;;;825;828;African swine fever (ASF), dengue fever, influenza, norovirus disease are names of outbreaks that have taken some parts of the world by surprise and caused several deaths. The advent of coronavirus disease at the end of 2019 is clear proof that the issue of outbreaks is more topical than ever. The Machine Learning (ML) comes to the rescue of medicine by offering predictive analysis methods to predict the reappearance of outbreaks and thus help the healthcare system and decisionmakers to take the necessary measures in advance. But which ML method should be used to predict an outbreak? Given the large number of ML methods, it is sometimes difficult to know which method to use. This is why we conducted this study. We looked at the above-mentioned outbreaks and identified the following ML methods as the most commonly used: LR, C4.5, NB, SVM, ANN and RF. Of these six methods, the random forest method (RF) stands out from the others because it was used in all four outbreaks considered, has the best accuracy for two outbreaks (ASF and dengue fever) and has been designated by several independent researchers as the most suitable ML method for outbreak prediction.;;978-1-6654-1490-6;10.1109/CCWC51732.2021.9376061;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9376061;outbreaks,prediction,covid-19,machine learning,random forest,methods;Radio frequency,Support vector machines,COVID-19,Conferences,Influenza,Spatiotemporal phenomena,Random forests;decision trees,diseases,learning (artificial intelligence),microorganisms,neural nets,support vector machines;dengue fever,suitable ML method,outbreak prediction,Machine Learning method,outbreaks predictions,norovirus disease,predictive analysis methods,above-mentioned outbreaks,random forest method;;;;29;;17 Mar 2021;;;IEEE;IEEE Conferences
Anomaly Detection Monitoring System for Healthcare;T. Boloka, G. Crafford, W. Mokuwe, B. V. Eden;Industrial Robotics Council for Scientific and Industrial Research,Pretoria,South Africa, Industrial Robotics Council for Scientific and Industrial Research,Pretoria,South Africa, Industrial Robotics Council for Scientific and Industrial Research,Pretoria,South Africa, Industrial Robotics Council for Scientific and Industrial Research,Pretoria,South Africa;2021 Southern African Universities Power Engineering Conference/Robotics and Mechatronics/Pattern Recognition Association of South Africa (SAUPEC/RobMech/PRASA);17 Mar 2021;2021;;;1;6;Most developing countries suffer from inadequate health care facilities and a lack of medical practitioners as most of them emigrate to developed countries. The outbreak of the COVID-19 pandemic has left these countries more vulnerable to facing the worse outcome of the pandemic. This necessitates the need for a system that continuously monitors patient status and detects how their physiological variables will change over time. As a result, it will reduce the rate of mortality and mitigate the need for medical practitioners to monitor patients continuously. In this work, we show how an autoencoder and extreme gradient boosting can be merged to forecast physiological variables of a patient and detect anomalies and their level of divergence. An accurate detection of current and future anomalies will enable remedial action to be taken by medical practitioners at the right time and possibly save lives.;;978-1-6654-0345-0;10.1109/SAUPEC/RobMech/PRASA52254.2021.9377017;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9377017;;Power engineering,Pandemics,Hospitals,Merging,Biomedical monitoring,Monitoring,Anomaly detection;diseases,gradient methods,health care,medical computing,patient monitoring;anomaly detection monitoring system,health care facilities,medical practitioners,COVID-19 pandemic,patient status,physiological variables,autoencoder,extreme gradient boosting;;;;24;;17 Mar 2021;;;IEEE;IEEE Conferences
Cancel-for-Any-Reason Insurance Recommendation Using Customer Transaction-Based Clustering;Z. Sadreddini, I. Donmez, H. Yanikomeroglu;Department of Systems and Computer Engineering, Carleton University, Ottawa, ON, Canada, Department of Computer Engineering, Istanbul Arel University, Istanbul, Turkey, Department of Systems and Computer Engineering, Carleton University, Ottawa, ON, Canada;IEEE Access;15 Mar 2021;2021;9;;39363;39374;In the travel insurance industry, <italic>cancel-for-any-reason</italic> insurance, also known as a cancellation protection service (CPS), is a recent attempt to strike a balance between customer satisfaction and service provider (SP) profits. However, some exceptional circumstances, particularly the COVID-19 pandemic, have led to a dramatic decrease in SP revenues, especially for non-refundable tickets purchased early with CPS. This paper begins by presenting a risk group segmentation of customers in an online ticket reservation system. Then, a CPS fee is recommended depending on the different customer risk groups provided by the cluster segmentation via different clustering algorithms such as centroid-based K-means, hierarchical agglomerative, DBSCAN, and artificial neural network-based SOM algorithms. According to the implemented cluster metrics, which include the Silhouette index, Davies-Bouldin index, Entropy index, and DBCV index, the SOM algorithm presents the most appropriate result. After predicting the new customer cluster, a CPS fee will be calculated with the proposed adaptive CPS method based on the cluster segmentation weights. Determining the weight of each cluster is related to the total CPS revenue threshold for all clusters defined by the SP. Therefore, to avoid a loss for SPs, the total CPS revenue will be kept constant with the threshold that the SP has been adjusted. The experimental results based on real-world data show that the risk group segmentation of customers helps to maintain a balance between CPS fees and SP profits. Finally, according to the calculated weights, the proposed model pegs the SP gain/loss variation with a 0.00012 exchange ratio.;2169-3536;;10.1109/ACCESS.2021.3064929;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9373358;Clustering algorithms,cancellation protection service,risk group segmentation,user satisfaction,service provider revenue;Clustering algorithms,Prediction algorithms,Insurance,Indexes,Adaptation models,Atmospheric modeling,Licenses;;;;;;45;CCBY;9 Mar 2021;;;IEEE;IEEE Journals
A Wearable Wireless Sensor System Using Machine Learning Classification to Detect Arrhythmia;A. Farooq, M. Seyedmahmoudian, A. Stojcevski;School of Software and Electrical Engineering, Swinburne University of Technology, Melbourne, VIC, Australia, School of Software and Electrical Engineering, Swinburne University of Technology, Melbourne, VIC, Australia, School of Software and Electrical Engineering, Swinburne University of Technology, Melbourne, VIC, Australia;IEEE Sensors Journal;5-apr-21;2021;21;9;11109;11116;Health care is becoming a public concern and has given intensifying attention in recent years considering the aspects such as an increase in population, urbanization and globalization. (a). Good quality and effective health care system is although low in cost but its ability to detect abnormalities and anomalies is not compromised. The objective of this research work is to introduce a novel cost-effective technique that allows the measured ECG waveform to get classified with the help of the LabVIEW. Using the combination of the sensor system, first, the input ECG sensor signal is collected and then processed in LabVIEW to get classified. (b). A LabVIEW based simulation is presented in this article which classifies the heart ECG signal to be as healthy, non-healthy and not defined. Moreover, the relevant hardware details are also discussed. The classification system is trained using the machine learning (ML) technique (K-mean clustering). (c). The findings from the work include classification of heart health status, timely detection of anomalies and (various) arrhythmia conditions at their preliminary stages. Further discoveries contain performance evaluation resulting in response time lesser than half a minute and accuracy estimation from the experiment on three patients. (d). The system can be useful for detecting the COVID-19 breathing issues at their early stage and an automatic appointment can be set with the available scheduled heart professional based on the severity of the detected arrhythmia condition. The system allows early access to the hospital support system and can help to reduce the crowds in the medical centers.;1558-1748;;10.1109/JSEN.2021.3062395;U.S. Department of Commerce(grant numbers:BS123456), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9363940;Abnormalities,mobile platform,ECG,IoT,LabVIEW,ANN,extraction techniques,HTTP;Electrocardiography,Heart,Sensors,Machine learning,Medical services,Sensor systems,Monitoring;body sensor networks,electrocardiography,health care,hospitals,learning (artificial intelligence),medical signal processing,patient monitoring,pneumodynamics;wearable wireless sensor system,machine learning classification,detect arrhythmia,public concern,urbanization,globalization,effective health care system,cost-effective technique,measured ECG waveform,input ECG sensor signal,LabVIEW based simulation,heart ECG signal,relevant hardware details,classification system,machine learning technique,heart health status,arrhythmia conditions,detected arrhythmia condition,hospital support system,scheduled heart professional;;3;;38;IEEE;26-feb-21;;;IEEE;IEEE Journals
Prediction of Epidimic Outbreak using Deep Learning Methods;C. R. S. Kiran, C. Naveen, D. A. Kumar, T. Saiteja, C. Karthikeyan;Koneru Lakshmaiah Education Foundation,Department of Computer Science and Engineering,Guntur,Andhra Pradesh,India, Koneru Lakshmaiah Education Foundation,Department of Computer Science and Engineering,Guntur,Andhra Pradesh,India, Koneru Lakshmaiah Education Foundation,Department of Computer Science and Engineering,Guntur,Andhra Pradesh,India, Koneru Lakshmaiah Education Foundation,Department of Computer Science and Engineering,Guntur,Andhra Pradesh,India, Koneru Lakshmaiah Education Foundation,Department of Computer Science and Engineering,Guntur,Andhra Pradesh,India;2021 6th International Conference on Inventive Computation Technologies (ICICT);26-feb-21;2021;;;995;1000;In late December 2019, a lot of unexplained pneumonia cases have been accounted for in Wuhan, China. Later it is declared a pandemic. The spread of the virus from people is increasing at a high rate and that led to the loss of human life. People with Hereditary diseases are likely to be the most affected by this virus. In this, an analysis is made to know in how many days a patient will take to recover from virus and how the infection spread across people. This analysis is performed using Deep Learning (DL) method. K-Means and the SIR Model are the two models used for implementation to analyze the disease.;;978-1-7281-8501-9;10.1109/ICICT50816.2021.9358710;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9358710;COVID-19,Hereditary,K-Means,SIR MODEL;Deep learning,COVID-19,Analytical models,Pandemics,Lung,Viruses (medical),Immune system;diseases,learning (artificial intelligence),medical information systems,microorganisms;epidimic outbreak,deep learning method,unexplained pneumonia cases,Wuhan,virus,human life,hereditary diseases,infection spread,disease,k-means,DL,SIR model;;5;;16;;26-feb-21;;;IEEE;IEEE Conferences
COVID-19 Patient Count Prediction Using LSTM;M. Iqbal, F. Al-Obeidat, F. Maqbool, S. Razzaq, S. Anwar, A. Tubaishat, M. S. Khan, B. Shah;Department of Computer Science and Information Technology, University of Sargodha, Sargodha, Pakistan, College of Technological Innovation, Zayed University, Abu Dhabi, United Arab Emirates, Department of Computer Science and Information Technology, University of Sargodha, Sargodha, Pakistan, Department of Computer Science and Information Technology, University of Sargodha, Sargodha, Pakistan, Center of Excellence in Information Technology, Institute of Management Sciences, Peshawar, Pakistan, College of Technological Innovation, Zayed University, Abu Dhabi, United Arab Emirates, Department of Computer Science, National University of Computer and Emerging Sciences, Chiniot-Faisalabad Campus, Chiniot, Pakistan, College of Information Technology, Zayed University, Abu Dhabi, United Arab Emirates;IEEE Transactions on Computational Social Systems;30-jul-21;2021;8;4;974;981;In December 2019, a pandemic named COVID-19 broke out in Wuhan, China, and in a few weeks, it spread to more than 200 countries worldwide. Every country infected with the disease started taking necessary measures to stop the spread and provide the best possible medical facilities to infected patients and take precautionary measures to control the spread. As the infection spread was exponential, there arose a need to model infection spread patterns to estimate the patient volume computationally. Such patients' estimation is the key to the necessary actions that local governments may take to counter the spread, control hospital load, and resource allocations. This article has used long short-term memory (LSTM) to predict the volume of COVID-19 patients in Pakistan. LSTM is a particular type of recurrent neural network (RNN) used for classification, prediction, and regression tasks. We have trained the RNN model on Covid-19 data (March 2020 to May 2020) of Pakistan and predict the Covid-19 Percentage of Positive Patients for June 2020. Finally, we have calculated the mean absolute percentage error (MAPE) to find the model's prediction effectiveness on different LSTM units, batch size, and epochs. Predicted patients are also compared with a prediction model for the same duration, and results revealed that the predicted patients' count of the proposed model is much closer to the actual patient count.;2329-924X;;10.1109/TCSS.2021.3056769;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9359351;Covid-19,deep learning,forecasting,long short-term memory (LSTM),pandemics,risk estimation,short term predictio;COVID-19,Predictive models,Forecasting,Data models,Viruses (medical),Training,Recurrent neural networks;diseases,hospitals,neural nets,recurrent neural nets,regression analysis,resource allocation;different LSTM units,predicted patients,prediction model,actual patient count,COVID-19 patient count prediction,December 2019,necessary measures,possible medical facilities,infected patients,precautionary measures,infection spread patterns,patient volume,necessary actions,control hospital load,short-term memory,COVID-19 patients,Pakistan,RNN model,Covid-19 data,Covid-19 Percentage,Positive Patients;;2;;31;IEEE;19-feb-21;;;IEEE;IEEE Journals
One Step Ahead: A Framework for Detecting Unexpected Incidents and Predicting the Stock Markets;Z. Li, S. Lyu, H. Zhang, T. Jiang;School of Information Science and Technology, ShanghaiTech University, Shanghai, China, School of Information Science and Technology, ShanghaiTech University, Shanghai, China, School of Information Science and Technology, ShanghaiTech University, Shanghai, China, School of Information Science and Technology, ShanghaiTech University, Shanghai, China;IEEE Access;23-feb-21;2021;9;;30292;30305;Unexpected incidents can be destructive or even disastrous, affecting the financial markets. Incidents such as the 9/11 attacks (2001), the Fukushima nuclear disaster (2011), and the COVID-19 outbreaks (2019, 2020) severely shocked both local and global markets. For investors, it is crucial to quantify the key facts that affect the incidents' impacts, and to estimate the reactions of the markets accurately and efficiently for global event-driven investment strategies. Though Web data and other alternative data allow such a possibility, it is still very challenging to mine noisy and often biased heterogeneous data sources, and construct a unified framework for modeling global markets across across time and regions. As a first attempt, we build a framework that extracts incident facts globally based on a deep neural network, feeds them into models built on a global event database complemented with novel socioeconomic datasets (e.g. nightlight data from satellites), and predicts stock market directions in a simulated real-world setting with interpretable results that outperform various baselines. Specifically, we study terrorist attacks in three countries for over 20 years on average, as a first effort to systematically quantify the impact on stock markets at a large scale using novel indicators.;2169-3536;;10.1109/ACCESS.2021.3059283;Shanghai Sail Program(grant numbers:19YF1433800), Key Projects of Shanghai Soft Science Research Program(grant numbers:20692194300), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9354149;Satellite data,stock market prediction,terrorist attacks,unexpected incidents;Stock markets,Terrorism,Biological system modeling,Databases,Predictive models,Data mining,Satellites;Internet,investment,neural nets,stock markets;heterogeneous data sources,global markets,global event database,stock market directions,financial markets,Fukushima nuclear disaster,COVID-19 outbreaks,global event-driven investment strategies,Web data,unexpected incident detection,stock market prediction,deep neural network;;1;;47;CCBYNCND;12-feb-21;;;IEEE;IEEE Journals
CoAID-DEEP: An Optimized Intelligent Framework for Automated Detecting COVID-19 Misleading Information on Twitter;D. S. Abdelminaam, F. H. Ismail, M. Taha, A. Taha, E. H. Houssein, A. Nabil;Faculty of Computers and Artificial Intelligence, Benha University, Benha, Egypt, Faculty of Computer Science, Misr International University, Cairo, Egypt, Faculty of Computers and Artificial Intelligence, Benha University, Benha, Egypt, Faculty of Computers and Artificial Intelligence, Benha University, Benha, Egypt, Faculty of Computers and Information, Minia University, Minia, Egypt, Faculty of Computer Science, Misr International University, Cairo, Egypt;IEEE Access;18-feb-21;2021;9;;27840;27867;COVID-19 has affected all peoples’ lives. Though COVID-19 is on the rising, the existence of misinformation about the virus also grows in parallel. Additionally, the spread of misinformation has created confusion among people, caused disturbances in society, and even led to deaths. Social media is central to our daily lives. The Internet has become a significant source of knowledge. Owing to the widespread damage caused by fake news, it is important to build computerized systems to detect fake news. The paper proposes an updated deep neural network for identification of false news. The deep learning techniques are The Modified-LSTM (one to three layers) and The Modified GRU (one to three layers). In particular, we carry out investigations of a large dataset of tweets passing on data with respect to COVID-19. In our study, we separate the dubious claims into two categories: true and false. We compare the performance of the various algorithms in terms of prediction accuracy. The six machine learning techniques are decision trees, logistic regression, k nearest neighbors, random forests, support vector machines, and naïve Bayes (NB). The parameters of deep learning techniques are optimized using Keras-tuner. Four Benchmark datasets were used. Two feature extraction methods were used (TF-ID with N-gram) to extract essential features from the four benchmark datasets for the baseline machine learning model and word embedding feature extraction method for the proposed deep neural network methods. The results obtained with the proposed framework reveal high accuracy in detecting Fake and non-Fake tweets containing COVID-19 information. These results demonstrate significant improvement as compared to the existing state of art results of baseline machine learning models. In our approach, we classify the data into two categories: fake or nonfake. We compare the execution of the proposed approaches with Six machine learning procedures. The six machine learning procedures are Decision Tree (DT), Logistic Regression (LR), K Nearest Neighbor (KNN), Random Forest (RF), Support Vector Machine (SVM), and Naive Bayes (NB). The parameters of deep learning techniques are optimized using Keras-tuner. Four Benchmark datasets were used. Two feature extraction methods were used (TF-ID with N-gram) to extract essential features from the four benchmark datasets for the baseline machine learning model and word embedding feature extraction method for the proposed deep neural network methods. The results obtained with the proposed framework reveal high accuracy in detecting Fake and non-Fake tweets containing COVID-19 information. These results demonstrate significant improvement as compared to the existing state of art results of baseline machine learning models.;2169-3536;;10.1109/ACCESS.2021.3058066;Faculty of Computers Science, Misr International University(grant numbers:28211231302952), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9350542;Fake news,COVID-19,misleading information,pandemic,social media,deep learning;COVID-19,Social networking (online),Feature extraction,Deep learning,Blogs,Viruses (medical),Organizations;decision trees,deep learning (artificial intelligence),epidemics,feature extraction,medical computing,nearest neighbour methods,pattern classification,random forests,regression analysis,social networking (online),support vector machines;CoAID-DEEP,optimized intelligent framework,automated detecting COVID-19 misleading information,fake news,deep neural network,deep learning,decision trees,logistic regression,k nearest neighbors,random forests,support vector machines,Keras-tuner,benchmark datasets,word embedding feature extraction method,machine learning,modified-LSTM;;17;;73;CCBY;9-feb-21;;;IEEE;IEEE Journals
A Mass-Conservation Model for Stability Analysis and Finite-Time Estimation of Spread of COVID-19;H. Rastgoftar, E. Atkins;Department of Mechanical Engineering, Villanova University, Villanova, PA, USA, Department of Aerospace Engineering, University of Michigan, Ann Arbor, MI, USA;IEEE Transactions on Computational Social Systems;30-jul-21;2021;8;4;930;937;The COVID-19 global pandemic has significantly impacted people throughout the United States and the World. While it was initially believed the virus was transmitted from animal to human, person-to-person transmission is now recognized as the main source of community spread. This article integrates data into physics-based models to analyze stability of the rapid COVID-19 growth and to obtain a data-driven model for spread dynamics among the human population. The proposed mass-conservation model is used to learn the parameters of pandemic growth and to predict the growth of total cases, deaths, and recoveries over a finite future time horizon. The proposed finite-time prediction model is validated by finite-time estimation of the total numbers of infected cases, deaths, and recoveries in the United States from March 12, 2020 to December 9, 2020.;2329-924X;;10.1109/TCSS.2021.3050476;National Science Foundation(grant numbers:1914581,1739525), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9344853;Finite-time estimation,finite-time modding,pandemic growth stability;COVID-19,Estimation,Pandemics,Stability criteria,Diseases,Analytical models,Aerodynamics;diseases,epidemics,estimation theory,microorganisms;mass-conservation model,stability analysis,finite-time estimation,COVID-19 global pandemic,United States,person-to-person transmission,community spread,physics-based models,data-driven model,spread dynamics,human population,finite future time horizon,finite-time prediction model;;1;;40;IEEE;2-feb-21;;;IEEE;IEEE Journals
Prediction of COVID-19 confirmed, death, and cured cases in India using random forest model;V. K. Gupta, A. Gupta, D. Kumar, A. Sardana;Department of Computer Science and Engineering (CSE), Graphic Era Deemedto be University, Dehradun 248002, India, Department of CSE, IMS Engineering College, Ghaziabad 201009, India, Department of CSE, KIET Group of Institutions, Ghaziabad 201206, India, Department of CSE, IMS Engineering College, Ghaziabad 201009, India;Big Data Mining and Analytics;1-feb-21;2021;4;2;116;123;A novel coronavirus (SARS-CoV-2) is an unusual viral pneumonia in patients, first found in late December 2019, latter it declared a pandemic by World Health Organizations because of its fatal effects on public health. In this present, cases of COVID-19 pandemic are exponentially increasing day by day in the whole world. Here, we are detecting the COVID-19 cases, i.e., confirmed, death, and cured cases in India only. We are performing this analysis based on the cases occurring in different states of India in chronological dates. Our dataset contains multiple classes so we are performing multi-class classification. On this dataset, first, we performed data cleansing and feature selection, then performed forecasting of all classes using random forest, linear model, support vector machine, decision tree, and neural network, where random forest model outperformed the others, therefore, the random forest is used for prediction and analysis of all the results. The K-fold cross-validation is performed to measure the consistency of the model.;2096-0654;;10.26599/BDMA.2020.9020016;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9343921;coronavirus,COVID-19,respiratory tract,multi-class classification,random forest;COVID-19,Viruses (medical),Predictive models,Random forests,Feature extraction,Data models,Animals;decision trees,diseases,learning (artificial intelligence),medical information systems,microorganisms,pattern classification,support vector machines;chronological dates,multiclass classification,data cleansing,feature selection,linear model,random forest model,India,novel coronavirus,SARS-CoV-2,unusual viral pneumonia,late December 2019,World Health Organizations,fatal effects,public health,COVID-19 pandemic,COVID-19 cases,K-fold cross-validation;;3;;;;1-feb-21;;;TUP;TUP Journals
A Comparative Study on Heart Disease Prediction Using Data Mining Techniques and Feature Selection;F. Tasnim, S. U. Habiba;International Islamic University Chittagong Kumira,Dept. of CSE,Chittagong,Bangladesh,4318, Khulna University of Engineering & Technology,Dept. of CSE,Khulna,Bangladesh,9203;2021 2nd International Conference on Robotics, Electrical and Signal Processing Techniques (ICREST);1-feb-21;2021;;;338;341;The world health organization shows us that cardiovascular disease is one of the noteworthy reasons for death in the world. In this paper, data mining classification techniques i.e. Naive Bayes (NB), Support Vector Machine (SVM), k-nearest neighbors' (k-NN), Decision Tree (DT), Neural Network (NN), Logistic Regression (LR), Random Forest (RF), Gradient Boosting are proposed to predict the probability of the coronary heart disease. In the present world, researchers are trying heart and soul to make advancements in the smart health care system. An automated system predicting the risk of heart disease may be added as a great achievement. This work of predicting heart disease is evaluated using the dataset from the UCI machine learning repository. The feature selection method enhances the performance of traditional machine learning algorithms. Among the classification algorithms, Random Forest (RF) algorithm with PCA has given the best accuracy of 92.85% for heart disease classification.;;978-1-6654-1576-7;10.1109/ICREST51555.2021.9331158;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331158;heart disease prediction,data mining,feature selection;Heart,Support vector machines,Radio frequency,Machine learning algorithms,Feature extraction,Random forests,Principal component analysis;cardiology,data mining,decision trees,diseases,gradient methods,health care,learning (artificial intelligence),medical computing,naive Bayes methods,neural nets,pattern classification,principal component analysis,random forests,regression analysis,support vector machines;smart health care system,UCI machine learning repository,feature selection,random forest,heart disease classification,heart disease prediction,World Health Organization,cardiovascular disease,data mining classification,naive Bayes classifier,k-nearest neighbors,decision tree,neural network,logistic regression,gradient boosting,coronary heart disease,machine learning,PCA;;1;;12;;1-feb-21;;;IEEE;IEEE Conferences
Optimisation of Non-Pharmaceutical Measures in COVID-19 Growth via Neural Networks;A. Riccardi, J. Gemignani, F. Fernández-Navarro, A. Heffernan;Department of Mechanical and Aerospace Engineering, University of Strathclyde, Glasgow, U.K., Department of Developmental Psychology and Socialisation, Università di Padova, Padova, Italy, Department of Quantitative Methods, Universidad Loyola Andalucía, Cordoba, Spain, Department of Physics, University of Guelph, Guelph, Ontario, Canada;IEEE Transactions on Emerging Topics in Computational Intelligence;21-jan-21;2021;5;1;79;91;On <inline-formula><tex-math notation=LaTeX>19^{\text{th}}</tex-math></inline-formula> March, the World Health Organisation declared a pandemic. Through this global spread, many nations have witnessed exponential growth of confirmed cases brought under control by severe mass quarantine or <italic>lockdown</italic> measures. However, some have, through a different timeline of actions, prevented this exponential growth. Currently as some continue to tackle growth, others attempt to safely lift restrictions whilst avoiding a resurgence. This study seeks to quantify the impact of government actions in mitigating viral transmission of SARS-CoV-2 by a novel soft computing approach that makes concurrent use of a neural network model, to predict the daily slope increase of cumulative infected, and an optimiser, with a parametrisation of the government restriction time series, to understand the best set of mitigating actions. Data for two territories, Italy and Taiwan, have been gathered to model government restrictions in travelling, testing and enforcement of social distance measures as well as people connectivity and adherence to government actions. It is found that a larger and earlier testing campaign with tighter entry restrictions benefit both regions, resulting in significantly less confirmed cases. Interestingly, this scenario couples with an earlier but milder implementation of nationwide restrictions for Italy, thus supporting Taiwan's lack of nationwide lockdown, i.e. earlier government actions could have contained the growth to a degree that a widespread lockdown would have been avoided, or at least delayed. The results, found with a purely data-driven approach, are in line with the main findings of mathematical epidemiological models, proving that the proposed approach has value and that the data alone contains valuable knowledge to inform decision makers.;2471-285X;;10.1109/TETCI.2020.3046012;Government of Canada, Province of Ontario, Ministry of Colleges and Universities, Scottish Funding Council, ERC Consolidator(grant numbers:773202 ERC-2017-COG), Spanish Ministry of Science(grant numbers:ENE2017-88889-C2-1-R), Natural Sciences and Engineering Research Council of Canada, ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9328205;Covid-19,SARS-CoV-2,epidemiology,BiLSTM,CNN,ELM,optimisation,data gathering;COVID-19,Testing,Viruses (medical),Government,Diseases,Predictive models,Forecasting;diseases,epidemics,fuzzy logic,health care,medical computing,neural nets,time series,uncertainty handling;COVID-19 growth,neural networks,World Health Organisation,SARS-CoV-2,soft computing,government restriction time series,nationwide lockdown,viral transmission mitigation,nonpharmaceutical measures optimisation,social distance measures,epidemiological models;;8;;72;IEEE;18-jan-21;;;IEEE;IEEE Journals
<italic>i</italic>Worksafe: Towards Healthy Workplaces During COVID-19 With an Intelligent Phealth App for Industrial Settings;M. S. Kaiser, M. Mahmud, M. B. T. Noor, N. Z. Zenia, S. A. Mamun, K. M. A. Mahmud, S. Azad, V. N. M. Aradhya, P. Stephan, T. Stephan, R. Kannan, M. Hanif, T. Sharmeen, T. Chen, A. Hussain;Institute of Information Technology, Jahangirnagar University, Dhaka, Bangladesh, Department of Computer Science, Nottingham Trent University, Nottingham, U.K., Institute of Information Technology, Jahangirnagar University, Dhaka, Bangladesh, Institute of Information Technology, Jahangirnagar University, Dhaka, Bangladesh, Institute of Information Technology, Jahangirnagar University, Dhaka, Bangladesh, Skoder Technologies, Dhaka, Bangladesh, Faculty of Computing, University Malaysia Pahang, Kuantan, Malaysia, Department of Computer Applications, JSS Science and Technology University, Mysuru, India, Department of Computer Science and Engineering, Karunya Institute of Technology and Sciences, Coimbatore, India, Department of Computer Science and Engineering, M. S. Ramaiah University of Applied Sciences, Bangalore, India, Department of Electrical and Electronics Engineering, Universiti Teknologi PETRONAS, Seri Iskandar, Malaysia, Dhaka Shishu Hospital, Bangladesh Institute of Child Health, Dhaka, Bangladesh, Women Immigrant in Economic Growth, Nottingham, U.K., Department of Computer Science, University of Huddersfield, Huddersfield, U.K., School of Computing, Edinburgh Napier University, Edinburgh, U.K.;IEEE Access;25-jan-21;2021;9;;13814;13828;The recent outbreak of the novel Coronavirus Disease (COVID-19) has given rise to diverse health issues due to its high transmission rate and limited treatment options. Almost the whole world, at some point of time, was placed in lock-down in an attempt to stop the spread of the virus, with resulting psychological and economic sequela. As countries start to ease lock-down measures and reopen industries, ensuring a healthy workplace for employees has become imperative. Thus, this paper presents a mobile app-based intelligent portable healthcare (pHealth) tool, called i WorkSafe, to assist industries in detecting possible suspects for COVID-19 infection among their employees who may need primary care. Developed mainly for low-end Android devices, the i WorkSafe app hosts a fuzzy neural network model that integrates data of employees' health status from the industry's database, proximity and contact tracing data from the mobile devices, and user-reported COVID-19 self-test data. Using the built-in Bluetooth low energy sensing technology and K Nearest Neighbor and K-means techniques, the app is capable of tracking users' proximity and trace contact with other employees. Additionally, it uses a logistic regression model to calculate the COVID-19 self-test score and a Bayesian Decision Tree model for checking real-time health condition from an intelligent e-health platform for further clinical attention of the employees. Rolled out in an apparel factory on 12 employees as a test case, the pHealth tool generates an alert to maintain social distancing among employees inside the industry. In addition, the app helps employees to estimate risk with possible COVID-19 infection based on the collected data and found that the score is effective in estimating personal health condition of the app user.;2169-3536;;10.1109/ACCESS.2021.3050193;Nottingham Trent University, U.K., ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9317697;Industry 4.0,artificial intelligence,machine learning,mobile app,digital health,safe workplace,worker safety,Coronavirus;COVID-19,Diseases,Employment,Viruses (medical),Economics,Safety,Mobile applications;Bayes methods,Bluetooth,decision trees,diseases,epidemics,fuzzy neural nets,health care,medical diagnostic computing,medical information systems,nearest neighbour methods,occupational safety,patient diagnosis,regression analysis,smart phones,telemedicine;healthy workplace,intelligent Phealth App,mobile app-based intelligent portable healthcare tool,low-end Android devices,i WorkSafe app,fuzzy neural network model,real-time health condition,intelligent e-health platform,pHealth tool,COVID-19 infection,built-in Bluetooth low energy sensing technology,k-nearest neighbor,k-means technique,logistic regression model,Bayesian decision tree model,personal health condition;;40;;63;CCBY;8-jan-21;;;IEEE;IEEE Journals
Relational Learning Improves Prediction of Mortality in COVID-19 in the Intensive Care Unit;T. Wanyan, A. Vaid, J. K. De Freitas, S. Somani, R. Miotto, G. N. Nadkarni, A. Azad, Y. Ding, B. S. Glicksberg;Icahn School of Medicine at Mount Sinai, Hasso Plattner Institute for Digital Health at Mount Sinai, New York, NY, USA, Icahn School of Medicine at Mount Sinai, Hasso Plattner Institute for Digital Health at Mount Sinai, New York, NY, USA, Icahn School of Medicine at Mount Sinai, Hasso Plattner Institute for Digital Health at Mount Sinai, New York, NY, USA, Icahn School of Medicine at Mount Sinai, Hasso Plattner Institute for Digital Health at Mount Sinai, New York, NY, USA, Icahn School of Medicine at Mount Sinai, Hasso Plattner Institute for Digital Health at Mount Sinai, New York, NY, USA, Icahn School of Medicine at Mount Sinai, Hasso Plattner Institute for Digital Health at Mount Sinai, New York, NY, USA, School of Informatics, Computing, and Engineering, Indiana University, Bloomington, IN, USA, School of Information, University of Texas at Austin, Austin, TX, USA, Department of Genetics and Genomic Sciences, Icahn School of Medicine at Mount Sinai, New York, NY, USA;IEEE Transactions on Big Data;1 Mar 2021;2021;7;1;38;44;Traditional Machine Learning (ML) models have had limited success in predicting Coronoavirus-19 (COVID-19) outcomes using Electronic Health Record (EHR) data partially due to not effectively capturing the inter-connectivity patterns between various data modalities. In this work, we propose a novel framework that utilizes relational learning based on a heterogeneous graph model (HGM) for predicting mortality at different time windows in COVID-19 patients within the intensive care unit (ICU). We utilize the EHRs of one of the largest and most diverse patient populations across five hospitals in major health system in New York City. In our model, we use an LSTM for processing time varying patient data and apply our proposed relational learning strategy in the final output layer along with other static features. Here, we replace the traditional softmax layer with a Skip-Gram relational learning strategy to compare the similarity between a patient and outcome embedding representation. We demonstrate that the construction of a HGM can robustly learn the patterns classifying patient representations of outcomes through leveraging patterns within the embeddings of similar patients. Our experimental results show that our relational learning-based HGM model achieves higher area under the receiver operating characteristic curve (auROC) than both comparator models in all prediction time windows, with dramatic improvements to recall.;2332-7790;;10.1109/TBDATA.2020.3048644;U54(grant numbers:TR001433-05), National Center for Advancing Translational Sciences, National Institutes of Health, ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9311826;Electronic health records,COVID-19,machine learning,deep learning,LSTM,heterogeneous graph model,relational learning,embeddings,ICU,mortality;COVID-19,Diseases,Data models,Hospitals,Predictive models,Temperature measurement,Urban areas;;;;2;;21;CCBY;31-dec-20;;;IEEE;IEEE Journals
Safety-Critical Control of Compartmental Epidemiological Models With Measurement Delays;T. G. Molnár, A. W. Singletary, G. Orosz, A. D. Ames;Department of Mechanical Engineering, University of Michigan, Ann Arbor, MI, USA, Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, USA, Department of Mechanical Engineering, University of Michigan, Ann Arbor, MI, USA, Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, USA;IEEE Control Systems Letters;21-dec-20;2021;5;5;1537;1542;We introduce a methodology to guarantee safety against the spread of infectious diseases by viewing epidemiological models as control systems and human interventions (such as quarantining or social distancing) as control input. We consider a generalized compartmental model that represents the form of the most popular epidemiological models and we design safety-critical controllers that formally guarantee safe evolution with respect to keeping certain populations of interest under prescribed safe limits. Furthermore, we discuss how measurement delays originated from incubation period and testing delays affect safety and how delays can be compensated via predictor feedback. We demonstrate our results by synthesizing active intervention policies that bound the number of infections, hospitalizations and deaths for epidemiological models capturing the spread of COVID-19 in the USA.;2475-1456;;10.1109/LCSYS.2020.3040948;National Science Foundation, CPS(grant numbers:1932091), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9272547;COVID-19,epidemiology,safety-critical control,time delay;Safety,Statistics,Sociology,Biological system modeling,Delays,Data models,COVID-19;delays,diseases;safe evolution,design safety-critical controllers,popular epidemiological models,generalized compartmental model,control input,social distancing,human interventions,control systems,viewing epidemiological models,infectious diseases,compartmental epidemiological models,safety-critical control,active intervention policies,testing delays,incubation period,measurement delays,prescribed safe limits;;4;;35;IEEE;26-nov-20;;;IEEE;IEEE Journals
An Epidemiological Neural Network Exploiting Dynamic Graph Structured Data Applied to the COVID-19 Outbreak;V. La Gatta, V. Moscato, M. Postiglione, G. Sperlí;Department of Electrical and Information Technology, University of Naples Federico II, Naples, Italy, Department of Electrical and Information Technology, University of Naples Federico II, Naples, Italy, Department of Electrical and Information Technology, University of Naples Federico II, Naples, Italy, Department of Electrical and Information Technology, University of Naples Federico II, Naples, Italy;IEEE Transactions on Big Data;1 Mar 2021;2021;7;1;45;55;With the recent COVID-19 outbreak, we have assisted to the development of new epidemic models or the application of existing methodologies to predict the virus spread and to analyze how the different lock-down strategies can effectively influence the epidemic diffusion. In this paper, we propose a novel machine learning based framework able to estimate the parameters of any epidemiological model, such as contact rates and recovery rates, based on static and dynamic features of places. In particular, we model mobility data through a graph series whose spatial and temporal features are investigated by combining Graph Convolutional Neural Networks (GCNs) and Long short-term memories (LSTMs) in order to infer the parameters of SIR and SIRD models. We evaluate the proposed approach using data related to the COVID-19 dynamics in Italy and we compare the forecasts of the trained model with available data about the epidemic spread.;2332-7790;;10.1109/TBDATA.2020.3032755;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9234698;COVID-19,epidemic diffusion modeling,data analytics,data model,spatio temporal data mining,deep learning,graph machine learning;Data models,Epidemics,Predictive models,Mathematical model,COVID-19,Analytical models;;;;26;;45;IEEE;21 Oct 2020;;;IEEE;IEEE Journals
Time Warping Clustering for the Forecast and Analysis of COVID-19;Q. Jin;Computing and Mathematical Sciences California Institute of Technology,Pasadena,US;2020 IEEE MIT Undergraduate Research Technology Conference (URTC);17-jan-22;2020;;;1;5;This paper presents an effective algorithm for the clustering of confirmed COVID-19 cases at the county-level in the United States. Dynamic time warping and Euclidean distance are examined as the k-means clustering distance metrics. Dynamic time warping can compare time series varying in speed, as counties often experience similar outbreak trends without the timelines matching up exactly. The effect of data preprocessing on clustering was systematically studied. Further analyses demonstrate the immediate value of our clusters for both retrospective interpretation of the pandemic and as informative inputs for case prediction models. We visualize the time progression of COVID-19 from April 5, 2020 to August 23, 2020. We proposed a Monte-Carlo dropout feedforward neural network with the ability to forecast four weeks into the future. Predictions evaluated from July 24, 2020 to August 20, 2020 demonstrate the better empirical performance of the model when trained on the clusters, in comparison with the model trained on individual counties and the model trained on counties clustered by state.;;978-1-7281-7571-3;10.1109/URTC51696.2020.9668904;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9668904;COVID-19,dynamic time warping,clustering;COVID-19,Measurement,Monte Carlo methods,Pandemics,Heuristic algorithms,Time series analysis,Euclidean distance;;;;;;10;;17-jan-22;;;IEEE;IEEE Conferences
Bidirectional Transformer based on online Text-based information to Implement Convolutional Neural Network Model For Secure Business Investment;M. Heidari, S. Rafatirad;George Mason University, George Mason University;2020 IEEE International Symposium on Technology and Society (ISTAS);28-jun-21;2020;;;322;329;Real estate investment decisions are critical for low-income people who have just one home as their life-time investment option. So during the COVID-19 pandemic, unemployment causes many homeowners with a low income to lose their homes because of two major factors: one, they could not pay their mortgages without a job, and second, their house could not be rented easily. Rent prediction in real-estate can guarantee the success of an investment. Online information from real estate websites plays a significant role in making a business decision to buy a home. This paper applies natural language processing models to introduce a new model for safe real estate investment based on online information. For the first time, we use a transfer learning model based on online information from various online resources to detect a profitable rental property. Bidirectional Encoder Representations from Transformers(BERT) are used to implement a semantic convolutional neural network model to predict real estate investment safety. This work introduces a new model for rent prediction based on the United States housing market. Our contribution is three-fold: (1) using natural language processing approach to use the semantics of online information on Airbnb, Zillow, Schools, Public transportation, and crime rate websites for rent prediction (2) We perform a comprehensive analysis of eager and lazy machine learning models as a traditional Machine learning models with our proposed new transfer learning model for rent prediction. (3) Creating a new public data set of semantic analysis for more than 5 million houses in the United States based on online information. This data set will be available for public research in natural language processing research for people analytic applications. This work introduces a new machine learning model to guarantee safe investment in the real estate market using a transfer learning approach based on online information.;2158-3412;978-1-6654-1507-1;10.1109/ISTAS50296.2020.9462170;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9462170;Natural language processing,transfer learning,Neural Network,Real estate,Analytical models,Atmospheric modeling,Semantics,Transfer learning,Predictive models,Natural language processing,Data models,business data processing,convolutional neural nets,investment,learning (artificial intelligence),natural language processing,real estate data processing,text analysis,unemployment,Web sites;online text-based information,estate Web sites,bidirectional transformer,machine learning,estate investment safety,semantic convolutional neural network model,online resources,transfer learning,natural language processing,online information,rent prediction,life-time investment option,low-income people,estate investment decisions,secure business investment;;4;;61;;28-jun-21;;;IEEE;IEEE Conferences;;
Predicting the Retweet Level of COVID-19 Tweets with Neural Network Classifier;Z. Qu, Z. Ding;Centre for Operational Research and Analysis,Defence Research and Development Canada,Ottawa,Ontario,Canada, Ottawa Research Centre,Defence Research and Development Canada,Ottawa,Ontario,Canada;2020 IEEE 19th International Conference on Cognitive Informatics & Cognitive Computing (ICCI*CC);14-jun-21;2020;;;15;20;A convolutional neural network (CNN) based classifier, to predict the retweet level of COVID-19 tweets, is proposed in this paper. The proposed CNN is able to predict whether a given COVID-19 tweet would be more retweeted, or less retweeted. The network is trained and validated with 100,000 and 5,000 English tweet samples, respectively, which were all posted within the last week of March 2020, and 81% accuracy has been achieved. The network is also evaluated by English tweet samples posted at the end of April. The result shows that the accuracy is about 80%. Therefore, the proposed approach is robust and capable to process tweets of chosen contents/topics.;;978-1-7281-9594-0;10.1109/ICCICC50026.2020.9450271;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9450271;COVID-19,social media,Twitter,misinformation,disinformation,retweet,machine learning,convolutional neural network,classification;COVID-19,Training,Neurons,Convolutional neural networks,Cognitive systems,Biological neural networks;convolutional neural nets,data analysis,Internet,natural language processing,pattern classification,social networking (online);COVID-19 tweets,CNN,convolutional neural network based classifier,retweet level prediction,English tweet samples;;;;26;;14-jun-21;;;IEEE;IEEE Conferences
U.S. Pandemic Prediction Using Regression and Neural Network Models;T. Liu;Dalian Yuming Senior High School,Dalian,China;2020 International Conference on Intelligent Computing and Human-Computer Interaction (ICHCI);10 May 2021;2020;;;351;354;With the global outbreak of COVID-19 in 2020, it is essential for government to make aware of the trend of the pandemic. To achieve this goal, some regression and neural network models are used to predict pandemic data of the U.S. Three models -linear regression, logistic regression, and Recurrent Neural Network (RNN) - are selected for predicting cases per million people in America. Then, the effectiveness of these models is compared. These models are evaluated using Mean Squared Error (MSE). It can be concluded that while the traditional regression models, including linear and logistic regression, are much more efficient for inference, RNN predicts more accurately, with the smallest MSE being nearly 2.8. This paper gives effective guidance for American governments on how to select models to predict relevant data of the pandemic.;;978-1-6654-2316-8;10.1109/ICHCI51889.2020.00080;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9424771;Pandemic Prediction,Linear Regression,Logistic Regression,RNN,COVID-19;COVID-19,Recurrent neural networks,Pandemics,Government,Linear regression,Predictive models,Market research;backpropagation,diseases,epidemics,mean square error methods,medical computing,recurrent neural nets,regression analysis;MSE,RNN,mean squared error,linear regression,pandemic data,COVID-19,global outbreak,neural network models,U.S. pandemic prediction,recurrent neural network,logistic regression;;;;20;;10 May 2021;;;IEEE;IEEE Conferences
Artificial Intelligence Facing COVID-19 Pandemic for Decision Support in Algeria;B. Seyfallah, T. Benkedjouh;University of Sciences and Technology Houari Boumediene,Algiers,Algeria,16111, EMP, LMS,Bordj Elbahri Algiers,Algeria;2020 4th International Symposium on Informatics and its Applications (ISIA);10 May 2021;2020;;;1;6;In this paper, we presents a new mathematical formula for COVID-19 spread virus based on polynomial regression. Although this statistical estimation aims to fits a nonlinear model to the observed data vector (from Covid-19 data series provided from the World Health Organization (WHO)). Moreover, a survey based on the WHO's covid 19 symptoms and recommandations with ten(10) chosen questions is developed, in addition, the person's age is also taken into consideration. It aimed at constituting COVID-19 database from volunteers responses using the OCSS (Open COVID-19 Survey System), that is designed with Qt5 and coded with Python on Ubuntu system. Chosen individuals displacements parameter in the developed formula is based on the best fit correlation from the model and lifestyle state [number of walking per day (confined / unconfined)]. considering the reduced number of volunteers dataset (100), in order to enlarge the Learning database, we generate a 1000 synthetic random response score from OCSS system. The 100 real responses constitute the test database. Finally, using python Keras Sequential model Tensorflow backends, an opensource deep learning frameworks, to classify OCSS data and give better accuracy with the obtained model of 99.10 %, Loss:0.03. Test phase gives a high accuracy of 98.00 %, Loss:0.08. We propose a nearly four months (until Oct 14) forecasting based on the obtained model and proposed formula.;;978-1-7281-9652-7;10.1109/ISIA51297.2020.9416545;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9416545;Polynomial regression,COVID-19,Deep learning,Time series,OCSS survey,python Tensorflow;COVID-19,Meters,Legged locomotion,Databases,Estimation,Predictive models,Data models;artificial intelligence,decision support systems,diseases,epidemics,medical computing,regression analysis;artificial intelligence,COVID-19 pandemic,decision support,mathematical formula,polynomial regression,statistical estimation,nonlinear model,observed data vector,World Health Organization,COVID-19 database,Ubuntu system,learning database,OCSS system,OCSS data,python Keras Sequential model Tensorflow,open source deep learning;;;;19;;10 May 2021;;;IEEE;IEEE Conferences
Analyzing students’ online presence in undergraduate courses using Clustering;R. Nand, A. Chand, M. Naseem;The University of the South Pacific,School of Computing, Information and Mathematical Sciences,Suva,Fiji, The University of the South Pacific,College of Science, Technology and Environment,Suva,Fiji, The University of the South Pacific,School of Computing, Information and Mathematical Sciences,Suva,Fiji;2020 IEEE Asia-Pacific Conference on Computer Science and Data Engineering (CSDE);28-apr-21;2020;;;1;6;The Higher Education Institute (HEI) are experiencing a major paradigm shift due to recent global pandemic. A sudden shift from face-to-face (F2F) and blended modes of study to completely online mode of delivery has introduced hidden challenges to facilitators and students alike. Student's online engagement has become even more important for their academic success as F2F component is not there in most cases. Therefore, there is a need to investigate the effects of the various indicators of students' online presence towards their academic performance. This paper explores the effectiveness of online presence in HEI where Covid-19 has shifted the course deliveries to fully online mode. Previously, Online Measurable Presence Model (OMPM) was used to find students effectiveness in a blended learning environment where two indicators used were Frequency and Duration. The chosen indicator in this research is frequency, which will be adequately used to quantify the effectiveness of the online presence in two mathematics courses in the Pacific. Clustering technique is used to create clusters of Frequency and see their relation to OMPM model. Prediction is made using neural network to see the accuracy based on model. The clusters would allow to build predictive models to predict future outcomes or occurrences and student performances, with a major focus on mathematics courses.;;978-1-6654-1974-1;10.1109/CSDE50874.2020.9411534;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9411534;online presence,clustering,neural network,self-organizing map,mathematics;COVID-19,Pandemics,Neural networks,Education,Predictive models,Data engineering,Frequency measurement;computer aided instruction,educational courses,educational institutions,further education,mathematics computing,neural nets,pattern clustering;academic performance,HEI,course deliveries,fully online mode,blended learning environment,mathematics courses,clustering technique,student performances,undergraduate courses,higher education institute,global pandemic,students online presence,face-to-face modes,blended modes,F2F component,online measurable presence model,neural network;;1;;25;;28-apr-21;;;IEEE;IEEE Conferences
Machine Learning Algorithms for Forecasting COVID 19 Confirmed Cases in America;M. F. Jojoa Acosta, B. Garcia-Zapirain;University of Deusto, University of Deusto;2020 IEEE International Symposium on Signal Processing and Information Technology (ISSPIT);22-apr-21;2020;;;1;6;This paper presents a Multilayer Perceptron and Support Vector Machine algorithms approach to predict the number of COVID19 infections in different countries of America. It intends to serve as a tool for decision-making and tackling the pandemic that the world is currently facing. The models were trained and tested using open data from the European Union repository where a time series of confirmed contagious cases was modeled until May 25, 2020. The hyperparameters as number of neurons per layer were set up using a tabu list algorithm. The countries selected to carry out the study were Brazil, Chile, Colombia, Mexico, Peru and the United States. The metrics used are Pearson's correlation coefficient (CP), Mean Absolute Error (MAE), and Mean Percentage Error (MPE). For the testing stage we obtained the following results: Brazil, CP=0.65, MAE=2508 and MPE=17%, Chile, CP=0.64, MAE=504, MPE=16%, Colombia, CP=0.83, MAE=76, MPE=9%, Mexico, CP=0.77, MAE=231, MPE=9%, Peru, CP=0.76, MAE=686, MPE=18% and the United States of America, CP=0.93, MAE=799, MPE=4%. This resulted in powerful machine learning tools although it is necessary to use specific algorithms depending on the data and the stage of the country's pandemic.;2641-5542;978-1-6654-1589-7;10.1109/ISSPIT51521.2020.9408742;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9408742;Multilayer Perceptron,Support Vector Machine,COVID19,SarsCov2,Forecasting,Machine Learning,Public Health,Pandemic,Support vector machines,Measurement,COVID-19,Machine learning algorithms,Pandemics,Signal processing algorithms,Tools,biology computing,epidemics,learning (artificial intelligence),multilayer perceptrons,search problems,support vector machines,time series,forecasting COVID 19 confirmed cases,America,multilayer perceptron,COVID19 infections,decision-making,open data,European Union repository,confirmed contagious cases,tabu list algorithm,Brazil,Chile,Colombia,Mexico,United States,mean absolute error,mean percentage error,MPE,testing stage,machine learning tools,machine learning algorithms,support vector machine algorithms approach,time series,Pearson's correlation coefficient;;;;;25;;22-apr-21;;;IEEE;IEEE Conferences;;
Based on the BPN and MARS model to discuss how hotels influence operational performance through intellectual capital;W. J. Hung, L. Yu Tseng, J. H. Chang, Y. -Y. Ruan;Min Jiang University,School of Economics and Management,Fuzhou,China, Nanfang College of Sun Yat-Sen University,Business School,Guangzhou,China, Nanfang College of Sun Yat-Sen University,Accounting School,Guangzhou,China, Min Jiang University,School of Economics and Management,Fuzhou,China;2020 Management Science Informatization and Economic Innovation Development Conference (MSIEID);23 Mar 2021;2020;;;43;49;Hotels are facing the greatest challenge since the outbreak of SARS and coronavirus disease, and researchers discovered that intellectual capital plays a crucial role at such times. This study applies the concept of artificial neural networks to investigate the effects of hotel intellectual capital with operating performances. This research select 145 international hotels listed in Asian countries' stock markets in the U.S. Compustat database to investigate the association between the value of intellectual capital and operating performances. This study proposes a two-stage construction procedure. First, The multivariate adaptive regression splines forecasting(MARS) results show that Z-score, Economic Added Value of Employees, Turnover Rate of Fixed Assets, Revenue Growth Rata, Turnover Rate of Accounts Receivable, and Employee Productivity play crucial roles in the intellectual capital dimension on operating performance. Second, the research use the obtained MARS variables as input variables of the back-propagation neural network model(MARS-BPN) not only to shorten the time required for model training but also provides a preferable prediction. The MARS-BPN forecasting has important implications for the implementation of appropriate operating performance decisions or strategies.;;978-1-6654-1541-5;10.1109/MSIEID52046.2020.00016;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9382502;Artificial Neural Network,Multivariate Adaptive Regression Splines,Intellectual Capital,Financial Health,Operating Performance;Training,Technological innovation,Artificial neural networks,Predictive models,Knowledge management,Splines (mathematics),Stock markets;backpropagation,diseases,neural nets,production engineering computing,regression analysis,splines (mathematics),stock markets;artificial neural networks,employee productivity,intellectual capital dimension,back-propagation neural network model,MARS-BPN forecasting,hotels influence operational performance,U.S. compustat database,multivariate adaptive regression splines forecasting,economic added value;;;;37;;23 Mar 2021;;;IEEE;IEEE Conferences
A Deep Recurrent Neural Network to Support Guidelines and Decision Making of Social Distancing;M. Aledhari, R. Razzak, R. M. Parizi, A. Dehghantanha;Kennesaw State University,College of Computing and Software Engineering,GA,USA, Kennesaw State University,College of Computing and Software Engineering,GA,USA, Kennesaw State University,College of Computing and Software Engineering,GA,USA, University of Guelph,Cyber Science Lab, School of Computer Science,Canada;2020 IEEE International Conference on Big Data (Big Data);19 Mar 2021;2020;;;4233;4240;The recent Covid-19 pandemic instigated many changes in our way of life within the United States, and slowly but surely we are working towards mitigating the virus. Due to Covid-19, there are higher demands for models to accurately forecast the number of Covid-19 cases that factor mandated guidelines such as social-distancing. Many scholarly and corporate research entities are investigating ways to achieve this goal preemptively, Unfortunately, current models are not yet able to accurately model future Covid-19 cases that factor in various guidelines, What is lacking with these models is an understanding of crucial factors affecting spread, accuracy, availability of reported cases on a small scale, and quantifiable metrics for how social distancing and quarantine efforts mitigate the spread. Therefore, the goal of this study is to produce a mathematical model to directly aid policy decisions by comparing predicted models of various decisions and social distancing protocols. This model can be applied on top of existing models to factor in more imminent data and produce predictive curves, indicating troughs and peaks of new daily Covid-19 cases with comparatively high accuracy, which can aid in analysis. These predictive curves can, therefore, be generated using data corresponding to projected responses to proposed guidelines and compared to each other to choose the optimal solution for “flattening the curve” of the Covid19 infection rate. We use an LSTM-RNN model with ANN Regression in an attempt to predict future Covid-19 cases. Our model achieved comparable results, but further improvements could be implemented for more optimal results.;;978-1-7281-6251-5;10.1109/BigData50022.2020.9377800;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9377800;Machine Learning,Epidemiology,Medical Field,Covid-19,Healthcare,Policy Making,Pandemic Response;COVID-19,Biological system modeling,Predictive models,Data models,Social factors,Mathematical model,Guidelines;decision making,decision support systems,government policies,health care,recurrent neural nets,regression analysis;daily Covid-19 cases,predictive curves,Covid19 infection rate,LSTM-RNN model,deep recurrent neural network,decision making,Covid-19 pandemic,United States,factor mandated guidelines,social-distancing,scholarly research entities,corporate research entities,model future Covid-19 cases,reported cases,mathematical model,policy decisions,social distancing protocols;;;;16;;19 Mar 2021;;;IEEE;IEEE Conferences
r-LSTM: Time Series Forecasting for COVID-19 Confirmed Cases with LSTMbased Framework;M. Masum, H. Shahriar, H. M. Haddad, M. S. Alam;Kennesaw State University,Analytics and Data Science Institute,Kennesaw,USA, Kennesaw State University,Department of Information Technology,Marietta,USA, Kennesaw State University,Department of Computer Science,Marietta,USA, Kennesaw State University,Analytics and Data Science Institute,Kennesaw,USA;2020 IEEE International Conference on Big Data (Big Data);19 Mar 2021;2020;;;1374;1379;The coronavirus disease 2019 (COVID-19) caused a pandemic outbreak with affecting 213 nations worldwide. Global policymakers are imposing many measures to slow and reduce the rapid growth of the infections. On the other hand, the healthcare system is encountering significant challenges for a massive number of COVID-19 confirmed or suspected individuals seeking treatment. Therefore, estimating the number of confirmed cases is necessary to provide valuable insights into the growth of the outbreak and facilitate policy making process. In this study, we apply ARIMA models as well as LSTM-based recurrent neural network to forecast the daily cumulative confirmed cases. The LSTM architecture generates more precise forecasting by leveraging both short- and long-term temporal dependencies from the pandemic time series data. Due to the stochastic nature in optimization and random initialization of weights in neural network, the LSTM based model produce less reproducible outcome. In this paper, we propose a reproducible-LSTM (r-LSTM) framework that produces a reproducible and robust results leveraging z-score outlier detection method. We performed five round of nested cross validation to show the consistency in evaluating model performance. The experimental results demonstrate that r-LSTM outperformed the ARIMA model producing minimum MAPE, RMSE, and MAE.;;978-1-7281-6251-5;10.1109/BigData50022.2020.9378276;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9378276;ARIMA Model,LSTM,Time Series Forecasting,COVID-19 pandemic,coronavirus;COVID-19,Pandemics,Time series analysis,Predictive models,Big Data,Data models,Forecasting;autoregressive moving average processes,diseases,epidemics,forecasting theory,government policies,mean square error methods,medical computing,neural net architecture,optimisation,recurrent neural nets,time series;r-LSTM,ARIMA,time series forecasting,COVID-19 confirmed cases,coronavirus disease 2019,pandemic outbreak,global policymakers,policy making,LSTM-based recurrent neural network,daily cumulative confirmed cases,LSTM architecture,long-term temporal dependencies,pandemic time series data,reproducible-LSTM,short-term temporal dependencies,optimization,z-score outlier detection,nested cross validation,MAPE,RMSE,MAE;;;;22;;19 Mar 2021;;;IEEE;IEEE Conferences
DeepSEAS: Smartphone-based Early Ailment Sensing Using Coupled LSTM AutoEncoders;S. N. Murthy, F. Asani, S. Srikanthan, E. Agu;Worcester Polytechnic Institute,Worcester,MA,01609, Worcester Polytechnic Institute,Worcester,MA,01609, Worcester Polytechnic Institute,Worcester,MA,01609, Worcester Polytechnic Institute,Worcester,MA,01609;2020 IEEE International Conference on Big Data (Big Data);19 Mar 2021;2020;;;4911;4918;Infectious diseases epidemics such as the current COVID-19 pandemic have an immense impact on all facets of life. Consequently, the current dearth of effective and timely public health surveillance methods, especially at the individual level, have been accentuated, prompting research into supplementary methods. Sensor-rich, ubiquitously owned smartphones can now gather large volumes of data that has been utilized for passive and continuous physical and mental health assessment. In this paper, we propose a Deep learning based Smartphone Early Ailment Sensing (DeepSEAS) framework that predicts a smart-phone user's future manifestation of influenza-like biological symptoms (e.g. coughing and sneezing) a day early while they are still asymptomatic. DeepSEAS works by analyzing a subject's historical one-day smartphone sensor and mobility data. First, we utilize the mean shift clustering algorithm to create clusters of users with similar social and behavioral traits such as their socialization levels, social media presence, eating and working out habits. Then, DeepSEAS employs an end-to-end trainable LSTM Autoencoder (LSTM AE) coupled with a Feed Forward Neural network classifier, a chieving a sensitivity of 7 8% i n correctly identifying users who will manifest biological symptoms a day later. DeepSEAS facilitates up-to-date influenza s urveillance at the individual level, which could transform the current healthcare system. Early detection can enable asymptomatic users to be alerted, notified and isolated, which could reduce disease transmission.;;978-1-7281-6251-5;10.1109/BigData50022.2020.9377885;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9377885;WLAN,Proximity,LSTM Autoencoder,Mean-Shift Clustering,Influenza;Social networking (online),Surveillance,Transforms,Big Data,Biology,Sensors,Smart phones;deep learning (artificial intelligence),diseases,epidemics,feedforward neural nets,health care,medical computing,mobile computing,pattern classification,pattern clustering,recurrent neural nets,smart phones,social networking (online),social sciences computing;DeepSEAS,healthcare system,infectious diseases epidemics,COVID-19 pandemic,public health surveillance,mental health assessment,mobility data,social traits,behavioral traits,end-to-end trainable LSTM Autoencoder,LSTM AE,deep learning based smartphone early ailment sensing,coupled LSTM autoencoders,feedforward neural network classifier,mean shift clustering;;2;;32;;19 Mar 2021;;;IEEE;IEEE Conferences
Examining Deep Learning Models with Multiple Data Sources for COVID-19 Forecasting;L. Wang, A. Adiga, S. Venkatramanan, J. Chen, B. Lewis, M. Marathe;University of Virginia,Computer Science,Charlottesville,VA,22903, University of Virginia,Biocomplexity Institute and Initiative,Charlottesville,VA,22903, University of Virginia,Biocomplexity Institute and Initiative,Charlottesville,VA,22903, University of Virginia,Biocomplexity Institute and Initiative,Charlottesville,VA,22903, University of Virginia,Biocomplexity Institute and Initiative,Charlottesville,VA,22903, University of Virginia,Computer Science,Charlottesville,VA,22903;2020 IEEE International Conference on Big Data (Big Data);19 Mar 2021;2020;;;3846;3855;The COVID-19 pandemic represents the most significant public health disaster since the 1918 influenza pandemic. During pandemics such as COVID-19, timely and reliable spatio-temporal forecasting of epidemic dynamics is crucial. Deep learning-based time series models for forecasting have recently gained popularity and have been successfully used for epidemic forecasting. Here we focus on the design and analysis of deep learning-based models for COVID-19 forecasting. We implement multiple recurrent neural network-based deep learning models and combine them using the stacking ensemble technique. In order to incorporate the effects of multiple factors in COVID-19 spread, we consider multiple sources such as COVID-19 confirmed and death case count data and testing data for better predictions. To overcome the sparsity of training data and to address the dynamic correlation of the disease, we propose clustering-based training for high-resolution forecasting. The methods help us to identify the similar trends of certain groups of regions due to various spatio-temporal effects. We examine the proposed method for forecasting weekly COVID-19 new confirmed cases at county-, state-, and country-level. A comprehensive comparison between different time series models in COVID-19 context is conducted and analyzed. The results show that simple deep learning models can achieve comparable or better performance when compared with more complicated models. We are currently integrating our methods as a part of our weekly forecasts that we provide state and federal authorities.;;978-1-7281-6251-5;10.1109/BigData50022.2020.9377904;National Institutes of Health, Centers for Disease Control and Prevention, ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9377904;;COVID-19,Deep learning,Training,Analytical models,Predictive models,Data models,Forecasting;deep learning (artificial intelligence),diseases,epidemics,medical computing,pattern clustering,recurrent neural nets,spatiotemporal phenomena,time series;multiple data sources,COVID-19 forecasting,COVID-19 pandemic,significant public health disaster,timely spatio-temporal forecasting,reliable spatio-temporal forecasting,deep learning-based time series models,epidemic forecasting,multiple recurrent neural network-based deep learning models,COVID-19 spread,testing data,training data,high-resolution forecasting,forecasting weekly COVID-19,stacking ensemble technique,disease,death case count data,clustering-based training;;1;;40;;19 Mar 2021;;;IEEE;IEEE Conferences
Google Trends Analysis of COVID-19 Pandemic;Z. Pan, H. L. Nguyen, H. Abu-gellban, Y. Zhang;Texas Tech University,Department of Computer Science, Texas Tech University,College of Engineering, Texas Tech University,Department of Computer Science, Texas Tech University,Department of Computer Science;2020 IEEE International Conference on Big Data (Big Data);19 Mar 2021;2020;;;3438;3446;The World Health Organization (WHO) announced that COVID-19 was a pandemic disease on the 11th of March as there were 118K cases in several countries and territories. Numerous researchers worked on forecasting the number of confirmed cases since anticipating the growth of the cases helps governments adopting knotty decisions to ease the lockdowns orders for their countries. These orders help several people who have lost their jobs and support gravely impacted businesses. Our research aims to investigate the relation between Google search trends and the spreading of the novel coronavirus (COVID-19) over countries worldwide, to predict the number of cases. We perform a correlation analysis on the keywords of the related Google search trends according to the number of confirmed cases reported by the WHO. After that, we applied several machine learning techniques (Multiple Linear Regression, Nonnegative Integer Regression, Deep Neural Network), to forecast the number of confirmed cases globally based on historical data as well as the hybrid data (Google search trends). Our results show that Google search trends are highly associated with the number of reported confirmed cases, where the Deep Learning approach outperforms other forecasting techniques. We believe that it is not only a promising approach for forecasting the confirmed cases of COVID-19, but also for similar forecasting problems that are associated with the related Google trends.;;978-1-7281-6251-5;10.1109/BigData50022.2020.9377852;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9377852;coronavirus,covid’19,forecasting,search trends,neural networks,machine learning,spatio-temporal analysis;COVID-19,Pandemics,Neural networks,Predictive models,Market research,Internet,Forecasting;deep learning (artificial intelligence),diseases,information retrieval,medical computing,regression analysis,search engines;Google trends analysis,COVID-19 pandemic,World Health Organization,pandemic disease,related Google search trends,reported confirmed cases;;1;;39;;19 Mar 2021;;;IEEE;IEEE Conferences
Machine Learning Methods on COVID-19 Situation Prediction;Z. Yang, K. Chen;Beijing University of Posts and Telecommunications,School of Information and Communication Engineering,Beijing,China,100876, Wuhan University,School of Mathematic and Statistics,Wuhan,China,430072;2020 International Conference on Artificial Intelligence and Computer Engineering (ICAICE);1 Mar 2021;2020;;;78;83;COVID-19 has already had a devastating impact on economic and social development and people's life all over the world. Up to September 22nd, 2020, more than 30 million people have been infected. Finding out how to predict and estimate the pandemic trend precisely is of huge necessity because COVID-19 has made the world economy in a recession and deprived over 700 thousand lives. This paper is dedicated to making a comparison between conventional machine learning regression models, including ridge regression and lasso regression, and multivariate polynomial regression. Besides, we attempt to use statewide data to fit nationwide data in the US, proposing a novel aspect to forecast pandemic trend.Under the current situation, insufficient data limit the use of machine learning. To address the issue of data deficiency, a classification model based on neural network with Twitter data is applied. This gives out an alternative approach to estimate daily increase of infected people.We discovered that in a different period, specific models would outweigh another models' performance. Also, our result showed that the data of Georgia and Massachusetts could represent the whole nation data with linear transformations. And this paper verified that using alternative data that relate to the COVID-19 situation to alleviate data deficiency is feasible.;;978-1-7281-9146-1;10.1109/ICAICE51518.2020.00021;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9361227;COVID-19,Machine learning,Trend prediction,Regression model,Neural network;COVID-19,Pandemics,Social networking (online),Biological system modeling,Machine learning,Predictive models,Market research;diseases,epidemics,learning (artificial intelligence),medical computing,neural nets,pattern classification,regression analysis,social networking (online);COVID-19 situation prediction,economic development,social development,machine learning regression models,ridge regression,lasso regression,multivariate polynomial regression,classification model,Twitter data,pandemic trend estimation,neural network;;1;;11;;1 Mar 2021;;;IEEE;IEEE Conferences
Research on Time Series Problem Model Based on Dynamic Network NAR and Multiple Regression;Z. Liu, J. Zuo, R. lv, Y. Sun, H. Kang;Shenyang Aerospace University,Shenyang,110136, Tongji University,Department of Computer Science and Technology,Shanghai,201804, Shenyang Aerospace University,Shenyang,110136, Shenyang Aerospace University,Shenyang,110136, Shenyang Aerospace University,Shenyang,110136;2020 International Conference on Artificial Intelligence and Computer Engineering (ICAICE);1 Mar 2021;2020;;;416;419;With the escalation of the trade war between China and the United States and the outbreak of the new coronavirus epidemic in early 2020, China's economy has been seriously affected. Accurate prediction of future economic development is a necessary means to formulate economic development strategies. For this reason, taking Guangdong province, the province with the strongest economic vitality, as an example, this paper uses multiple regression method to calculate the correlation degree and influence weight of population number, number of enterprises and per capita disposable income with economic development, and obtains multiple regression linear equation. In addition, this paper also uses the NAR dynamic neural network model in machine learning algorithms to predict the future trends of the three factors and economic aggregates, and analyzes the feedback results of network training errors, autocorrelation values, and partial correlation values. Compared with the multiple regression method, it is found that the final results of the two are very similar, with small errors and high correlation.;;978-1-7281-9146-1;10.1109/ICAICE51518.2020.00088;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9361289;NAR dynamic neural network,time series,machine learning,economic vitality prediction,memory and feedback;Analytical models,Correlation,Economic indicators,Linear regression,Time series analysis,Market research,Mathematical model;economic indicators,econophysics,learning (artificial intelligence),neural nets,regression analysis,time series;multiple regression method,time series problem model,dynamic network NAR,trade war,United States,coronavirus epidemic,future economic development,economic development strategies,Guangdong province,strongest economic vitality,correlation degree,population number,capita disposable income,multiple regression linear equation,NAR dynamic neural network model,economic aggregates,network training errors,partial correlation values;;1;;10;;1 Mar 2021;;;IEEE;IEEE Conferences
Face Mask Detection Classifier and Model Pruning with Keras-Surgeon;A. Negi, P. Chauhan, K. Kumar, R. S. Rajput;National Institute of Technology,Department of Computer Science and Engineering,Srinagar (Garhwal),Uttarakhand,India, G.B. Pant University of Agriculture and Technology,Department of Information Technology,Pantnagar,India, National Institute of Technology,Department of Computer Science and Engineering,Srinagar (Garhwal),Uttarakhand,India, G.B. Pant University of Agriculture and Technology,Department of Mathematics, Statistics and Computer Science,Pantnagar,India;2020 5th IEEE International Conference on Recent Advances and Innovations in Engineering (ICRAIE);26-feb-21;2020;;;1;6;Multidisciplinary initiatives in the new world of coronavirus were combined to limit the spread of the pandemic. Interestingly, the AI group was a part of those efforts. This result-based approach is used to help scan, assess, predict and track current patients and possibly potential patients. Developments for tracking social distances or recognizing face masks have made headlines in particular. Most current advanced approaches to face mask recognition are built based on deep learning which is dependent on a large number of face samples. Nearly everybody wears a mask during corona virus outbreak in order to effectively avoid the spread of COVID-19 virus. Our goal is to train a customized deep learning model that helps to detect even if or not a person wears a mask and study the concept of model pruning with Keras-Surgeon. Model pruning can be efficient in reducing model size, so that it can be easily implemented and inferred on embedded systems.;;978-1-7281-8867-6;10.1109/ICRAIE51050.2020.9358337;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9358337;CNN,Data Augmentation,Deep learning,Face Mask,Model pruning;COVID-19,Deep learning,Training,Technological innovation,Face recognition,Social factors,Viruses (medical);diseases,embedded systems,face recognition,learning (artificial intelligence),medical computing,medical disorders,microorganisms,neural nets;Keras-Surgeon,multidisciplinary initiatives,AI group,result-based approach,current patients,possibly potential patients,social distances,recognizing face masks,current advanced approaches,mask recognition,face samples,corona virus outbreak,COVID-19 virus,customized deep learning model,model pruning,face mask detection classifier;;5;;12;;26-feb-21;;;IEEE;IEEE Conferences
An Enhanced Approach to Infer Potential Host of Coronavirus by Analyzing Its Spike Genes Using Multilayer Artificial Neural Network;K. Lakhwani, S. Bhargava, D. Somwanshi, R. Doshi, K. K. Hiran;Lovely Professional University,dept. of Computer Science & Engineering,Punjab,India, Poornima College of Engineering,dept. of Computer Science & Engineering,Jaipur,Rajasthan,India, Poornima College of Engineering,dept. of Computer Science & Engineering,Jaipur,Rajasthan,India, Jayoti Vidyapeeth Women's University,dept. of Computer Science Technology,Jaipur,Rajasthan,India, Sir Padampat Singhania University,dept. of Computer Science & Engineering,Udaipur,Rajasthan,India;2020 5th IEEE International Conference on Recent Advances and Innovations in Engineering (ICRAIE);26-feb-21;2020;;;1;5;Numerous coronaviruses are capable of transmitting interspecies. In recent years, transmission of coronavirus created a panic situation in the whole world. Therefore it is very important to infer the potential host of coro- navirus. In this research work nineteen parameters computed from the spike genes of coronavirus has been analysed to infer the potential host of coron- avirus. An enhanced multilayer neural network approach is proposed to analyse the data. The proposed model is compared with the other exiting statistical predictors like decision tree predictor, Support vector machine predictor and PNN predictor. All the model shown the higher accuracy such as 82.051 % by SVM predictor, 85.256% by PNN predictor,94.872% by decision tree predictor, and the highest accuracy 95.% is shown by proposed Multilayer Perceptron Predictor.;;978-1-7281-8867-6;10.1109/ICRAIE51050.2020.9358382;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9358382;SVM Predictor,Decision Tree Predictor,PNN Predictor,Multilayer Perceptron,Artificial Neural Network;Support vector machines,COVID-19,Multilayer perceptrons,Predictive models,Tools,Nonhomogeneous media,Decision trees;biology computing,decision trees,learning (artificial intelligence),multilayer perceptrons,support vector machines;enhanced approach,infer potential host,spike genes,multilayer artificial neural network,numerous coronaviruses,panic situation,research work nineteen parameters,coronavirus,enhanced multilayer neural network approach,statistical predictors,decision tree predictor,PNN predictor,SVM predictor,multilayer perceptron predictor,support vector machine predictor;;;;12;;26-feb-21;;;IEEE;IEEE Conferences
Performance of Different Models of Machine Learning in Predicting the COVID-19 Pandemic;Q. Wang;Dalian Maritime University Dalian,Liaoning,China,116026;2020 International Conference on Public Health and Data Science (ICPHDS);26-feb-21;2020;;;218;226;COVID-19 outbreaks experienced explosive growth worldwide in late 2019 and early 2020. In order to control the spread of the epidemic, many researchers used different machine learning models to predict the trend of the epidemic. This paper tested the performance of some common machine learning models to predict the epidemic, so as to provide a basis for future researchers to choose models. This paper used different models of machine learning, including the Susceptible Infected Recovered Model, classic machine learning of the Linear Regression, Polynomial Regression, k-Nearest Neighbor, Logistic Growth Model and the Long Short-Term Memory model of deep learning. Based on the data of the United States, Japan, Wuhan, China, we intended to predict the COVID-19 trend in these countries with the parameters of the machine learning and intuitive chart to measure the prediction results of different model, also, we put into consideration the degree of each country to the attention of the outbreak as well as control mode and analyze the different models to predict the tendency of the epidemic development rationality and validity.;;978-1-7281-8571-2;10.1109/ICPHDS51617.2020.00050;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9361901;COVID-l9,epidemic,Machine learning,Forecast;COVID-19,Epidemics,Analytical models,Linear regression,Predictive models,Market research,Data models;deep learning (artificial intelligence),diseases,epidemics,nearest neighbour methods,recurrent neural nets,regression analysis;deep learning,COVID-19 pandemic,epidemic researchers,linear regression,polynomial regression,k-nearest neighbor,United States,Japan,Wuhan,China,long short-term memory model,logistic growth model,machine learning,susceptible infected recovered model;;;;15;;26-feb-21;;;IEEE;IEEE Conferences
The COVID-19 Pandemic Prediction in the US Based on Machine Learning;W. Zou;Shandong University (Weihai),School of Mechanical, Electrical and Information Engineering,Weihai,China,264209;2020 International Conference on Public Health and Data Science (ICPHDS);26-feb-21;2020;;;283;289;The COVID-19 pandemic situation is aggravating in the United States, and due to its high infection rate, it seems hard to predict the number of infected people. In this research, we carry out machine learning methods such as linear regression and neuron networks to make predictions on the number of positive cases of COVID-19. We also collect state-level data to generate predictions by linear regression and we find that the data from two states-Georgia and Massachusetts-can be used to predict the number of infections nationwide. After dividing our dataset into 3 consecutive time periods and training different models to fit each corresponding data, we compare mean square error (MSE) values to draw the conclusion that for the first time period the Lasso performs better than Ridge, for the second time period the Ridge and Lasso behave similarly on our data, and for the third period time the Ridge fits our data better than Lasso. Furthermore, from the general perspective regardless of 3 time periods we find that single variable linear regression performs more accurately than fully connected neural network.;;978-1-7281-8571-2;10.1109/ICPHDS51617.2020.00062;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9361928;COVID-19 prediction,Coronavirus,Linear regression,Lasso regression,Ridge regression,Neural network;COVID-19,Pandemics,Neurons,Linear regression,Machine learning,Predictive models,Data models;diseases,learning (artificial intelligence),mean square error methods,medical computing,neural nets,regression analysis;COVID-19 pandemic prediction,United States,high infection rate,infected people,machine learning methods,neuron networks,positive cases,state-level data,Georgia,mean square error,time period,period time,single variable linear regression,Massachusetts;;1;;7;;26-feb-21;;;IEEE;IEEE Conferences
Coronavirus Disease (COVID-19) Global Prediction Using Hybrid Artificial Intelligence Method of ANN Trained with Grey Wolf Optimizer;S. Ardabili, A. Mosavi, S. S. Band, A. R. Varkonyi-Koczy;University of Mohaghegh Ardabili,Department of Biosystem Engineering,Ardabil,Iran, Institute of Automation, Obuda University,Budapest,Hungary,1034, National Yunlin University of Science and Technology,Yunlin,Taiwan,64002, Institute of Automation, Obuda University,Budapest,Hungary,1034;2020 IEEE 3rd International Conference and Workshop in Óbuda on Electrical and Power Engineering (CANDO-EPE);9-feb-21;2020;;;251;254;Advancement of the novel models for time-series prediction of COVID-19 is of utmost importance. Machine learning (ML) methods have recently shown promising results. The present study aims to engage an artificial neural network-integrated by grey wolf optimizer for COVID-19 outbreak predictions by employing the Global dataset. Training and testing processes have been performed by time-series data related to January 22 to September 15, 2020 and validation has been performed by time-series data related to September 16 to October 15, 2020. Results have been evaluated by employing mean absolute percentage error (MAPE) and correlation coefficient (r) values. ANN-GWO provided a MAPE of 6.23, 13.15 and 11.4% for training, testing and validating phases, respectively. According to the results, the developed model could successfully cope with the prediction task.;;978-1-7281-8491-3;10.1109/CANDO-EPE51100.2020.9337757;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9337757;COVID-19,Machine learning (ML),Grey wolf optimizer (GWO),artificial neural network (ANN),time-series,outbreak prediction;COVID-19,Training,Artificial neural networks,Machine learning,Predictive models,Task analysis,Testing;biology computing,diseases,epidemics,learning (artificial intelligence),neural nets,optimisation,time series;global dataset,testing processes,time-series data,ANN-GWO,hybrid artificial intelligence method,grey wolf optimizer,time-series prediction,machine learning methods,artificial neural network,COVID-19 outbreak predictions,coronavirus disease global prediction,mean absolute percentage error,correlation coefficient values;;3;;12;;9-feb-21;;;IEEE;IEEE Conferences
Real-time estimation of COVID-19 cases using machine learning and mathematical models - The case of India;P. Kumari, D. Toshniwal;Indian Institute of Technology,Department of Computer Science & Engineering,Roorkee,India, Indian Institute of Technology,Department of Computer Science & Engineering,Roorkee,India;2020 IEEE 15th International Conference on Industrial and Information Systems (ICIIS);8-feb-21;2020;;;369;374;COVID-19 pandemic has stressed out the economy and resources of major countries across the world due to its high infection and transmission rate. The count of COVID-19 cases skyrocketed in the past few days, which creates immense pressure on health officials and governments. Therefore, prediction models to determine the number of new infections are urgently required in such grave times. In the present study, a machine learning technique, namely artificial neural network (ANN) is proposed to forecast the COVID-19 outbreak in India, for the first time. Moreover, in our study, we have additionally attempted to use a mathematical curve fitting model to ascertain the performance of the proposed ANN-based machine learning model. In addition, the impact of preventive measures such as lockdown and social distancing on the spread of COVID-19 is also analyzed by estimating the growth of the epidemic under different transmission rates. Moreover, a comparison between the proposed and existing COVID-19 prediction models is also demonstrated. Intriguingly, the proposed model is found to be highly accurate in estimating the growth of COVID-19 related parameters with the lowest MAPE values (cumulative confirmed cases (3.981), daily confirmed cases (4.173) and cumulative deceased cases (4.413)). Hence, the present study can assist the health officers and administration in getting prepared with the beforehand arrangement of the required resources and medical facilities.;2164-7011;978-1-7281-8524-8;10.1109/ICIIS51140.2020.9342735;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9342735;Covid-19,infectious disease,prediction,machine learning,artificial neural network;COVID-19,Biological system modeling,Machine learning,Artificial neural networks,Predictive models,Social factors,Mathematical model;curve fitting,diseases,epidemics,health care,learning (artificial intelligence),neural nets,regression analysis;transmission rate,COVID-19 cases,grave times,machine learning technique,COVID-19 outbreak,India,ANN-based machine learning model,different transmission rates,proposed existing COVID-19 prediction models,COVID-19 related parameters,cumulative confirmed cases,daily confirmed cases,cumulative deceased cases,time estimation,mathematical models,COVID-19 pandemic,high infection;;1;;27;;8-feb-21;;;IEEE;IEEE Conferences
Link Prediction Using Semi-Automated Ontology and Knowledge Graph in Medical Sphere;S. Varma, S. Shivam, R. Jamaiyar, A. Anukriti, S. Kashyap, A. Sarkar;ZS Associates,Pune,India, Jadavpur University,IEEE Industry Applications Society,Chapter Advisor,Pune,India, Jadavpur University,dept. of Instrumentation and electronics,Kolkata,India, Jadavpur University,dept. of Instrumentation and electronics,Kolkata,India, IBM,Associate System Engineer,Kolkata,India, NIT, Durgapur,dept. of Electrical Engineering,Durgapur,India;2020 IEEE 17th India Council International Conference (INDICON);5-feb-21;2020;;;1;5;Presently, medical professionals and researchers face a dire problem trying to identify important and subject specific documents for medical research. This is mainly owing to the fact that there is a disconnection in the pipeline for finding essential documents via a common platform which can parse and link the complex medical terminologies. To solve this problem, a model is generated, which creates a Semi-automated ontology and Knowledge-graph for link prediction using unstructured medical documents. To extract entities from a document is a tiresome task but can be achieved using multiple resources like DBPedia, pretrained statistical models on English provided by spaCy. Though, for biomedical data above two are not enough, as another key challenge with biomedical data is with its commonly occurring abbreviated names and noun compounds containing punctuation, which might lead to misidentification. To overcome this problem and also to train this model more medical specific, [bionlp13cg] model provided by scispaCy is used. It is a spaCy NER model trained on the BIONLP13CG corpus. This model not only extracts entities which are more specific to the medical domain, but also label them according to the category they belong to. All the entities are classified into subclass and main-class using ontologies. Hence link is predicted between two entities according to the categories they belong to. Ontology is created using Medical Subject Headings (MeSH) RDF. It is a linked data representation of the MeSH biomedical vocabulary produced by the National Library of Medicine, thereby it provides precise results. Since, some entities are not identified by Mesh, they are first categorized using labels obtained by scispaCy, if it is recognized by latter. Further these categories are mapped to MeSH Ontology to enhance the precision of linked entities. Since this model is graph enabled, it gives users a very specific relation between medical terminologies.;2325-9418;978-1-7281-6916-3;10.1109/INDICON49873.2020.9342301;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9342301;COVID-19,Ontology,Knowledge Graph,Natural language processing,Graph convolutional networks,Deep learning,MeSH,link prediction;Vocabulary,Terminology,Biological system modeling,Ontologies,Predictive models,Mathematical model,Bioinformatics;data structures,information retrieval,medical computing,medical information systems,natural language processing,ontologies (artificial intelligence),text analysis,vocabulary;link prediction,Semiautomated Ontology,Knowledge graph,medical professionals,dire problem,important documents,subject specific documents,medical research,essential documents,common platform,complex medical terminologies,Semiautomated ontology,Knowledge-graph,unstructured medical documents,tiresome task,multiple resources,pretrained statistical models,biomedical data,spaCy NER model,BIONLP13CG corpus,extracts entities,medical domain,subclass,main-class using ontologies,Medical Subject Headings RDF,linked data representation,MeSH biomedical vocabulary,MeSH Ontology,linked entities,specific relation;;;;5;;5-feb-21;;;IEEE;IEEE Conferences
Performance Comparison of Classification Models for Diabetes Prediction;S. Bamal, M. Gupta, N. Sewal, A. Sharma;DPGITM(MDU),CSE Department,Gurgaon,India, Starex University),CSE Department,Gurgaon,India, DPGITM(MDU),CSE Department,Gurgaon,India, Teerthanker Mahaveer University,Moradabad,India;2020 9th International Conference System Modeling and Advancement in Research Trends (SMART);4-feb-21;2020;;;45;51;Diabetes is an incessant illness and a significant general wellbeing challenge worldwide and adds to nerve harm, visual deficiency, coronary illness, expands the dangers of creating kidney sickness and coronary illness and vein harm. The fundamental goal of this work is to plan a classification model by utilizing the machine learning methods. Counts are done to anticipate diabetes in patients at a beginning phase with most extreme exactness by utilizing machine learning classification algorithm specifically SVM, Naive Bayes, Decision tree, Random Forest, Linear Regression, and K-NN, Neural Network. Dataset is taken from UCI (Machine Learning Repository) and calculations and tests are done on the dataset and result got shows Neural Net, improved k-NN, and improved Random Forest beats with most elevated precision of (96%) and (93%) and (78.8%) nearly different calculations.;;978-1-7281-8908-6;10.1109/SMART50582.2020.9337123;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9337123;Diabetes,Data Mining,SVM,Naive Bayes,Decision tree,Random forest,Linear Regression,K-NN,Neural Net,Result and Discussion;Visualization,Veins,Neural networks,Prediction algorithms,Diabetes,Classification algorithms,Random forests;decision trees,diseases,learning (artificial intelligence),medical diagnostic computing,neural nets,pattern classification,support vector machines;classification model,diabetes prediction,machine learning methods,classification algorithm,Random Forest,Machine Learning Repository;;;;20;;4-feb-21;;;IEEE;IEEE Conferences
Simulate the number of confirmed COVID-19 Cases in 9 Countries from January to June 2020 based on 3 Models;Z. Xiao, J. He, R. Zhao;College of Earth Sciences, Jilin University,Changchun,China, College of Earth Sciences, Jilin University,Changchun,China, College of Earth Sciences, Jilin University,Changchun,China;2020 IEEE 3rd International Conference of Safe Production and Informatization (IICSPI);1-feb-21;2020;;;605;610;Currently, the COVID-19 pandemic has been effectively controlled in China. However, the situation remains grim in several other countries around the world - with continued risk and adverse impact on the safety and lives of people, industrial production, and societal activities. In this context, this study aims to analyze and simulate the number of confirmed cases in 9 countries (US, Brazil, Chile, India, Russia, Peru, Pakistan, Mexico and Saudi Arabia) affected by severe COVID-19 outbreaks from January to June 2020, in order to provide potential guidance for the prevention and control of COVID-19. More specifically, one infectious disease model (SEIR, Susceptible Exposed Infectious Removed) and two time-series models (ARIMA, Autoregressive Integrated Moving Average and LSTM, Long Short-Term Memory) were adopted to simulate the number of confirmed COVID-19 cases in these countries. A comparison between the simulated results obtained via these 3 models demonstrates that the time-series models (ARIMA and LSTM) yield good results only on a short-term scale. The average Mean Squared Logarithmic Error (MSLE) of ARIMA on the test set was observed to be 0.11, while that of LSTM was 0.12. However, on a long-term scale, these two models were unable to forecast the inflection point of the pandemic, with error exhibiting a gradual increase with time. In comparison, the improved SEIR model exhibited an average MSLE of 2.25 on the test set, but yielded more accurate longterm forecasts.;;978-1-7281-7738-0;10.1109/IICSPI51290.2020.9332361;China Scholarship Council(grant numbers:CSC201906175002), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9332361;ARIMA,COVID-19,LSTM,SEIR,Simulation;COVID-19,Analytical models,Pandemics,Infectious diseases,Production,Predictive models,Data models;autoregressive moving average processes,epidemics,medical computing,recurrent neural nets,time series;COVID-19 pandemic,COVID-19 outbreaks,infectious disease model,susceptible exposed infectious removed model,time-series models,ARIMA,LSTM,long short-term memory,confirmed COVID-19 cases,improved SEIR model,mean squared logarithmic error,MSLE,US,Brazil,Chile,India,Russia,Peru,Pakistan,Mexico,Saudi Arabia;;1;;13;;1-feb-21;;;IEEE;IEEE Conferences
Autocorrelation Sequence Prediction Model Based On Reference Function Transformation: Taking Epidemic Prediction As An Example;T. Liu, T. Zhou, J. Gao, W. Li, Y. Ma;Shenyang University of Technology,College of Information Science and Engineering,Shenyang,110020, Shenyang University of Technology,College of Information Science and Engineering,Shenyang,110020, Shenyang University of Technology,College of Information Science and Engineering,Shenyang,110020, Shenyang University of Technology,College of Information Science and Engineering,Shenyang,110020, Shenyang University of Technology,College of Information Science and Engineering,Shenyang,110020;2020 Chinese Automation Congress (CAC);29-jan-21;2020;;;1599;1604;Autocorrelation sequence prediction is one of the hotspots in machine learning and statistics. At present, the problem of epidemic prediction is concerned by the whole world in this field. In this paper, a prediction algorithm of autocorrelation sequence based on transformation is proposed. It construct a reference function based on the time series of regions that have experienced the whole process of epidemic situation. The reference function coordinates are transformed with the incomplete observation data of other regions as the supervision. Under the condition that the cost of transformation is kept as small as possible, the transformed function can effectively predict the series values that are not observed in other regions. This algorithm needs a little data and has good training stability. On this basis, we study how to use the information provided by other exogenous variables on the basis of autocorrelation prediction to make the model achieve better results. We use the covid-19 epidemic data set provided by Baidu to test our model, and the results show that it has good fitting metrics. It also has better effect in comparison with LSTM epidemic prediction model baseline.;2688-0938;978-1-7281-7687-1;10.1109/CAC51589.2020.9327602;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9327602;Autocorrelation Sequence,Time Series Analysis,Neural Network,Coordinate Transformation,Transfer Learning,Machine Learning,Epidemic Prediction;Predictive models,Correlation,Epidemics,Data models,Training,Time series analysis,Fitting;biology computing,epidemics,forecasting theory,learning (artificial intelligence),recurrent neural nets,time series;autocorrelation sequence prediction model,reference function transformation,machine learning,statistics,time series,epidemic situation,reference function coordinates,observation data,covid-19 epidemic data,LSTM epidemic prediction model baseline,long short-term memory;;;;12;;29-jan-21;;;IEEE;IEEE Conferences
A review of the prevalent ICT techniques used for COVID-19 SOP violation detection;T. Ikram, A. Saeed, N. Ayn, M. A. Tahir, R. Mumtaz;National University of Sciences and Technology (NUST), School of Electrical Engineering and Computer Science,Islamabad,Pakistan, National University of Sciences and Technology (NUST), School of Electrical Engineering and Computer Science,Islamabad,Pakistan, National University of Sciences and Technology (NUST), School of Electrical Engineering and Computer Science,Islamabad,Pakistan, National University of Sciences and Technology (NUST), School of Electrical Engineering and Computer Science,Islamabad,Pakistan, National University of Sciences and Technology (NUST), School of Electrical Engineering and Computer Science,Islamabad,Pakistan;2020 IEEE 17th International Conference on Smart Communities: Improving Quality of Life Using ICT, IoT and AI (HONET);21-jan-21;2020;;;194;198;COVID-19 is a disease that has adversely impacted the health and daily lives of people worldwide, therefore there must be measures in place to control the spread of such diseases. Standard Operating Procedures (SOPs) such as wearing masks and maintaining social distancing are enforced by the Government and healthcare authorities. These SOP's mitigate the spread of COVID-19, but it has been observed with concern that people do not generally follow them. This survey work explores classical techniques that can be used to detect SOP violations. These are primarily computer vision based methods used in object detection and distance estimation. We will also explore deep learning based techniques used for object detection to detect SOP violations.;1949-4106;978-0-7381-0527-7;10.1109/HONET50430.2020.9322821;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9322821;COVID-19,SOPs,Deep learning,Distance estimation;Feature extraction,COVID-19,Object detection,Faces,Computer architecture,Real-time systems,Deep learning;computer vision,diseases,health care,learning (artificial intelligence),object detection;prevalent ICT techniques,COVID-19 SOP violation detection,standard operating procedures,masks,social distancing,healthcare authorities,SOP violations,object detection,deep learning based techniques,SOP mitigation;;3;;30;;21-jan-21;;;IEEE;IEEE Conferences
Deep Learning for COVID-19 prediction;S. Bahri, M. Kdayem, N. Zoghlami;National School of Engineering of Tunis, LTSIRS Laboratory,Tunis,Tunisia,1002, National School of Engineering of Sousse, National School of Engineering of Tunis, LTSIRS Laboratory,Tunis,Tunisia,1002;2020 4th International Conference on Advanced Systems and Emergent Technologies (IC_ASET);20-jan-21;2020;;;406;411;From January 30, 2020, COVID-19 disease was announced by the World Health Organization (WHO) as a Public Health Emergency of International Concern (PHEIC). For that, many scientific researchers were interested in developing algorithms and models in order to mitigate the spread of this epidemic. Existing mathematical models including compartmental models such as SEIR, SIR, SIRQ and statistical models such as ARIMA, ARMA often fail to capture the dynamic of the propagation of an epidemic. Recently, artificial intelligence-based models have proven their effectiveness and accuracy in classification and prediction tasks. This paper aim to deploy a Recurrent Neural Network architecture called Long Short-Term Memory (LSTM) neural network for predicting the next COVID-19 recovered cases in USA, India and Italy for seven days ahead. The model' effectiveness is then evaluated on the basis of the Mean Absolute Percentage Error (MAPE) criterion. Experiments show that LSTM model is accurate with a minimal error that not exceed 3%.;;978-1-7281-6356-7;10.1109/IC_ASET49463.2020.9318297;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9318297;Deep Learning,LSTM,Forecasting models,Time Series data;COVID-19,Artificial neural networks,Recurrent neural networks,Training,Diseases,Data models,Predictive models;deep learning (artificial intelligence),diseases,emergency management,epidemics,medical information systems,neural net architecture,pattern classification,recurrent neural nets;artificial intelligence-based models,classification,prediction tasks,recurrent neural network architecture,long short-term memory neural network,COVID-19 recovered cases,model effectiveness,LSTM model,COVID-19 prediction,COVID-19 disease,World Health Organization,Public Health Emergency of International Concern,PHEIC,mathematical models,mean absolute percentage error criterion,deep learning,epidemic spread mitigation,USA,India,Italy,MAPE criterion;;;;53;;20-jan-21;;;IEEE;IEEE Conferences
Forecast of the number of new patients and those who died from COVID-19 in Bahrain;A. -O. Strontsitska, O. Pavliuk, R. Dunaev, R. Derkachuk;Institute of Computer Sciences and Information Technologies, Lviv Polytechnic National University,Department of Automated Control Systems,Lviv,Ukraine, Institute of Computer Sciences and Information Technologies, Lviv Polytechnic National University,Department of Automated Control Systems,Lviv,Ukraine, Institute of Computer Sciences and Information Technologies, Lviv Polytechnic National University,Department of Automated Control Systems,Lviv,Ukraine, Institute of Computer Sciences and Information Technologies, Lviv Polytechnic National University,Department of Automated Control Systems,Lviv,Ukraine;2020 International Conference on Decision Aid Sciences and Application (DASA);15-jan-21;2020;;;422;426;A review of the COVID-19 pandemic in Bahrain has been conducted. Correlations between the parameters describing the coronavirus pandemic have been established. Partially lost data was supplemented by polynomial functions, as well as by linear approximation. The number of those who suffered and those who died from COVID-19 was predicted using SGTM neural-like structure topologies supervised mode.;;978-1-7281-9677-0;10.1109/DASA51403.2020.9317122;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9317122;COVID-19,Bahrain,ANN,SGTM neural-like structure,forecast of the number of new patients,forecast those who died from COVID-19,matrix of correlations between parameters,linear approximation;COVID-19,Correlation,Pandemics,Biological neural networks,Neurons,Linear approximation,Viruses (medical);diseases,epidemics,medical computing,microorganisms,neural nets,polynomials,supervised learning,topology;Bahrain,COVID-19 pandemic,coronavirus pandemic,polynomial functions,linear approximation,SGTM neural like structure topologies supervised mode,neural network training;;1;;10;;15-jan-21;;;IEEE;IEEE Conferences
Random Net Implementation of MLP and LSTMs Using Averaging Ensembles of Deep Learning Models;V. A. Bharadi;Head Research Center, Finolex Academy of Management and Technology, Mumbai University,Ratnagiri,Maharashtra,India;2020 International Conference on Decision Aid Sciences and Application (DASA);15-jan-21;2020;;;1197;1204;Long Short Term Memory Networks are a special type of recurrent Neural Network having better performance. LSTMs are widely used for sequence prediction. The multilayer perceptron (MLP) provides a nonlinear mapping between an input vector and a corresponding output vector. MLPs are a popular class of feedforward neural networks used for binary as well as multi-class classification. Ensemble learning is a technique by which the variance in the performance of a deep learning model is reduced by combining learning from various models for a combination of different training data as well as other parameters. This paper is discussing an experiment where this mechanism is implemented for binary classification using MLP and LSTM sequence prediction. A random Net implementation using an ensemble of MLPs as well as LSTMs is discussed here. The network is trained for a random length of the training sequence and the performance of single and ensemble classifiers is compared. The results show that the ensemble classifier is more robust and has a better stability.;;978-1-7281-9677-0;10.1109/DASA51403.2020.9317015;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9317015;LSTM,MLP,Deep Learning,Random Nets,Random Forest,Ensemble Learning,Overfitting,Regularization;Predictive models,Data models,Training,COVID-19,Training data,Neural networks,Deep learning;deep learning (artificial intelligence),feedforward neural nets,multilayer perceptrons,pattern classification,recurrent neural nets,vectors;MLP,LSTMs,deep learning,long short term memory networks,recurrent neural network,multilayer perceptron,nonlinear mapping,input vector,output vector,feedforward neural networks,multiclass classification,ensemble learning,binary classification,sequence prediction,random net implementation;;;;26;;15-jan-21;;;IEEE;IEEE Conferences
Prediction of Gross Domestic Product (GDP) in Indonesia Using Deep Learning Algorithm;S. Sa'adah, M. S. Wibowo;School of Computing, Telkom University,Bandung,Indonesia, School of Computing, Telkom University,Bandung,Indonesia;2020 3rd International Seminar on Research of Information Technology and Intelligent Systems (ISRITI);13-jan-21;2020;;;32;36;Growth Domestic Product (GDP) is the important factor to know the stability of financial condition in a country. Regarding into GDP value could be known the economic condition per capita. Especially, during this pandemic situation, GDP need study further about its sudden fluctuation. The solution can be covered using the prediction approach. Deep learning as new method from machine learning schema had been observed in this research to cope the prediction of GDP problem. Two methods of deep learning techniques that were used, LSTM and RNN, shown that the prediction could fit the data actual very well. The accuracy at around 80% until 90% emerge from LSTM architecture 2 and RNN architecture 2. Based on this result, it could bring new perspective to use this model to know the GDP fluctuation in a country even in catastrophe of Covid-19.;;978-1-7281-8406-7;10.1109/ISRITI51436.2020.9315519;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9315519;GDP Prediction,LSTM,RNN,Deep Learning Algorithm;Computer architecture,Economic indicators,Training,Recurrent neural networks,Microprocessors,Deep learning,Artificial neural networks;economic indicators,financial data processing,learning (artificial intelligence),recurrent neural nets;economic condition,pandemic situation,sudden fluctuation,prediction approach,machine learning schema,GDP problem,deep learning techniques,GDP fluctuation,gross domestic product,deep learning algorithm,financial condition,GDP value,growth domestic product,Covid-19,LSTM architecture,RNN architecture;;;;35;;13-jan-21;;;IEEE;IEEE Conferences
Long Short-Term Memory Forecasting for COVID19 Data;M. S. Milivojević, A. Gavrovska;School of Electrical Engineering, University of Belgrade,Belgrade,Serbia,11120, School of Electrical Engineering, University of Belgrade,Belgrade,Serbia,11120;2020 28th Telecommunications Forum (TELFOR);11-jan-21;2020;;;1;4;Nowadays everyone is talking about Coronavirus 2 or COVID-19. It is a severe acute respiratory syndrome which produces a lot of concerns around the globe. Since data is available for everyone, as well as for the Republic of Serbia, we used it for experiments via a neural network. Here, a long short-term memory approach is applied in order to make experiments with its parameters, such as the number of layers and the number of hidden units. The results show proper modelling from the standard root mean square error standpoint. The paper contribution is related to testing the parameters in the long short-term memory approach for recent data from the Republic of Serbia.;;978-1-6654-0499-0;10.1109/TELFOR51502.2020.9306601;Ministry of Education, Science and Technological Development of the Republic of Serbia, ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9306601;Severe Acute Respiratory Syndrome Coronavirus 2,forecasting,neural network,long short-term memory;COVID-19,Neural networks,Logic gates,Computer architecture,Training,Microprocessors,Standards organizations;diseases,epidemics,medical administrative data processing,medical computing,recurrent neural nets;long short-term memory forecasting,COVID19 data,Coronavirus 2,severe acute respiratory syndrome,neural network;;1;;18;;11-jan-21;;;IEEE;IEEE Conferences
Elastic Net to Forecast COVID-19 Cases;T. K. Johnsen, J. Z. Gao;San Jose State Univeristy,Applied Data Science,San Jose,CA,USA, Computer Engineering San Jose State University,San Jose,CA,USA;2020 International Conference on Innovation and Intelligence for Informatics, Computing and Technologies (3ICT);8-jan-21;2020;;;1;6;Forecasting novel daily cases of COVID-19 is crucial for medical, political, and other officials who handle day to day, COVID-19 related logistics. Current machine learning approaches, though robust in accuracy, can be either black boxes, specific to one region, and/or hard to apply if the user has nominal knowledge in machine learning and programing. This weakens the integrity of otherwise robust machine learning methods, causing them to not be utilized to their full potential. Thus, the presented Elastic Net COVID-19 Forecaster, or EN-CoF for short, is designed to provide an intuitive, generic, and easy to apply forecaster. EN-CoF is a multi-linear regressor trained on time series data to forecast number of novel daily COVID-19 cases. EN-CoF maintains a high accuracy on par with more complex models such as ARIMA and Bi-LSTM, while gaining the advantages of transparency, generalization, and accessibility.;;978-1-7281-9673-2;10.1109/3ICT51146.2020.9311968;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9311968;COVID-19,Elastic Net,Machine Learning,Artificial Intelligence,Time Series,Forecast;Predictive models,Time series analysis,COVID-19,Mathematical model,Data models,Training,Measurement;learning (artificial intelligence),regression analysis,time series;time series data,political officials,Elastic Net COVID-19 Forecaster,daily COVID-19 cases,EN-CoF,programing,black boxes,machine learning approaches,COVID-19 related logistics,medical officials;;1;;32;;8-jan-21;;;IEEE;IEEE Conferences
Predictions of COVID-19 Infection Severity Based on Co-associations between the SNPs of Co-morbid Diseases and COVID-19 through Machine Learning of Genetic Data;R. Y. Wang, T. Q. Guo, L. G. Li, J. Y. Jiao, L. Y. Wang;Shanghai American School,Shanghai,China, Shanghai United International School,Shanghai,China, University of Illinois at Urbana-Champaign,Champaign,United States, Tianjin No.1 High School,Tianjin,China, Shanghai American School,Shanghai,China;2020 IEEE 8th International Conference on Computer Science and Network Technology (ICCSNT);7-jan-21;2020;;;92;96;In this research, a quantitative model is built to predict people's susceptibility to COVID-19 based on their genomes. Identifying people vulnerable to COVID-19 infections is crucial in stopping the spread of the virus. In previous studies, researchers have found that individuals with comorbid diseases have higher chances of being infected and developing more severe COVID-19 conditions. However, these patterns are only observed through correlational analyses between patient phenotypes and the severity of their COVID-19 infection. In this study, genetic variants underlying the observed comorbidity patterns are analyzed through machine learning of COVID-19 data from GWAS studies, which may reveal biological pathways underlying COVID-19 contraction that are essential to the development of effective and targeted therapeutics. Furthermore, through combining genetic variants with the individual's phenotypes, this study built a Neural Network model and Random Forest classifier to predict an individual's likelihood of COVID-19 infection. The Random Forest Classifier in this study shows that on-going symptoms are generally better predictors of COVID-19 condition (higher impurity-based feature importance) than diseases or medical histories. In addition, when trained with genomic data, the comorbid disease impact ranking deduced by the resulting RF model is highly consistent with phenotypic comorbidity patterns observed in past studies.;;978-1-7281-8123-3;10.1109/ICCSNT50940.2020.9304990;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9304990;SNP,COVID-19,Machine Learning,Neural Network,Random Forest,Genetics;COVID-19,Diseases,Genomics,Random forests,Predictive models,Data models,Bioinformatics;bioinformatics,diseases,genetics,genomics,learning (artificial intelligence),medical information systems,neural nets,pattern classification,random forests;COVID-19 infection severity,machine learning,comorbid diseases,severe COVID-19 conditions,genetic variants,COVID-19 data,COVID-19 contraction,COVID-19 condition,neural network model,random forest classifier,medical histories,phenotypic comorbidity patterns,GWAS;;10;;10;;7-jan-21;;;IEEE;IEEE Conferences
Understanding the Effects of Human Factors on the Spread of COVID-19 Using a Neural Network;A. Chhabra, D. Pately, X. Li, L. Pickering, J. Viaña, K. Cohen;University of Cincinnati,Cincinnati,Ohio,U.S.A.,45221, University of Cincinnati,Cincinnati,Ohio,U.S.A.,45221, University of Cincinnati,Cincinnati,Ohio,U.S.A.,45221, University of Cincinnati,Cincinnati,Ohio,U.S.A.,45221, University of Cincinnati,Cincinnati,Ohio,U.S.A.,45221, University of Cincinnati,Cincinnati,Ohio,U.S.A.,45221;2020 7th International Conference on Soft Computing & Machine Intelligence (ISCMI);7-jan-21;2020;;;121;125;During the spread of an infectious disease such as COVID-19, the identification of human factors that affect the spread is a really important area of research. These factors directly impact the spread of such a disease and are important in identifying the various regions that are at a higher risk than others. This allows for an optimal distribution of resources according to predicted demand. Traditional infectious modeling techniques are good at representing the spread and can incorporate multiple factors that resemble real-life scenarios. The primary issue here is the identification of relevant variables. In this study, a residual analysis is presented to downsize the dataset available and shortlist the variables classified as absolutely necessary for disease modeling. The performance of different datasets is evaluated using an Artificial Neural Network and regression analysis. The results show that the drop in performance using the reduced dataset is reasonable as it is very difficult to obtain a perfect dataset covering only necessary variables. This approach can be automated in the future as it offers a small dataset containing a few variables against a large dataset with possibly hundreds of variables.;2640-0146;978-1-7281-7559-1;10.1109/ISCMI51676.2020.9311591;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9311591;COVID -19,Infectious Diseases,Neural Network,Artificial Intelligence,Variable Reduction,Human Factors;Biological system modeling,COVID-19,Neurons,Human factors,Statistics,Sociology,Infectious diseases;diseases,human factors,medical computing,neural nets,regression analysis,risk analysis;human factors,COVID-19,infectious disease,traditional infectious modeling techniques,residual analysis,disease modeling,Artificial Neural Network,reduced dataset,perfect dataset,regression analysis;;;;16;;7-jan-21;;;IEEE;IEEE Conferences
An Imperative Diagnostic Model for Predicting CHD using Deep Learning;N. Mangathayaru, B. P. Rani, V. Janaki, S. M. Gajapaka, S. A. Patel, L. B. B;VNR Vignana Jyothi Institute of Engineering and Technology,Department of Information Technology, Jawaharlal Nehru Technological University,Department of Computer Science,Hyderabad, Vaagdevi Engineering college,Department of Computer Science, VNR Vignana Jyothi Institute of Engineering and Technology,Department of Information Technology, VNR Vignana Jyothi Institute of Engineering and Technology,Department of Information Technology, VNR Vignana Jyothi Institute of Engineering and Technology,Department of Information Technology;2020 IEEE International Conference for Innovation in Technology (INOCON);1-jan-21;2020;;;1;5;Coronary heart disease (CHD) is one of the leading cause of an increase in the mortality rate. Various factors are influencing to estimate the presence of CHD in an individual biologically. We made inferences with these influencing factors and their peculiarity by analyzing with a various set of algorithms which help in obtaining a precisive decision support system for the presence of CHD in an individual. We considered a set of linear models (Logistic Regression, Linear Discriminant Analysis), Naïve Bayes, Classification and Regression Trees (CART), Support Vector Machines (SVM). K-Nearest Neighbor (k-NN) for k=1 to 21. Next, we have considered a set of ensemble models. Furtherly, we computed a Multi-Layer Perceptron (MLP) and a Deep Neural Network to evaluate the performance through a deep learning approach. So, with this analysis, we found a linear model (Logistic Regression) tend to give on par results both in the case of Cleveland as well as Framingham dataset. This analysis led to design an intuitive approach for CHD classification and would give insights on how to use them in the medical research field.;;978-1-7281-9744-9;10.1109/INOCON50539.2020.9298423;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9298423;Coronary Heart Disease,Deep Learning,Disease Prediction,Feature Extraction;Heart,Data models,Diseases,Computational modeling,Feature extraction,Data mining,Deep learning;cardiology,decision support systems,deep learning (artificial intelligence),diseases,medical computing,multilayer perceptrons,naive Bayes methods,nearest neighbour methods,regression analysis,support vector machines;imperative diagnostic model,coronary heart disease,mortality rate,decision support system,logistic regression,linear discriminant analysis,Naïve Bayes,classification and regression trees,support vector machines,multilayer perceptron,deep neural network,deep learning,CHD classification,CHD prediction,k-nearest neighbor;;;;39;;1-jan-21;;;IEEE;IEEE Conferences
Short-Term Forecasting COVID-19 Cases In Turkey Using Long Short-Term Memory Network;S. S. HELLİ, Ç. DEMİRCİ, O. ÇOBAN, A. HAMAMCI;Yeditepe University,Department of Biomedical Engineering,Istanbul,Turkey, Yeditepe University,Department of Biomedical Engineering,Istanbul,Turkey, Yeditepe University,Department of Biomedical Engineering,Istanbul,Turkey, Yeditepe University,Department of Biomedical Engineering,Istanbul,Turkey;2020 Medical Technologies Congress (TIPTEKNO);25-dec-20;2020;;;1;4;COVID-19 has been one of the most severe diseases, causing a harsh pandemic all over the world, since December 2019. The aim of this study is to evaluate the value of Long Short-Term Memory (LSTM) Networks in forecasting the total number of COVID-19 cases in Turkey. The COVID-19 data for 30 days, between March 24 and April 23, 2020, are used to estimate the next fifteen days. The mean absolute error of the LSTM Network for 15 days estimation is 1,69±1.35%. Whereas, for the same data, the error of the Box-Jenkins method is 3.24±1.56%, Prophet method is 6.88±4.96% and Holt-Winters Additive method with Damped Trend is 0.47±0.28%. Additionally, when the number of deaths data is also provided with the number of total cases to the input of LSTM Network, the mean error reduces to 0.99±0.51%. Consequently, addition of the number of deaths data to the input, results a lower error in forecasting, compared to using only the number of total cases as the input. However, Holt-Winters Additive method with Damped Trend gives superior results to LSTM Networks in forecasting the total number of COVID-19 cases.;2687-7783;978-1-7281-8073-1;10.1109/TIPTEKNO50054.2020.9299235;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9299235;COVID-19,forecasting,Turkey,LSTM,ARIMA,HWAAS,Prophet,elu;Forecasting,COVID-19,Time series analysis,Predictive models,Market research,Estimation,Logic gates;data analysis,diseases,epidemics,medical computing,microorganisms,recurrent neural nets,time series;LSTM network,short term forecasting,Turkey,long short term memory network,COVID-19 disease,Box-Jenkins method,Prophet method,pandemic,Holt-Winters additive method with damped trend,time series data;;1;;19;;25-dec-20;;;IEEE;IEEE Conferences
Predicting COVID-19 Spread Level using Socio- Economic Indicators and Machine Learning Techniques;A. Mihoub, H. Snoun, M. Krichen, R. B. H. Salah, M. Kahia;Information System and Production Management, College of Business and Economics, Qassim University,Department of Management,Buraidah,Saudi Arabia,51452, Modeling in Hydraulics & Environment Labratory National Engineering, School of Tunis Campus universitaire,Departement of Civil Engineering,Bélvédére,Tunis,Tunisia,1002, ReDCAD Laboratory, University of Sfax,Tunisia, STC Solutions,Department of Digital Transformation,Riyadh,Saudi Arabia,12641, College of Business and Economics, Qassim University, LAREQUAD & FSEGT, University of Tunis El Manar, Tunisia,Department of Finance & Economics,Buraidah,Saudi Arabia,51452;2020 First International Conference of Smart Systems and Emerging Technologies (SMARTTECH);15-dec-20;2020;;;128;133;The new so-called COVID-19 virus is unfortunately founded to be highly transmissible across the globe. In this study, we propose a novel approach for estimating the spread level of the virus for each country for three different dates between April and May 2020. Unlike previous studies, this investigation does not process any historical data of spread but rather relies on the socioeconomic indicators of each country. Actually, more than 1000 socio-economic indicators and more than 190 countries were processed in this study. Concretely, data preprocessing techniques and feature selection approaches were applied to extract relevant indicators for the classification process. Countries around the globe were assigned to 4 classes of spread. To find the class level of each country, many classifiers were proposed based especially on Support Vectors Machines (SVM), Multi-Layer Perceptrons (MLP) and Random Forests (RF). Obtained results show the relevance of our approach since many classifiers succeeded in capturing the spread level, especially the RF classifier, with an F-measure equal to 93.85% for April 15th, 2020. Moreover, a feature importance study is conducted to deduce the best indicators to build robust spread level classifiers. However, as pointed out in the discussion, classifiers may face some difficulties for future dates since the huge increase of cases and the lack of other relevant factors affecting this widespread.;;978-1-7281-7407-5;10.1109/SMART-TECH49988.2020.00041;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9283753;covid-19,socio-economic indicators,data preprocessing,spread level prediction,machine learning,country classification,feature importance;Support vector machines,Radio frequency,COVID-19,Tools,Feature extraction,Viruses (medical),Random forests;epidemics,feature extraction,feature selection,medical computing,microorganisms,multilayer perceptrons,pattern classification,random forests,socio-economic effects,support vector machines;machine learning,COVID-19 virus,socioeconomic indicators,classification,support vector machines,COVID-19 spread level prediction,data preprocessing,feature selection,multilayer perceptrons,random forests;;1;;30;;15-dec-20;;;IEEE;IEEE Conferences
Prediction of Resumed Production Trajectories in the Post-Epidemic Area Based on Big Power Data;H. Li, X. Wang, X. Zhu, Z. Xu, Z. Yang;China United Engineering Corporation Limited, State Grid Zhejiang Economy Research Institute,Zhejiang,China, State Grid Zhejiang Hangzhou Fuyang Power Supply Company,Zhejiang,China, North China Electric Power University,Beijing,China, State Grid Nanjing Power Supply Company,China;2020 IEEE International Conference on Information Technology,Big Data and Artificial Intelligence (ICIBA);14-dec-20;2020;1;;137;141;Before the Spring Festival of 2020, China began to spread the new 2019-ncov coronavirus, and the outbreak period coincides with the Spring Festival. The ability to resume production of post-epidemic after the festival has become the focus of attention. This paper proposes an improved forecasting method for resumption based on big data and trajectory clustering. This method clusters the daily power consumption patterns of different industries, summarizes the characteristics of the epidemic situation, and improves the intelligent prediction method. It can evaluate the resumption of production in regional industries and enterprises when there is no clear trend in the external economic environment. It quantitatively solves the problem of forecasting and evaluating the degree of resumption in the context of the epidemic. Calculations are made for the resumption of production in typical industrial agglomeration areas, and the results show that the method can accurately reflect the recovery trend of enterprises and industries from the perspective of feature modification.;;978-1-7281-5224-0;10.1109/ICIBA50161.2020.9276988;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9276988;Big data,Reproduction prediction,FCM clustering,BP neural network,Feature extraction;Industries,Neural networks,Feature extraction,Springs,Optimization,Epidemics,Trajectory;Big Data,diseases,load forecasting,pattern clustering,power consumption,power engineering computing,power system economics;economic environment,resumed production trajectories,post-epidemic area,forecasting method,Big Data,trajectory clustering,daily power consumption patterns,intelligent prediction method,China,industrial agglomeration areas;;;;11;;14-dec-20;;;IEEE;IEEE Conferences
A Comparative Study of Predictive Machine Learning Algorithms for COVID-19 Trends and Analysis;A. Kunjir, D. Joshi, R. Chadha, T. Wadiwala, V. Trikha;Lakehead University,Department of Computer Science,Thunder Bay,Canada, Lakehead University,Department of Computer Science,Thunder Bay,Canada, Lakehead University,Department of Computer Science,Thunder Bay,Canada, Lakehead University,Department of Computer Science,Thunder Bay,Canada, Lakehead University,Department of Computer Science,Thunder Bay,Canada;2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC);14-dec-20;2020;;;3407;3412;This paper attempts to conduct analysis on the WHO dataset to produce predictive analysis applying different machine learning regression approaches such as decision trees, LSTM, and CNN regressor. The primary data has 91 entries, which consists of data of various countries with respect to dates along with confirmed cases, confirmed deaths, and recovered cases. The dataset has been divided into 70:30 in which 70 percent is used for training and validation, and 30 percent is used for testing. The coronavirus disease outbreak started in 2019, arising in Wuhan, China. The key objective is to exercise different artificial intelligence approaches, we ought to predict the confirmed cases, confirmed deaths, and recovered cases, and further, various visualization techniques have been used to deduce the meaningful inferences from the model's prediction and perform specific analytics on the results concluded. The prediction models such as LSTM and CNN are evaluated on the basis of several loss functions such as R2 score and Mean Squared Error.;2577-1655;978-1-7281-8526-2;10.1109/SMC42975.2020.9282953;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9282953;Coronavirus Disease 2019 (COVID-19),Convolutional Neural Network (CNN),Long-Short Term Memory (LSTM),data visualization,Loss function;COVID-19,Training,Machine learning algorithms,Predictive models,Market research,Real-time systems,Regression tree analysis;convolutional neural nets,data visualisation,decision trees,diseases,medical computing,recurrent neural nets,regression analysis;predictive machine learning algorithms,COVID-19 trends,predictive analysis,regression approaches,decision trees,CNN regressor,coronavirus disease outbreak,artificial intelligence approaches,LSTM regressor,loss functions,R2 score,mean squared error,visualization techniques,efficiency 70.0 percent,efficiency 30.0 percent;;1;;7;;14-dec-20;;;IEEE;IEEE Conferences
Machine Learning for Predicting Stock Market Movement using News Headlines;Y. Liu, J. Trajkovic, H. -G. H. Yeh, W. Zhang;California State University,Department of Computer Engineering and Computer Science,Long Beach,CA,90840, California State University,Department of Computer Engineering and Computer Science,Long Beach,CA,90840, California State University,Department of Electrical Engineering,Long Beach,CA,90840, California State University,Department of Computer Engineering and Computer Science,Long Beach,CA,90840;2020 IEEE Green Energy and Smart Systems Conference (IGESSC);11-dec-20;2020;;;1;6;There are many factors that affect performance of stock market, such as global and local economy, political events, supply and demand, and out of the ordinary events, as COVID-19 pandemic. The factors may not only influence the stock market movement, but also influence each other. We propose to observe the movement of Dow Jones Industrial Average in relations to daily news. We use top-5 news headlines from Reddit to create 1Day and 5-Day models to predict if Dow Jones Industrial Average movement will be in Down and Up direction from the moment the market opens till it closes. We propose use of shallow (traditional) Machine Learning algorithms and Deep Learning algorithms. Additionally, we explore the effect of word representation, using TF-IDF and GloVE approaches. Moreover, we evaluate our models in terms of accuracy of prediction on data sets containing data before pandemic and during pandemic. Our models show that Deep Learning models uniformly have higher accuracy than Machine Learning ones. Convolution Neural Network with TFIDF and 5 Days prediction performs the best for the dataset before the pandemic with accuracy of 59.6%. Gated Recurrent Unit (GRU), a class of Recurrent Neural Networks, with GloVe and 1 Day prediction outperforms the other models for dataset during the pandemic with the accuracy of 62.9%.;2640-0138;978-1-7281-8744-0;10.1109/IGESSC50231.2020.9285163;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9285163;Stock Movement,Text Classification,Text Mining,Machine Learning,Deep Learning;Deep learning,Machine learning algorithms,Supply and demand,Pandemics,Biological system modeling,Predictive models,Stock markets;deep learning (artificial intelligence),economics,recurrent neural nets,stock markets;supply and demand,COVID-19 pandemic,machine learning,deep learning algorithms,stock market movement prediction,global economy,local economy,Dow Jones industrial average movement,TF-IDF,GloVE approaches,recurrent neural networks,gated recurrent unit,GRU;;1;;33;;11-dec-20;;;IEEE;IEEE Conferences
Predicting the level of generalized anxiety disorder of the coronavirus pandemic among college age students using artificial intelligence technology;H. Alharthi;College of Public Health, Imam Abdulrahman Bin Faisal University (IAU),Dept. of Health Information Management & Technology,Dammam,Saudi Arabia;2020 19th International Symposium on Distributed Computing and Applications for Business Engineering and Science (DCABES);9-dec-20;2020;;;218;221;Introduction: Emerging reports indicate heightened anxiety among university students during the Corona pandemic. Implications of which can impact their academic performance. Artificial intelligence (AI) through machine learning can be used to predict which students are more susceptible to anxiety which can inform closer monitoring and early intervention. To date, there are no studies that have explored the efficacy of AI to predict anxiety among college students. Objective: to develop the best fit model to predict anxiety and to rank the most important factors affecting anxiety. Method: Data was collected using an online survey that included general information, Covid-19 stressors and (GAD-7). This scale categorizes level of anxiety to none, mild, moderate, and severe. We received 917 survey answers. Several machine learning classifiers were used to develop the best fit model to predict student level of anxiety. Results: the best performance based on AUC is AdaBoost (0.943) followed by neural network (0.936). Highest accuracy and F1 were for neural network (0.754) and (0.749) respectively, then neural network selected to be the best fit model. The three scoring methods revealed that the top three features that predicted anxiety to be gender, sufficient support from family and friends, and fixed family income. Conclusion: Neural network model can assist college counselors to predict which students are going through anxiety and revealed the top three features for heightened student anxiety to be gender, a support system, and family fixed income. This information can alter college councilors for early mental intervention.;2473-3636;978-1-7281-9724-1;10.1109/DCABES50732.2020.00064;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9277785;Machine learning,Artificial intelligence,Classifiers,anxiety,AI,ML;Machine learning,COVID-19,Artificial intelligence,Predictive models,Mental health,Pandemics,Neural networks;diseases,epidemics,learning (artificial intelligence),medical diagnostic computing,medical disorders,microorganisms,neural nets,pattern classification,psychology;college age students,artificial intelligence,university students,college students,neural network,student anxiety,generalized anxiety disorder,Coronavirus pandemic,academic performance,machine learning,Covid-19 stressors,GAD-7,classifiers,student anxiety level,AdaBoost,fixed family income,gender,college counselors,mental intervention,anxiety prediction;;2;;15;;9-dec-20;;;IEEE;IEEE Conferences
Forecasting COVID-19 cases in India Using Machine Learning Models;V. R. J, A. Jakka;CMR Institute of Technology,Dept of MCA,Bengaluru,Karnataka,India, University of Pittsburgh,MSIS,Pittsburgh,USA;2020 International Conference on Smart Technologies in Computing, Electrical and Electronics (ICSTCEE);8-dec-20;2020;;;466;471;COVID-19 pandemic has affected the economy and changed the human way of life, disrupting everyone's mental, physical, and financial well-being. Many of the fastest-growing economies are strained owing to the severity and communicability of the epidemic. Because of the increasing diversity of cases and the resulting burden on healthcare practitioners and the government, therefore, predicting the number of infected COVID-19 cases which could be useful in planning the required hospital resources in the future. In this paper, we focussed on information-led methods of estimating the numbers of COVID-19 confirmed cases in the country and their implications in the future, using different learning models such as Sigmoid modelling, ARIMA, SEIR model and LSTM, for protective measures, such as social isolation or the lockout of COVID-19. . Use of raw data by separating an event from the previous event in order to set the time series. The computation of number of positive incidents, number of re-referred incidents are reliable within a limited range. A data-driven forecasting method has been used to approximate the total confirmed cases in coming months. These LSTM model gave very promising results than other models. Hence, this work would help the decision makers to understand the upcoming of the pandemic trajectory in the country and take necessary actions for the effect of interventions.;;978-1-7281-7213-2;10.1109/ICSTCEE49637.2020.9276852;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9276852;Covid-19,Epidemiology,SEIR,LSTM,Machine Learning,ARIMA,Time series,Forecasting of cases;COVID-19,Diseases,Predictive models,Time series analysis,Analytical models,Lung,Logic gates;decision making,diseases,epidemics,forecasting theory,health care,hospitals,learning (artificial intelligence),recurrent neural nets,regression analysis;India,COVID-19 pandemic,economy,fastest-growing economies,healthcare practitioners,infected COVID-19 cases,required hospital resources,information-led methods,COVID-19 confirmed cases,Sigmoid modelling,SEIR model,data-driven forecasting method,LSTM model;;2;;15;;8-dec-20;;;IEEE;IEEE Conferences
Predicting Ventricular Fibrillation Through Deep Learning;L. -M. Tseng, V. S. Tseng;Department of Emergency Medicine, Shin-Kong WHS Memorial Hospital, Taipei, Taiwan, Department of Computer Science, National Chiao Tung University, Hsinchu, Taiwan;IEEE Access;17-dec-20;2020;8;;221886;221896;Ventricular fibrillation (VF) is a type of cardiac arrhythmia. This chaotic cardiac electrical activity results in heart quivering instead of normal pumping. To date, early cardiopulmonary resuscitation (CPR) and defibrillation are the only effective VF treatment. Acute myocardial infarction is the most common cause of VF, and cardiomyopathy, myocarditis, electrolyte imbalance, cardiotoxic medication, and even ion channel abnormality can cause VF. Physicians have attempted to identify specific patterns in electrocardiography (ECG) that might predict VF in the short term. For example, ST segment changes might imply coronary artery occlusion with myocardial ischemia, increasing VF risk. However, in most cases, VF occurs abruptly without any early warning. Machine learning is used to extract information usually neglected by the human brain. In deep learning, a cascade of multiple layers of processing is used to extract features. Machine learning is used to classify different types and outcomes of cardiac arrhythmias that are difficult to recognize directly. In this study, we developed a new deep learning method to predict the onset of VF. ECG from MIT-BIH databases were used as the training and validation data sets, the prediction results showed that the proposed two-dimensional short-time Fourier transform (2D STFT)/continuous wavelet transform (CWT) convolutional neural network (CNN) model can reach a recall of 99% and an accuracy of 97%. We also compared the proposed 2D model with 1D and 2D time-domain CNN models. The results showed that the 1D CNN and 2D time-domain models can achieve an accuracy of 60.5% and 56%, respectively.;2169-3536;;10.1109/ACCESS.2020.3042782;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284455;Cardiac arrhythmias,continuous wavelet transform (CWT),deep learning,electrocardiography,short-time Fourier transform (STFT),sudden cardiac death,ventricular fibrillation;Electrocardiography,Feature extraction,Myocardium,Databases,Defibrillation,Data mining,Support vector machines;blood vessels,cardiovascular system,convolutional neural nets,diseases,electrocardiography,Fourier transforms,learning (artificial intelligence),medical signal processing,wavelet transforms;2D time-domain models,1D CNN,two-dimensional short-time Fourier transform,continuous wavelet transform,convolutional neural network model,VF treatment,chaotic cardiac electrical activity,ventricular fibrillation,deep learning method,cardiac arrhythmia,machine learning,VF risk,defibrillation;;1;;36;CCBY;7-dec-20;;;IEEE;IEEE Journals
Variation on solar wind parameters and total electron content over middle- to low-latitude regions during intense geomagnetic storms;R. K. Mishra, B. Adhikari, N. P. Chapagain, R. Barai, P. K. Das, V. Klausner, M. Sharma;Department of Physics, St. Xavier's College, Tribhuvan University, Kathmandu, Nepal, Department of Physics, St. Xavier's College, Tribhuvan University, Kathmandu, Nepal, Department of Physics, Patan Multiple College, Tribhuvan University, Kathmandu, Nepal, Department of Physics, Amrit Science College, Tribhuvan University, Kathmandu, Nepal, Department of Physics, St. Xavier's College, Tribhuvan University, Kathmandu, Nepal, Department of Physics, St. Xavier's College, Tribhuvan University, Kathmandu, Nepal, Department of Physic and Astronomy, UNIVAP - Universidade do Vale do Paraíba, São José dos Campos, Brazil, Department of Physics, St. Xavier's College, Tribhuvan University, Kathmandu, Nepal;Radio Science;2-dec-20;2020;55;11;1;26;Streams of the particle ejected from the Sun and the extreme space weather conditions like storms, high-speed streamers (HSSs), interplanetary coronal mass ejections (ICMEs), corotating interaction regions (CIRs), and interplanetary shocks (IS) termed as geomagnetic storms have massive influence in the climate and components of the Earth's upper atmosphere such as total electron content (TEC). The study of TEC helps to understand variations in ionospheric electron density during geomagnetic storms. Global ionospheric maps of TEC are a real-time mapping of GPS observations produced by ground-based stations. In this paper, we have analyzed three intense geomagnetic storms of the year 2015: during 16–21 March 2015 (the St. Patrick's Day storm), 21–24 June 2015, and 18–22 December 2015. We present the variations of IMF-Bz, solar wind parameters (Vsw, Nsw, and Psw), and geomagnetic indices (AE and SYM-H) and the variations of vertical total electron content (VTEC) using simultaneous VTEC data from 12 GPS-TEC stations over the Indian, Australian, Brazilian, and South African regions. We describe contrast in TEC throughout the globe using global ionospheric maps at a regular 2 hr interval of UT during the three intense geomagnetic storms. Moreover, we observed that heavily TEC-influenced areas were found to be transposing through the equatorial plane starting from eastern sectors to the western sectors. The Indian Ocean, Atlantic Ocean, and South Pacific Ocean sectors were affected flowingly. Global ionospheric maps evince that Indian and Brazilian sectors were affected heavily explaining the traveling ionospheric disturbances (TID) and equatorial anomaly as seen in those areas. The equatorial and low-latitude regions have been mainly affected by geomagnetic storms. All these results suggested that the acute disruption of global winds (surging toward the equator from higher latitudes) and electric fields commenced from magnetosphere-ionosphere interaction causing the severe modification in the equatorial, low-latitude region. We also checked the cross correlation of VTEC of LCK3 station and various other stations during the period of high solar and geomagnetic activities, the correlation gradually increased with the nearby stations by latitudes in most of the cases which was another intriguing result. Thus, these results suggested that the storms were affected globally, which is why we believe that variation of TEC over various stations of the globe could turn out to be very helpful in predicting solar wind coupling with the magnetosphere-ionosphere.;1944-799X;;10.1029/2020RS007129;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9277931;;Storms,Magnetosphere,Indexes,Correlation,Ionosphere,Global Positioning System,Turning;;;;1;;;;2-dec-20;;;AGU;AGU Journals
Machine Learning Approaches for COVID-19 Forecasting;O. Istaiteh, T. Owais, N. Al-Madi, S. Abu-Soud;Princess Sumaya University for Technology,Computer Science Dept.,Amman,Jordan, Princess Sumaya University for Technology,Data Science Dept.,Amman,Jordan, Princess Sumaya University for Technology,Data Science Dept.,Amman,Jordan, Princess Sumaya University for Technology,Data Science Dept.,Amman,Jordan;2020 International Conference on Intelligent Data Science Technologies and Applications (IDSTA);30-nov-20;2020;;;50;57;COVID-19 (Coronavirus) pandemic tends to be one of the most global serious issues in the last century. Furthermore, the world did not face any similar experience regarding the spread of the virus and its economic and political impacts. Forecasting the number of COVID-19 cases in advance could help the decision-makers to take proactive measures and plans. This paper aims to provide a global forecasting tool that predicts the COVID-19 confirmed cases for the next seven days in all over the world. This paper applies four different machine learning algorithms, The autoregressive integrated moving average (ARIMA), artificial neural network(ANN), long-short term memory (LSTM), and convolutional neural network (CNN) to predict the COVID-19 cases in each country for the next seven days. The fine-tuning process of each model is described in this paper and numerical comparisons between the four models are concluded using different evaluation measures, mean absolute error (MAPE), root mean squared logarithmic error (RMSLE) and mean squared logarithmic error (MSLE).;;978-1-7281-8376-3;10.1109/IDSTA50958.2020.9264101;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9264101;COVID-19,Spatial Time-series Forecasting,Deep Learning,ARIMA,ANN,CNN,LSTM;Forecasting,COVID-19,Predictive models,Data models,Prediction algorithms,Time series analysis,Mathematical model;autoregressive moving average processes,convolutional neural nets,data handling,decision making,epidemics,learning (artificial intelligence),medical computing,microorganisms,recurrent neural nets;data preprocessing,mean squared logarithmic error,root mean squared logarithmic error,mean absolute error,long short term memory,artificial neural network,autoregressive integrated moving average,decision makers,machine learning,convolutional neural network,political impacts,economic impacts,coronavirus pandemic,COVID-19 forecasting;;2;;29;;30-nov-20;;;IEEE;IEEE Conferences
Predicting and Preventing Cyber Attacks During COVID-19 Time Using Data Analysis and Proposed Secure IoT layered Model;L. Tawalbeh, F. Muheidat, M. Tawalbeh, M. Quwaider, G. Saldamli;Texas A&M University,IEEE SM,Department of Computing and Cybersecurity,San Antonio,USA, California State University, San Bernardino,IEEE SM, School of Computer Science and Engineering,San Bernardino,USA, Jordan University of Science and Technology,Computer Engineering Department,Jordan, Jordan University of Science and Technology,Computer Engineering Department,Jordan, San Jose State University,Computer Engineering Department,San Jose,USA;2020 Fourth International Conference on Multimedia Computing, Networking and Applications (MCNA);23-nov-20;2020;;;113;118;The global spread of the COVID-19 pandemic and its unprecedented impact not only on health and economy but almost on all aspects of our lives, including how we work, meet, communicate, collaborate, etc. Unfortunately, these changes and the transition to the virtual space in such a short time without proper planning created opportunities for bad actors in cyberspace. In the last few months, we have witnessed new treads and waves of cyber-attacks targeting businesses, governments, health, and other critical services. Attackers try to take advantage of people's fear of the virus, vulnerabilities associated with data collection sensors and IoT devices, and eagerness to look for solutions or protections. In this study, we will survey the nature of cyberattacks related to the COVID-19 outbreak. Them, we will analyze related data to phishing attacks using Neural Networks. This analysis is covering different technical and socio-economical aspects. We will also evaluate states' countermeasures in response to such attacks. We propose a new IoT model. We define three layers, End User, Device or Sensors, and Cloud. We can combine the proposed model with the security and privacy policies to countermeasure the cybersecurity threats facing each layer.;;978-1-7281-8373-2;10.1109/MCNA50957.2020.9264301;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9264301;IoT model,Cloud,Security attacks,Data Analysis,ANN,COVID-19;COVID-19,Security,Organizations,Phishing,Pandemics,Computer crime,Electronic mail;computer crime,computer network security,data analysis,data privacy,Internet of Things;COVID-19 time,data analysis,global spread,COVID-19 pandemic,economy,virtual space,cyberspace,critical services,data collection sensors,IoT devices,protections,COVID-19 outbreak,phishing attacks,socio-economical aspects,IoT model,security,privacy policies,secure IoT layered model,cyber-attacks;;;;24;;23-nov-20;;;IEEE;IEEE Conferences
GPR and ANN based Prediction Models for COVID-19 Death Cases;A. Jarndal, S. Husain, O. Zaatar, T. A. Gumaei, A. Hamadeh;University of Sharjah,Electrical Engineering Department,Sharjah,UAE, University of Sharjah,Electrical Engineering Department,Sharjah,UAE, University of Sharjah,Electrical Engineering Department,Sharjah,UAE, University of Sharjah,Electrical Engineering Department,Sharjah,UAE, University of Sharjah,Electrical Engineering Department,Sharjah,UAE;2020 International Conference on Communications, Computing, Cybersecurity, and Informatics (CCCI);18-nov-20;2020;;;1;5;COVID-19 pandemic now affects the entire world and has a major effect on the global economy. A number of medical researchers are currently working in various fields to tackle this pandemic and its circumstances. This paper aims of developing a model that can estimate the number of deaths in the affected cases based on the documented number of older (above 65 years of age), diabetic and smoking cases. The Gaussian Process Regression (GPR) approach has been used to build the model and its performance was compared with a corresponding Artificial Neural Network (ANN) model. The model was applied to reliable data published by the World Health Organization (WHO) for different countries in North America, Europe and the Gulf region. The model provided impressive results with an excellent prediction of data from all the countries under investigation. The model may be useful in estimating the number of deaths due to any arbitrary number of inputs. It would also help to prepare effective measures to minimize the number of deaths.;;978-1-7281-7315-3;10.1109/CCCI49893.2020.9256564;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9256564;COVID-19,Prediction Model,Gaussian Process Regression;Predictive models,Data models,COVID-19,Biological system modeling,Europe,Training,Pandemics;diseases,epidemics,Gaussian processes,medical computing,neural nets,regression analysis;prediction models,COVID-19 death cases,COVID-19 pandemic,global economy,medical researchers,Gaussian process regression,GPR,artificial neural network,ANN,World Health Organization,pandemic,diabetic cases,smoking cases,North America,Europe,Gulf region;;4;;12;;18-nov-20;;;IEEE;IEEE Conferences
Predicting Covid-19 Trajectory Using Machine Learning;Z. A. A. Alwaeli, A. A. Ibrahim;Altinbas univeristy,Department of Computer engineering,Istanbul,Turkey, Altinbas univeristy,Department of Computer engineering,Istanbul,Turkey;2020 4th International Symposium on Multidisciplinary Studies and Innovative Technologies (ISMSIT);17-nov-20;2020;;;1;4;The pandemic caused by COVID-19 in 2020 triggered a devastating effect on the economy and health of the world population, whose social implications for the next few years are still uncertain. Two types of standard tests are used to detect COVID-19: the viral test that indicates whether the patient is infected and the antibody test that allows us to observe if the patient has previously had an infection. These tests employ techniques such as reverse transcription and polymerase chain reaction (RT-PCR), immunochromatographic lateral flow or rapid test, and ELISA-type immunoassay In this paper we have designed and implemented a system whose main purpose is to detect the rise of Covid-19 cases using disruptive technologies such as artificial intelligence and intelligent computing, manifested through machine learning (Machine Learning) and deep learning (Deep Learning). Combined with data science, Big Data and advanced data analytics, among others that present various research and development options, it can help the early detection of COVID-19 through the search for relevant characteristics that allow the scientific community identify biochemical, molecular and cellular factors that facilitate the early detection of the virus in its different states of infection, incubation, propagation and treatments to be used.;;978-1-7281-9090-7;10.1109/ISMSIT50672.2020.9255149;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9255149;component,formatting,style,styling,insert (key words);COVID-19,Pandemics,Deep learning,Predictive models,Public healthcare,Prediction algorithms,Data models;biochemistry,biosensors,cellular biophysics,data analysis,diseases,learning (artificial intelligence),microorganisms,molecular biophysics,patient diagnosis;viral test,standard tests,Covid-19 trajectory,advanced data analytics,deep learning,machine learning,ELISA-type immunoassay,rapid test,polymerase chain reaction,reverse transcription,antibody test;;3;;19;;17-nov-20;;;IEEE;IEEE Conferences
Forecasting Ionospheric Total Electron Content During Geomagnetic Storms;R. M. Akir, S. A. Bahari, M. Abdullah, M. J. Homam, K. Chellapan, R. Ngadengon;Universiti Tun Hussein Onn Malaysia,Faculty of Electrical and Electronic Engineering,Department of Electronic Engineering Wireless and Radio Science Centre,Parit Raja, Batu Pahat, Johor,Malaysia,86400, Institute of Climate Change, Universiti Kebangsaan Malaysia,Space Science Centre (ANGKASA),Bangi,Selangor,Malaysia,43600, Faculty of Engineering & Built Environment Space Science Centre (ANGKASA), Institute of Climate Change, Universiti Kebangsaan Malaysia,Department of Electrical, Electronic & Systems Engineering,Bangi,Selangor,Malaysi,43600, Universiti Tun Hussein Onn Malaysia,Faculty of Electrical and Electronic Engineering,Department of Electronic Engineering,Parit Raja, Batu Pahat, Johor,Malaysia,86400, Universiti Kebangsaan Malaysia,Faculty of Engineering & Built Environment,Department of Electrical, Electronic & Systems Engineering,Bangi,Selangor,Malaysi,43600, Universiti Tun Hussein Onn Malaysia,Faculty of Electrical and Electronic Engineering,Department of Electronic Engineering Wireless and Radio Science Centre,Parit Raja, Batu Pahat, Johor,Malaysia,86400;2020 IEEE Student Conference on Research and Development (SCOReD);12-nov-20;2020;;;1;6;A geomagnetic storm is a temporary disturbance of the Earth’s magnetosphere that caused magnetic field depression. This activity is associated with solar coronal mass ejections, coronal holes, or solar flares which allows its association with ionospheric Total Electron Content (TEC) and its physical changes. Neural Network (NN) is a modeling technique capable in exhibiting nonlinear properties that comprises physical quantities. This study focuses on establishing an ionospheric TEC prediction model during a geomagnetic storm using feed-forward back propagation neural networks. Geomagnetic events on 18 March and 23 June 2015 with (Kp index of 8 and DST index \lt-200nT) over Universiti Kebangsaan Malaysia were selected as the case study. Factors influencing TEC were defined and used as input parameters. TEC was modelled as a function of seasonal variation, diurnal variation and solar activity to establish a valid correlation with magnetic field depression. Model output was analyzed by comparing the predicted TEC with measured GPS-TEC and IRIOI-corr TEC model output to verify the accuracy of TEC modeling using RMSE and MAPE values. The RMSE of the NN prediction model against the measured TEC between 2 – 12 TECU in comparison with the IRIOI-corr TEC model between 7-25 TECU. Whereas the MAPE represents 10% – 54% for NN prediction against 23% - 57% for IRIOI-corr TEC model. Hence, NN method showed a higher performance and better estimates of the TEC compared to the IRIOI-corr. This study concludes that both NN and IROI-corr models are unable to predict accurate ionospheric TEC during major geomagnetic storms. However, the prediction accuracy improved in the recovery phase (post-storm).;2643-2447;978-1-7281-9317-5;10.1109/SCOReD50371.2020.9250978;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9250978;geomagnetic storm,ionospheric TEC,neural network,forecasting;Analytical models,Storms,Artificial neural networks,Predictive models,Data models,Magnetic fields,Forecasting;electron density,geophysics computing,Global Positioning System,ionosphere,ionospheric disturbances,ionospheric electromagnetic wave propagation,ionospheric techniques,magnetic storms,magnetosphere,neural nets,radiowave propagation,solar activity,solar flares,total electron content (atmosphere);IRIOI-corr TEC model output,measured GPS-TEC,predicted TEC,solar activity,factors influencing TEC,8 DST index \lt-200nT,geomagnetic events,propagation neural networks,ionospheric TEC prediction model,Neural Network,solar flares,coronal holes,solar coronal mass ejections,magnetic field depression,ionospheric Total Electron Content,geomagnetic storm,accurate ionospheric TEC,IROI-corr models,measured TEC,NN prediction model,TEC modeling;;1;;21;;12-nov-20;;;IEEE;IEEE Conferences
Social Distancing Detection with Deep Learning Model;Y. C. Hou, M. Z. Baharuddin, S. Yussof, S. Dzulkifly;Institute of Informatics and Computing in Energy, College of Engineering, Universiti Tenaga Nasional,Kajang,Selangor,Malaysia, Institute of Informatics and Computing in Energy, Institute of Informatics and Computing in Energy;2020 8th International Conference on Information Technology and Multimedia (ICIMU);11-nov-20;2020;;;334;338;The paper presents a methodology for social distancing detection using deep learning to evaluate the distance between people to mitigate the impact of this coronavirus pandemic. The detection tool was developed to alert people to maintain a safe distance with each other by evaluating a video feed. The video frame from the camera was used as input, and the open-source object detection pre-trained model based on the YOLOv3 algorithm was employed for pedestrian detection. Later, the video frame was transformed into top-down view for distance measurement from the 2D plane. The distance between people can be estimated and any noncompliant pair of people in the display will be indicated with a red frame and red line. The proposed method was validated on a pre-recorded video of pedestrians walking on the street. The result shows that the proposed method is able to determine the social distancing measures between multiple people in the video. The developed technique can be further developed as a detection tool in realtime application.;;978-1-7281-7310-8;10.1109/ICIMU49871.2020.9243478;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9243478;social distancing,pedestrian detection,deep learning,convolutional neural network;Deep learning,Pandemics,Two dimensional displays,Human factors,Tools,Streaming media,Social factors;behavioural sciences computing,distance measurement,learning (artificial intelligence),object detection,pedestrians,video signal processing;deep learning model,social distancing detection,coronavirus pandemic,detection tool,safe distance,video feed,video frame,open-source object detection pre-trained model,YOLOv3 algorithm,pedestrian detection,distance measurement,red frame,pre-recorded video,social distancing measures;;14;;13;;11-nov-20;;;IEEE;IEEE Conferences
Artificial Intelligence Cyber Security Strategy;X. Feng, Y. Feng, E. S. Dawam;University of Bedfordshire,School of Computer Science & Tech.,Luton,UK, Hebei Normal University,Shijiazhuang,P.R. China, University of Bedfordshire,School of CST,Luton Bedfordshire,UK;2020 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech);11-nov-20;2020;;;328;333;Nowadays, STEM (science, technology, engineering and mathematics) have never been treated so seriously before. Artificial Intelligence (AI) has played an important role currently in STEM. Under the 2020 COVID-19 pandemic crisis, coronavirus disease across over the world we are living in. Every government seek advices from scientist before making their strategic plan. Most of countries collect data from hospitals (and care home and so on in the society), carried out data analysis, using formula to make some AI models, to predict the potential development patterns, in order to make their government strategy. AI security become essential. If a security attack make the pattern wrong, the model is not a true prediction, that could result in thousands life loss. The potential consequence of this non-accurate forecast would be even worse. Therefore, take security into account during the forecast AI modelling, step-by-step data governance, will be significant. Cyber security should be applied during this kind of prediction process using AI deep learning technology and so on. Some in-depth discussion will follow.AI security impact is a principle concern in the world. It is also significant for both nature science and social science researchers to consider in the future. In particular, because many services are running on online devices, security defenses are essential. The results should have properly data governance with security. AI security strategy should be up to the top priority to influence governments and their citizens in the world. AI security will help governments' strategy makers to work reasonably balancing between technologies, socially and politics. In this paper, strategy related challenges of AI and Security will be discussed, along with suggestions AI cyber security and politics trade-off consideration from an initial planning stage to its near future further development.;;978-1-7281-6609-4;10.1109/DASC-PICom-CBDCom-CyberSciTech49142.2020.00064;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9251111;Artificial Intelligence (AI),Cyber Security,Data Governance,Strategy,General Data Protection Regulation (GDPR),Personal Identifiable Information (PII),Privacy,Trade-off,Deep Learning;COVID-19,Law,Government,Predictive models,Security,Artificial intelligence,Computer crime;data analysis,diseases,government data processing,Internet,learning (artificial intelligence),politics,project management,security of data,strategic planning;artificial intelligence cyber security strategy,STEM,mathematics,2020 COVID-19,data analysis,AI models,potential development patterns,government strategy,security attack,potential consequence,nonaccurate forecast,forecast AI modelling,step-by-step data governance,prediction process,AI deep learning technology,AI security impact,nature science,social science researchers,security defenses,properly data governance,AI security strategy,influence governments,strategy related challenges,suggestions AI cyber security;;2;;37;;11-nov-20;;;IEEE;IEEE Conferences
COVID-19 Time Series Forecasting of Daily Cases, Deaths Caused and Recovered Cases using Long Short Term Memory Networks;S. Bodapati, H. Bandarupally, M. Trupthi;JP Morgan Chase & Co.,Hyderabad,India, Chaitanya Bharathi Institue of Technology Hyderabad,Computer Science and Engineering,India, Chaitanya Bharathi Institue of Technology,Information Technology,Hyderabad,India;2020 IEEE 5th International Conference on Computing Communication and Automation (ICCCA);10-nov-20;2020;;;525;530;Novel Coronavirus (COVID-19) outbreak that emerged originally in Wuhan, the Hubei province of China has put the entire human race at risk. This virus was declared as Pandemic on 11<sup>th</sup> March 2020. Considering the massive growth rate in the number of cases and highly contagious nature of the virus, machine learning prediction models and algorithms are essential to predict the number of cases in the coming days. This could help in reducing the stress on health care systems and administrations by helping them plan better. In this paper the datasets used are obtained from the John Hopkins University's publicly available datasets to develop a state-of-the-art forecasting model of COVID-19 outbreak. We have incorporated data-driven estimations and time series analysis to predict the trends in coming days such as the number of cases confirmed positive, number of deaths caused by the virus and number of people recovered from the novel coronavirus. To achieve the estimations, we have used the Deep learning model long-shortterm memory network (LSTM).;2642-7354;978-1-7281-6324-6;10.1109/ICCCA49541.2020.9250863;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9250863;Deep learning,Artificial Neural Networks,Long-Short-Term Memory (LSTMs),Pandemic,COVID-19,Corona-virus;COVID-19,Time series analysis,Estimation,Predictive models,Market research,Viruses (medical),Long short term memory;diseases,health care,learning (artificial intelligence),microorganisms,recurrent neural nets,time series;machine learning prediction models,COVID-19 outbreak,time series analysis,coronavirus,COVID-19 time series forecasting,human race,deep learning model long-short term memory network,LSTM,health care,Wuhan,China;;5;;20;;10-nov-20;;;IEEE;IEEE Conferences
Analyzing the Effects of COVID-19 Pandemic on the Energy Demand: the Case of Northern Italy;P. Scarabaggio, M. La Scala, R. Carli, M. Dotoli;Polytechnic of Bari,Dept. of Electrical and Information Engineering,Bari,Italy, Polytechnic of Bari,Dept. of Electrical and Information Engineering,Bari,Italy, Polytechnic of Bari,Dept. of Electrical and Information Engineering,Bari,Italy, Polytechnic of Bari,Dept. of Electrical and Information Engineering,Bari,Italy;2020 AEIT International Annual Conference (AEIT);2-nov-20;2020;;;1;6;The COVID-19 crisis is profoundly influencing the global economic framework due to restrictive measures adopted by governments worldwide. Finding real-time data to correctly quantify this impact is very significant but not as straightforward. Nevertheless, an analysis of the power demand profiles provides insight into the overall economic trends. To accurately assess the change in energy consumption patterns, in this work we employ a multi-layer feed-forward neural network that calculates an estimation of the aggregated power demand in the north of Italy, (i.e, in one of the European areas that were most affected by the pandemics) in the absence of the COVID-19 emergency. After assessing the forecasting model reliability, we compare the estimation with the ground truth data to quantify the variation in power consumption. Moreover, we correlate this variation with the change in mobility behaviors during the lockdown period by employing the Google mobility report data. From this unexpected and unprecedented situation, we obtain some intuition regarding the power system macro-structure and its relation with the overall people's mobility.;;978-8-8872-3747-4;10.23919/AEIT50178.2020.9241136;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9241136;COVID-19,Lockdown,Power systems,Machine learning,Neural networks;COVID-19,Economics,Energy consumption,Power demand,Pandemics,Estimation,Resilience;feedforward neural nets,load forecasting,mobile computing,power consumption,power engineering computing;energy demand,northern Italy,COVID-19 crisis,global economic framework,restrictive measures,governments,real-time data,power demand profiles,economic trends,energy consumption patterns,multilayer feed-forward neural network,aggregated power demand,European areas,pandemics,COVID-19 emergency,forecasting model reliability,ground truth data,power consumption,Google mobility report data,power system macro-structure,COVID-19 pandemic;;4;;22;;2-nov-20;;;IEEE;IEEE Conferences
Lifetime Prediction of Ultraviolet Light-Emitting Diodes Using a Long Short-Term Memory Recurrent Neural Network;Z. Jing, J. Liu, M. S. Ibrahim, J. Fan, X. Fan, G. Zhang;College of Mechanical and Electrical Engineering, Hohai University, Changzhou, China, School of Information Science and Technology, Fudan University, Shanghai, China, Department of Industrial and System Engineering, The Hong Kong Polytechnic University, Hong Kong, Institute of Future Lighting, Academy for Engineering and Technology, Shanghai, China, Department of Mechanical Engineering, Lamar University, Beaumont, TX, USA, Department of Microelectronics Engineering, Delft University of Technology, Delft, The Netherlands;IEEE Electron Device Letters;24-nov-20;2020;41;12;1817;1820;Ultraviolet light-emitting diodes (UV LEDs) play an important role in inactivating novel coronavirus pneumonia, but the lack of rapid lifetime prediction can easily cause untimely failure detection, long product development cycles, and high costs. This study predicts the lifetime of UV LEDs based on the long short-term memory (LSTM) recurrent neural network (RNN). First, the equipment setup was designed to conduct an aging test to obtain a predicted length of life for the UV LED samples using a Weibull distribution. Next, LSTM RNN was employed to predict the lifetime of the UV LEDs based on the radiation power degradation. The results were then compared with those from nonlinear least squares (NLS) regression recommended by the IESNA TM-21 industry standard. Finally, the robustness of the two methods was analyzed by changing the starting times of the predictions. The results showed that the LSTM RNN proposed in this letter reveals not only a 29.7% lower lifetime prediction error compared with the NLS regression, but also a more stable robustness. Thus, the LSTM RNN method is found to be more accurate and more robust in predicting the lifetime of UV LEDs.;1558-0563;;10.1109/LED.2020.3034567;National Natural Science Foundation of China(grant numbers:51805147), Six Talent Peaks Project in Jiangsu Province(grant numbers:GDZB-017), Fundamental Research Funds for the Central Universities(grant numbers:B200203031), Shanghai Science and Technology Development Funds(grant numbers:19DZ2253400), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9244084;Ultraviolet LED,long short-term memory,recurrent neural network,IESNA TM-21 recommendation,lifetime prediction;Light emitting diodes,Long short term memory,Maintenance engineering,Degradation,Recurrent neural networks;least squares approximations,life testing,light emitting diodes,optical engineering computing,recurrent neural nets,regression analysis,Weibull distribution;ultraviolet light-emitting diodes,long short-term memory recurrent neural network,rapid lifetime prediction,long product development cycles,UV LED samples,LSTM RNN method,lifetime prediction error,aging test,Weibull distribution,radiation power degradation,nonlinear least squares regression,IESNA TM-21 industry standard;;7;;18;IEEE;29 Oct 2020;;;IEEE;IEEE Journals
Spread & Peak Prediction of Covid-19 using ANN and Regression (Workshop Paper);A. Prakash, P. Sharma, I. K. Sinha, U. P. Singh;Indian Institute of Information Technology Allahabad,Machine Learning and Optimization Lab,Prayagraj, Indian Institute of Information Technology Allahabad,Machine Learning and Optimization Lab,Prayagraj, Indian Institute of Information Technology Allahabad,Machine Learning and Optimization Lab,Prayagraj, Indian Institute of Information Technology Allahabad,Machine Learning and Optimization Lab,Prayagraj;2020 IEEE Sixth International Conference on Multimedia Big Data (BigMM);20 Oct 2020;2020;;;356;365;Covid-19, caused by Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) virus, has presented tough times for countries all over the world with number of cases and casualties running in millions. While virologists and doctors have spent sleepless nights to come up with a potent vaccine, the work life of government personnel including administrative staffs, hospital employees etc. has not been any easier. Amidst this turmoil, the common question crossing every mind is concerned with the statistics about this infection including expected number of infections, peak prediction etc. We try to answer these questions by analyzing the time series data of Covid-19 infections for certain hard-hit countries and states in India. A series of machine and deep learning models have been built to capture the infection distribution so that these models could predict the fate of this infection in the near future. We also make an attempt to predict the time when active cases would cease to increase.;;978-1-7281-9325-0;10.1109/BigMM50055.2020.00062;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9232477;Severe Acute-Respiratory Syndrome (SARS),Exploratory analysis,Growth rate,Active cases,Regression;Predictive models,Data models,COVID-19,Analytical models,Linear regression,Time series analysis,Testing;diseases,hospitals,learning (artificial intelligence),medical computing,microorganisms,neural nets,personnel,time series;spread & peak prediction,severe acute respiratory syndrome Coronavirus 2 virus,SARS-CoV-2,virologists,doctors,government personnel,administrative staffs,hospital employees,time series data,Covid-19 infections,hard-hit countries,infection distribution,regression,ANN,deep learning,machine learning;;5;;25;;20 Oct 2020;;;IEEE;IEEE Conferences
DP-ANN: A new Differential Private Artificial Neural Network with Application on Health data (Workshop Paper);I. K. Sinha, K. P. Singh, S. Verma;IIIT Allahabad,MLO Lab,Prayagraj,India, IIIT Allahabad,MLO Lab,Prayagraj,India, IIIT Allahabad,MLO Lab,Prayagraj,India;2020 IEEE Sixth International Conference on Multimedia Big Data (BigMM);20 Oct 2020;2020;;;351;355;Privacy of the individual data, especially in the Health data, is very sensitive and important. Privacy preserving Machine learning is emerging as one of the solutions for the security of data with the utility to create knowledge. In this paper, we have proposed a differential private artificial neural network (DP-ANN) and shows its application to predict the spread and the peak number of COVID-19 cases. We proposed a differential private artificial neural network (DP-ANN) in which Laplacian noise has been introduced at activation function level and it has been compared with existing privacy ideas at error function and weights level of ANN. Results show that DP-ANN model with the private activation function produces the result similar to the base ANN model.;;978-1-7281-9325-0;10.1109/BigMM50055.2020.00061;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9232500;Differential privacy,randomized activation function,ANN,machine learning;Predictive models,Data models,COVID-19,Privacy,Differential privacy,Analytical models,Neural networks;data privacy,health care,learning (artificial intelligence),medical information systems,neural nets,security of data,transfer functions;security of data,differential private artificial neural network,DP-ANN model,private activation function,health data,privacy preserving machine learning,COVID-19 cases,Laplacian noise;;1;;24;;20 Oct 2020;;;IEEE;IEEE Conferences
Design of well-matched Microwave Slot Antenna on a Flat Metal Grounded Plate using Neural Model;Z. Stanković, N. Dončov, B. Stošić, M. Sarevska, I. Milovanović;University of Niš,Faculty of Electronic Engineering,Niš,Serbia,18000, University of Niš,Faculty of Electronic Engineering,Niš,Serbia,18000, University of Niš,Faculty of Electronic Engineering,Niš,Serbia,18000, AUE-FON University Skopje,North Macedonia, Singidunum University,Educational Center Niš,Belgrade,Serbia,11000;2020 55th International Scientific Conference on Information, Communication and Energy Systems and Technologies (ICEST);20 Oct 2020;2020;;;211;215;A neural model of microwave slot antenna on a flat metal grounded plate based on MultiLayer Perceptron network (MLP) is described here. The presented model is a part of the software package called PMWA ANN Design which is developed for design of a well-matched planar microwave antenna. This software allows for fast estimation of the flat metal grounded plate and slot dimensions for desired central frequency of the microwave slot antenna to make the antenna well-matched to the feed line. The current version of this software allows for design of antenna matched to 50 Ω feed line in S and C frequency bands.;;978-1-7281-7143-2;10.1109/ICEST49890.2020.9232898;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9232898;Slot antenna,Neural networks,Neural model,Antenna optimization;Microwave antennas,Microwave integrated circuits,Slot antennas,Software packages,Metals,Microwave communication,Antenna feeds;antenna feeds,antenna radiation patterns,microwave antennas,multilayer perceptrons,neural nets,planar antennas,slot antennas,telecommunication computing;software package,planar microwave antenna,flat metal grounded plate,slot dimensions,neural model,multilayer perceptron network,microwave slot antenna,PMWA ANN design,central frequency,feed line,S frequency band,C frequency band,resistance 50 ohm;;;;18;;20 Oct 2020;;;IEEE;IEEE Conferences
Simulation Environment for Optimal Resource Planning During COVID-19 Crisis;N. Petrović;University of Niš,Faculty of Electronic Engineering,Niš,Serbia,18000;2020 55th International Scientific Conference on Information, Communication and Energy Systems and Technologies (ICEST);20 Oct 2020;2020;;;23;26;Recent COVID-19 outbreak has affected both human resources and economy around the world dramatically leading towards pandemic and serious global crisis. In this paper, a simulation environment leveraging the synergy of deep learning-based predictions and linear optimization for efficient resource planning is presented. The proposed solution shows satisfiable prediction performance and enables efficient resource exchange by reducing the trading costs.;;978-1-7281-7143-2;10.1109/ICEST49890.2020.9232908;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9232908;Deep Learning,Coronavirus,COVID-19,Linear optimization,Simulation;Urban areas,COVID-19,Unified modeling language,Optimization,Pandemics,Predictive models,Data models;learning (artificial intelligence),medical information systems,optimisation,public administration,resource allocation;linear optimization,deep learning-based predictions,serious global crisis,pandemic,economy,human resources,recent COVID-19 outbreak,COVID-19 crisis,optimal resource planning,simulation environment,efficient resource exchange,satisfiable prediction performance,efficient resource planning;;4;;18;;20 Oct 2020;;;IEEE;IEEE Conferences
COVID-19 Time Series Forecast Using Transmission Rate and Meteorological Parameters as Features;M. Mousavi, R. Salgotra, D. Holloway, A. H. Gandomi;University of Tasmania, Australia, Thapar Institute of Engineering & Technology, India, University of Tasmania, Australia, University of Technology Sydney, Australia;IEEE Computational Intelligence Magazine;15 Oct 2020;2020;15;4;34;50;The number of confirmed cases of COVID-19 has been ever increasing worldwide since its outbreak in Wuhan, China. As such, many researchers have sought to predict the dynamics of the virus spread in different parts of the globe. In this paper, a novel systematic platform for prediction of the future number of confirmed cases of COVID-19 is proposed, based on several factors such as transmission rate, temperature, and humidity. The proposed strategy derives systematically a set of appropriate features for training Recurrent Neural Networks (RNN). To that end, the number of confirmed cases (CC) of COVID-19 in three states of India (Maharashtra, Tamil Nadu and Gujarat) is taken as a case study. It has been noted that stationary and nonstationary parts of the features improved the prediction of the stationary and non-stationary trends of the number of confirmed cases, respectively. The new platform has general application and can be used for pandemic time series forecasting.;1556-6048;;10.1109/MCI.2020.3019895;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9225213;;COVID-19,Time series analysis,Recurrent neural networks,Temperature measurement,Systematics,Globalization,India,China,Pandemics,Predictive models;forecasting theory,medical computing,recurrent neural nets,time series;transmission rate,meteorological parameters,recurrent neural networks,pandemic time series forecasting,COVID-19 time series forecasting,RNN;;8;;33;IEEE;15 Oct 2020;;;IEEE;IEEE Magazines
A Comprehensive Predictive Evaluation Model Based on T-S Fuzzy Neural Network and Regression Fitting Cross Analysis;Y. Wu, J. Zhang, J. Zuo, Y. Tan, Z. Han, Z. Zhao;Shenyang Aerospace University, Shenyang Aerospace University, Shenyang Aerospace University, Shenyang Aerospace University, Shenyang Aerospace University, Shenyang Aerospace University;2020 International Workshop on Electronic Communication and Artificial Intelligence (IWECAI);13 Oct 2020;2020;;;188;192;With the outbreak of COVID-19 at the end of 2019, under the requirement of in-depth study and implementation of the overall national security concept, people's health level has become the focus of people's attention, and it is also the most basic and fundamental important indicator to reflect people's livelihood. Taking Shenzhen, a city with strong comprehensive economic level, as an example, this paper uses data processing to select six major influencing factors, such as medical treatment and environment, and uses the method of regression and fitting crossover analysis to establish the fitting curve between factors and people's health level for prediction, and obtains the regression equation. On this basis, T-S Fuzzy Neural Network (T-S FNN) is used to divide the evaluation grade of regression model, make an effective evaluation of multiple factors of people's physical health level, establish a comprehensive prediction evaluation model, and obtain the gradient grade of factors affecting people's physical health correlation and their own direct factors.;;978-1-7281-8149-3;10.1109/IWECAI50956.2020.00045;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9221656;Fuzzy neural network,predictive evaluation model,health level,regression analysis,difference fitting,Analytical models,Correlation,Fitting,Predictive models,Fuzzy neural networks,Market research,Mathematical models,diseases,fuzzy neural nets,fuzzy set theory,medical information systems,regression analysis,fitting curve,regression equation,T-S fuzzy neural network,evaluation grade,regression model,effective evaluation,physical health level,comprehensive prediction evaluation model,physical health correlation,comprehensive predictive evaluation model,regression fitting cross analysis,COVID-19,national security concept,basic indicator,fundamental important indicator,strong comprehensive economic level,medical treatment,fitting crossover analysis,T-S FNN;;;;;9;;13 Oct 2020;;;IEEE;IEEE Conferences;;
LSTM perfomance analysis for predictive models based on Covid-19 dataset;I. Cruz-Mendoza, J. Quevedo-Pulido, L. Adanaque-Infante;Universidad Nacional Mayor de San Marcos UNMSM,Lima,Perú, Universidad Nacional Mayor de San Marcos UNMSM,Lima,Perú, Universidad Nacional Mayor de San Marcos UNMSM,Lima,Perú;2020 IEEE XXVII International Conference on Electronics, Electrical Engineering and Computing (INTERCON);12 Oct 2020;2020;;;1;4;Within the large amount of data that can be processed with Neural Networks (NN), COVID-19 is leaving us a lot of information that is susceptible to be treated and set trends regarding the development of the disease in the country. The present work shows the implementation and the optimization of a Long Short-Term Memory (LSTM) Neural Network in two different simulation environments, with a dataset related to the number of infected people by COVID-19 in Peru, in order to optimize the prediction level on the number of infected people on following days.;;978-1-7281-9377-9;10.1109/INTERCON50315.2020.9220248;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9220248;Optimization,Neural Networks,LSTM,Performance,MATLAB,Colab;;computer simulation,diseases,medical information systems,recurrent neural nets;prediction level,infected people,LSTM perfomance analysis,predictive models,Covid-19 dataset,NN,long short-term memory neural network,simulation environments,Peru;;3;;10;;12 Oct 2020;;;IEEE;IEEE Conferences
Safety-Critical Control of Active Interventions for COVID-19 Mitigation;A. D. Ames, T. G. Molnár, A. W. Singletary, G. Orosz;Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, USA, Department of Mechanical Engineering, University of Michigan, Ann Arbor, MI, USA, Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, USA, Department of Mechanical Engineering, University of Michigan, Ann Arbor, MI, USA;IEEE Access;23 Oct 2020;2020;8;;188454;188474;The world has recently undergone the most ambitious mitigation effort in a century, consisting of wide-spread quarantines aimed at preventing the spread of COVID-19. The use of influential epidemiological models of COVID-19 helped to encourage decision makers to take drastic non-pharmaceutical interventions. Yet, inherent in these models are often assumptions that the active interventions are static, e.g., that social distancing is enforced until infections are minimized, which can lead to inaccurate predictions that are ever evolving as new data is assimilated. We present a methodology to dynamically guide the active intervention by shifting the focus from viewing epidemiological models as systems that evolve in autonomous fashion to control systems with an “input” that can be varied in time in order to change the evolution of the system. We show that a safety-critical control approach to COVID-19 mitigation gives active intervention policies that formally guarantee the safe evolution of compartmental epidemiological models. This perspective is applied to current US data on cases while taking into account reduction of mobility, and we find that it accurately describes the current trends when time delays associated with incubation and testing are incorporated. Optimal active intervention policies are synthesized to determine future mitigations necessary to bound infections, hospitalizations, and death, both at national and state levels. We therefore provide means in which to model and modulate active interventions with a view toward the phased reopenings that are currently beginning across the US and the world in a decentralized fashion. This framework can be converted into public policies, accounting for the fractured landscape of COVID-19 mitigation in a safety-critical fashion.;2169-3536;;10.1109/ACCESS.2020.3029558;National Science Foundation, Cyber-Physical Systems (CPS)(grant numbers:1932091), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9217519;Safety-critical control,epidemiology,non-pharmaceutical intervention,COVID-19;Sociology,Statistics,Control systems,Safety,Data models,Delay effects,Mathematical model;decision making,diseases,epidemics;social distancing,public policies,decision makers,US data,safety-critical control approach,nonpharmaceutical interventions,influential epidemiological models,wide-spread quarantines,optimal active intervention policies,COVID-19 mitigation;;7;;74;CCBY;8 Oct 2020;;;IEEE;IEEE Journals
Implementation of an Informative Website – Covid19 Predictor, Highlighting COVID-19 Pandemic Situation in India;S. Roy, M. N. Pal, S. Bhattacharyya, S. Lahiri;MCKV Institute of Engineering,Computer Science and Engineering Department,Howrah,India, MCKV Institute of Engineering,Computer Science and Engineering Department,Howrah,India, JIS College of Engineering,Computer Science and Engineering Department,Nadia,India, JIS College of Engineering,Computer Science and Engineering Department,Nadia,India;2020 IEEE International IOT, Electronics and Mechatronics Conference (IEMTRONICS);8 Oct 2020;2020;;;1;6;In this paper, we have represented implementation of an informative online platform-Covid-19 Predictor which is capable of disseminating accurate prediction of confirmed, deceased and affected Covid-19 cases in India on the basis of the data available in a reliable online repository. The work characterizes proper utilization of advanced technologies for web scrapping, model prediction, implementation of web application framework and cloud hosting.;;978-1-7281-9615-2;10.1109/IEMTRONICS51293.2020.9216352;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9216352;covid-19,Web Scrapping,Deep Neural Network,Web Application Framework,Cloud Hosting;Predictive models,Time series analysis,Data models,Databases,Mathematical model,Computer science,Neural networks;cloud computing,diseases,epidemics,information dissemination,Internet,medical information systems;COVID-19 pandemic situation,India,confirmed Covid-19 cases,informative Website,informative online platform,Web scrapping,model prediction,Covid19 predictor,cloud hosting,Web application,information dissemination;;1;;10;;8 Oct 2020;;;IEEE;IEEE Conferences
The impact of Artificial Intelligence, Blockchain, Big Data and evolving technologies in Coronavirus Disease - 2019 (COVID-19) curtailment;S. Ahir, D. Telavane, R. Thomas;Vivekanand Education Society’s Institute of Technology,Mumbai,India, EbixCash Financial Technologies,Mumbai,India, Vivekanand Education Society’s Institute of Technology,Mumbai,India;2020 International Conference on Smart Electronics and Communication (ICOSEC);7 Oct 2020;2020;;;113;120;The pandemic of Coronavirus Disease 2019 (COVID-19) is proliferating across the globe obnoxiously and it is the most heard buzzword in recent times. Every person ranging from older people, persons with disabilities, youth, indigenous people have become a part of this chain and are most likely to suffer in the upcoming chronology. Social distancing is likely to become a new norm where “Work from Home”, Online Lectures” and “Meetings” ensue on social media applications. Technology has always lent a helping hand for mankind's problems. The idea focuses on highlighting the advancements in technology in the midst of a bizarre situation. Deep Learning applications to detect the symptoms of COVID-19, AI based robots to maintain social distancing, Blockchain technology to maintain patient records, Mathematical modeling to predict and assess the situation and Big Data to trace the spread of the virus and other technologies. These technologies have immensely contributed to curtailing this pandemic. Strong will power, patience and optimistic guidelines catered by the respective government are some of the altercations to COVID-19.;;978-1-7281-5461-9;10.1109/ICOSEC49089.2020.9215294;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9215294;COVID-19,coronavirus,Society,Social Distancing,Technology,Guidelines,Precautions,Diseases,Machine Learning,Deep Learning,Blockchain,Artificial Intelligence,Robotics,Big Data;Diseases,Hospitals,Machine learning,Lung,Viruses (medical),Vaccines;Big Data,cryptography,diseases,distributed databases,learning (artificial intelligence),medical information systems,neural nets,social networking (online);social media applications,AI based robots,social distancing,Big Data,pandemic,artificial intelligence,Coronavirus Disease 2019,online lectures,blockchain technology,COVID-19,deep learning;;6;;16;;7 Oct 2020;;;IEEE;IEEE Conferences
Phishing Attacks Detection using Deep Learning Approach;I. Saha, D. Sarma, R. J. Chakma, M. N. Alam, A. Sultana, S. Hossain;University of Science and Technology Chittagong,Department of Computer Science and Engineering,Chittagong,Bangladesh, Rangamati Science and Technology University,Department of Computer Science and Engineering,Rangamati,Bangladesh, Rangamati Science and Technology University,Department of Computer Science and Engineering,Rangamati,Bangladesh, Royal University of Dhaka,Department of Computer Science and Engineering,Dhaka,Bangladesh, East Delta University,Department of Computer Science and Engineering,Chittagong,Bangladesh, East Delta University,Department of Computer Science and Engineering,Chittagong,Bangladesh;2020 Third International Conference on Smart Systems and Inventive Technology (ICSSIT);6 Oct 2020;2020;;;1180;1185;In the COVID-19 pandemic, people are enforced to adopt `work from home' policy. The Internet has become an effective channel for social interactions nowadays. Peoples' immense dependence on digital platform opens doors for fraud. Phishing is a type of cybercrime to steal users' credentials from online platforms such as online banking, online business, e-commerce, online classroom, digital marketplaces, etc. Phishers develop fake webpages alike the original one and send spam emails to hook the users. Phishers seize users' credentials when an online user visits the counterfeit webpages through the spams. Researchers have introduced enormous tools like blacklist, white-list, and antivirus software to detect phishing webpages. Attackers always devise creative ways to exploit human and network weakness to penetrate cyber defense. This paper presents a data-driven framework for detecting phishing webpages using deep learning approach. More precisely, a multilayer perceptron, which is also referred as a feed-forward neural network is used to predict the phishing webpages. The dataset was collected from Kaggle and contains information of ten thousand webpages. It consists of ten attributes. The proposed model has achieved 95% training accuracy and 93% test accuracy.;;978-1-7281-5821-1;10.1109/ICSSIT48917.2020.9214132;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9214132;Phishing attack,phishing attack detection,artificial intelligence,machine learning,deep learning,convolutional neural network;Phishing,Machine learning,Training,Electronic mail,Neural networks,Computer science,Feature extraction;computer crime,electronic commerce,fraud,Internet,learning (artificial intelligence),multilayer perceptrons,unsolicited e-mail,Web sites;phishing webpages,counterfeit webpages,online user,spam emails,fake webpages,phishers,digital marketplaces,online classroom,online business,online banking,online platforms,digital platform,social interactions,effective channel,home policy,COVID-19 pandemic,deep learning approach,phishing attacks detection;;8;;56;;6 Oct 2020;;;IEEE;IEEE Conferences
Research on the prediction algorithm about the number of workers returning to work based on the COVID-19;B. Gao, Z. Zhai, L. Wang, Z. Pan, S. Xu, D. Liu, Y. Hu, J. Wang;Electronic Technology Group Corporation,The thirty-sixth Research Institute of China,Jiaxing,China, Electronic Technology Group Corporation,The thirty-sixth Research Institute of China,Jiaxing,China, Electronic Technology Group Corporation,The thirty-sixth Research Institute of China,Jiaxing,China, Electronic Technology Group Corporation,The thirty-sixth Research Institute of China,Jiaxing,China, Electronic Technology Group Corporation,The thirty-sixth Research Institute of China,Jiaxing,China, Electronic Technology Group Corporation,The thirty-sixth Research Institute of China,Jiaxing,China, Electronic Technology Group Corporation,The thirty-sixth Research Institute of China,Jiaxing,China, Electronic Technology Group Corporation,The thirty-sixth Research Institute of China,Jiaxing,China;2020 IEEE International Conference on Advances in Electrical Engineering and Computer Applications( AEECA);6 Oct 2020;2020;;;127;131;In order to make rational use of the resources about epidemic prevention such as masks, and prevent the leaders of enterprises from falsely reporting the number of workers back to work, the evaluation of the number of workers back to work in enterprises is transformed into the prediction of the number of workers back to work under different distribution about the number of workers back to work. Based on the analysis of the existing historical data, this paper predicts the number of people who return to work through intelligent algorithm, so that the government can prepare and distribute epidemic prevention materials. Based on the analysis of the daily power consumption data of the enterprise, combined with the existing number of enterprises returning to work, this paper constructs a prediction model of the number of enterprises returning to work based on the power consumption, and completes the prediction of the number of enterprises returning to work in the future. The experimental results based on the simulation data of the number of enterprises returning to work with different distributions show that the intelligent algorithm can effectively predict the number of enterprises returning to work under the background of COVID-19.;;978-1-7281-6521-9;10.1109/AEECA49918.2020.9213667;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9213667;COVID-19,multiple linear regression,support vector machine,multilayer perceptron;Predictive models,Data models,Prediction algorithms,Support vector machines,Power demand,Analytical models,Distribution functions;data analysis,epidemics,government data processing,health care;enterprise,prediction algorithm,COVID-19,historical data analysis,epidemic prevention materials,intelligent algorithm;;1;;16;;6 Oct 2020;;;IEEE;IEEE Conferences
SARS-CoV-2 Detection From Voice;G. Pinkas, Y. Karny, A. Malachi, G. Barkai, G. Bachar, V. Aharonson;Afeka Center of Language Processing, Afeka, Tel Aviv Academic College of Engineering, Tel Aviv-Yafo, Israel, Afeka Center of Language Processing, Afeka, Tel Aviv Academic College of Engineering, Tel Aviv-Yafo, Israel, Afeka Center of Language Processing, Afeka, Tel Aviv Academic College of Engineering, Tel Aviv-Yafo, Israel, Pediatric Infectious Diseases Unit, Safra Children's Hospital, Sheba Medical Center and Sackler School of Medicine, Tel-Aviv University, Tel Aviv-Yafo, Israel, Department of Otorhinolaryngology, Rabin Medical center and Sackler School of Medicine, Tel-Aviv University, Tel Aviv-Yafo, Israel, Afeka Center of Language Processing, Afeka, Tel Aviv Academic College of Engineering, Tel Aviv-Yafo, Israel;IEEE Open Journal of Engineering in Medicine and Biology;14 Oct 2020;2020;1;;268;274;Automated voice-based detection of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) could facilitate the screening for COVID19. A dataset of cellular phone recordings from 88 subjects was recently collected. The dataset included vocal utterances, speech and coughs that were self-recorded by the subjects in either hospitals or isolation sites. All subjects underwent nasopharyngeal swabbing at the time of recording and were labelled as SARS-CoV-2 positives or negative controls. The present study harnessed deep machine learning and speech processing to detect the SARS-CoV-2 positives. A three-stage architecture was implemented. A self-supervised attention-based transformer generated embeddings from the audio inputs. Recurrent neural networks were used to produce specialized sub-models for the SARS-CoV-2 classification. An ensemble stacking fused the predictions of the sub-models. Pre-training, bootstrapping and regularization techniques were used to prevent overfitting. A recall of 78% and a probability of false alarm (PFA) of 41% were measured on a test set of 57 recording sessions. A leave-one-speaker-out cross validation on 292 recording sessions yielded a recall of 78% and a PFA of 30%. These preliminary results imply a feasibility for COVID19 screening using voice.;2644-1276;;10.1109/OJEMB.2020.3026468;Directorate of Defense Research and Development, Israeli Ministry of Defense, ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9205643;COVID19,audio embeddings,transformer,recurrent neural network,ensemble stacking,semi supervised learning;Training,Diseases,Machine learning,Stacking,Magnetic heads,Biomedical engineering,Speech processing;cellular radio,diseases,feature extraction,learning (artificial intelligence),medical computing,medical signal detection,medical signal processing,microorganisms,pneumodynamics,recurrent neural nets,speech processing,statistical analysis;leave-one-speaker-out cross validation,probability of false alarm,recurrent neural networks,cellular phone recordings,severe acute respiratory syndrome coronavirus 2,automated voice-based detection,SARS-CoV-2 detection,COVID19 screening,recording sessions,SARS-CoV-2 classification,self-supervised attention-based transformer,SARS-CoV-2 positives;;15;;34;CCBYNCND;24-sep-20;;;IEEE;IEEE Journals
Prediction of Patients with Heart Disease using Artificial Neural Network and Adaptive Boosting techniques;O. Terrada, B. Cherradi, S. Hamida, A. Raihani, H. Moujahid, O. Bouattane;Hassan II University Casablanca(UH2C),SSDIA Laboratory, ENSET Mohammedia,Casablanca,Morocco, Hassan II University of Casablanca,STIE Team, CRMEF Casablanca-Settat, SSDIA Laboratory, ENSET Mohammedia,Casablanca,Morocco, Hassan II University Casablanca(UH2C),SSDIA Laboratory, ENSET Mohammedia,Casablanca,Morocco, Hassan II University Casablanca(UH2C),SSDIA Laboratory, ENSET Mohammedia,Casablanca,Morocco, Hassan II University Casablanca(UH2C),SSDIA Laboratory, ENSET Mohammedia,Casablanca,Morocco, Hassan II University Casablanca(UH2C),SSDIA Laboratory, ENSET Mohammedia,Casablanca,Morocco;2020 3rd International Conference on Advanced Communication Technologies and Networking (CommNet);18-sep-20;2020;;;1;6;Machine learning (ML) technique behind the most existing abilities fields in several areas like languages processing, robotics, including medicine. The most important medical applications are the early prediction system for heart diseases especially, coronary artery disease (CAD) also called atherosclerosis. The need for a medical diagnosis support system is to detect atherosclerosis at the earlier stages to optimize the diagnosis, avoid the advanced cases, and reduce treatment costs. Here, a supervised machine learning medical diagnosis support system (MDSS) for atherosclerosis prediction is presented that is able to obtain and learn automatically knowledge from each patient's clinical data. Therefore, we used the various ML classifiers for the proposed medical diagnosis support system for atherosclerosis. Two supervised ML algorithms (Artificial Neural Network and Adaptive Boosting) were used in order to compare which one is more efficient for atherosclerosis diagnosis. Thus, this work is accomplished using databases collected from the UCI repository (Cleveland, Hungarian) and Sani Z-Alizadeh dataset. The performance metrics were computed utilizing Recall, Accuracy and Precision. Furthermore and F1 score measures were also calculated to greatly increase the proposed system performance. Consequently, the proposed model can be used to support healthcare and facilitate large-scale clinical diagnostic of atherosclerosis diseases.;;978-1-7281-8704-4;10.1109/CommNet49926.2020.9199620;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9199620;Atherosclerosis,machine learning techniques,Adaptive Boosting,artificial neural network,prediction;Heart,Atherosclerosis,Prediction algorithms,Artificial neural networks,Classification algorithms,Databases;diseases,medical diagnostic computing,neural nets,patient diagnosis,pattern classification,supervised learning;heart disease,artificial neural network,adaptive boosting,early prediction system,coronary artery disease,supervised machine learning,atherosclerosis prediction,patient,ML classifiers,supervised ML algorithms,atherosclerosis diagnosis,system performance,atherosclerosis diseases,medical diagnosis support system;;6;;25;;18-sep-20;;;IEEE;IEEE Conferences
Prediction of COVID-19 spread via LSTM and the deterministic SEIR model;Y. Yang, W. Yu, D. Chen;Southeast University,School of Mathematics,Nanjing,P. R. China,210096, Southeast University,School of Mathematics,Nanjing,P. R. China,210096, Southeast University,School of Mathematics,Nanjing,P. R. China,210096;2020 39th Chinese Control Conference (CCC);9-sep-20;2020;;;782;785;Due to the outbreak of COVID-19, China and most countries in the world have been seriously affected and tens of thousands of people have lost their lives, it is urgent to study the transmission characteristics and trends of the virus. In this study, we adopt the Long Short Term Memory algorithm at first to predict the infected population in China. However, it does not explain the dynamics of diffusion process, and the long-term prediction error is too large. Therefore, the widely-accepted SEIR model is introduced to capture the spread process of COVID-19. By using a sliding window method, we suggest that the parameter estimation and the prediction of the infected populations are well performed. This may provide some insights for epidemiological studies and understanding of the spread of the current COVID-19.;1934-1768;978-9-8815-6390-3;10.23919/CCC50068.2020.9189012;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9189012;Epidemiological model,LSTM,Sliding window method,COVID-19;Sociology,Statistics,Data models,Predictive models,Market research,Mathematical model,Training;diseases,epidemics,medical computing,parameter estimation,recurrent neural nets;LSTM,deterministic SEIR model,transmission characteristics,Long Short Term Memory algorithm,infected population,diffusion process,long-term prediction error,epidemiological studies,COVID-19 spread process,parameter estimation;;5;;15;;9-sep-20;;;IEEE;IEEE Conferences
Modeling and Prediction of the Covid-19 Cases With Deep Assessment Methodology and Fractional Calculus;E. Karaçuha, N. Ö. Önal, E. Ergün, V. Tabatadze, H. Alkaş, K. Karaçuha, H. Ö. Tontuş, N. V. N. Nu;Informatics Institute, Istanbul Technical University, Istanbul, Turkey, Informatics Institute, Istanbul Technical University, Istanbul, Turkey, Informatics Institute, Istanbul Technical University, Istanbul, Turkey, Informatics Institute, Istanbul Technical University, Istanbul, Turkey, Faculty of Society and Economics, Rhine-Waal University of Applied Science, Kleve, Germany, Informatics Institute, Istanbul Technical University, Istanbul, Turkey, Faculty of Science and Letters, Istanbul Technical University, Istanbul, Turkey, Faculty of Society and Economics, Rhine-Waal University of Applied Science, Kleve, Germany;IEEE Access;17-sep-20;2020;8;;164012;164034;This study focuses on modeling, prediction, and analysis of confirmed, recovered, and death cases of COVID-19 by using Fractional Calculus in comparison with other models for eight countries including China, France, Italy, Spain, Turkey, the UK, and the US. First, the dataset is modeled using our previously proposed approach Deep Assessment Methodology, next, one step prediction of the future is made using two methods: Deep Assessment Methodology and Long Short-Term Memory. Later, a Gaussian prediction model is proposed to predict the short-term (30 Days) future of the pandemic, and prediction performance is evaluated. The proposed Gaussian model is compared to a time-dependent susceptible-infected-recovered (SIR) model. Lastly, an analysis of understanding the effect of history is made on memory vectors using wavelet-based denoising and correlation coefficients. Results prove that Deep Assessment Methodology successfully models the dataset with 0.6671%, 0.6957%, and 0.5756% average errors for confirmed, recovered, and death cases, respectively. We found that using the proposed Gaussian approach underestimates the trend of the pandemic and the fastest increase is observed in the US while the slowest is observed in China and Spain. Analysis of the past showed that, for all countries except Turkey, the current time instant is mainly dependent on the past two weeks where countries like Germany, Italy, and the UK have a shorter average incubation period when compared to the US and France.;2169-3536;;10.1109/ACCESS.2020.3021952;Vodafone Future Laboratory, Istanbul Technical University (ITU)(grant numbers:ITUVF20180901P11), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9186689;COVID-19,deep assessment methodology (DAM),fractional calculus,least squares,long short-term memory,modeling,prediction of pandemics,SIR model;Predictive models,Biological system modeling,Fractional calculus,Data models,Analytical models,Differential equations;complex networks,diseases,epidemics,Gaussian processes,medical computing,recurrent neural nets,vectors,wavelet transforms;memory vectors,correlation coefficients,wavelet-based denoising,pandemic prediction,deep assessment methodology,Covid-19 case prediction,fractional calculus,US,death cases,Gaussian prediction model,long short-term memory,step prediction;;7;;58;CCBY;4-sep-20;;;IEEE;IEEE Journals
DeepCOVIDNet: An Interpretable Deep Learning Model for Predictive Surveillance of COVID-19 Using Heterogeneous Features and Their Interactions;A. Ramchandani, C. Fan, A. Mostafavi;Department of Computer Science and Engineering, Texas A&M University, College Station, TX, USA, Zachry Department of Civil and Environmental Engineering, Texas A&M University, College Station, TX, USA, Zachry Department of Civil and Environmental Engineering, Texas A&M University, College Station, TX, USA;IEEE Access;10-sep-20;2020;8;;159915;159930;In this paper, we propose a deep learning model to forecast the range of increase in COVID-19 infected cases in future days and we present a novel method to compute equidimensional representations of multivariate time series and multivariate spatial time series data. Using this novel method, the proposed model can both take in a large number of heterogeneous features, such as census data, intra-county mobility, inter-county mobility, social distancing data, past growth of infection, among others, and learn complex interactions between these features. Using data collected from various sources, we estimate the range of increase in infected cases seven days into the future for all U.S. counties. In addition, we use the model to identify the most influential features for prediction of the growth of infection. We also analyze pairs of features and estimate the amount of observed second-order interaction between them. Experiments show that the proposed model obtains satisfactory predictive performance and fairly interpretable feature analysis results, hence, the proposed model could complement the standard epidemiological models for national-level surveillance of pandemics, such as COVID-19. The results and findings obtained from the deep learning model could potentially inform policymakers and researchers in devising effective mitigation and response strategies. To fast-track further development and experimentation, the code used to implement the proposed model has been made fully open source.;2169-3536;;10.1109/ACCESS.2020.3019989;National Science Foundation(grant numbers:SES-2026814 (RAPID)), National Academies’ Gulf Research Program Early-Career Research Fellowship, Amazon Web Services (AWS) Machine Learning Award, Microsoft AI for Health COVID-19 Grant for cloud computing resources, ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9179729;COVID-19,deep learning,interpretable machine learning,feature interactions,pandemic surveillance,disease spread modeling,policy making;Predictive models,Machine learning,Diseases,Mathematical model,Hidden Markov models,Sociology,Statistics;demography,diseases,forecasting theory,learning (artificial intelligence),medical administrative data processing,statistical analysis,surveillance,time series;interpretable feature analysis results,inter-county mobility,intra-county mobility,census data,multivariate spatial time series data,equidimensional representations,COVID-19 infected cases,heterogeneous features,predictive surveillance,interpretable deep learning model,standard epidemiological models,satisfactory predictive performance,second-order interaction,influential features,infected cases,complex interactions,social distancing data;;21;;75;CCBY;28-aug-20;;;IEEE;IEEE Journals
Predicting Length of Stay for Cardiovascular Hospitalizations in the Intensive Care Unit: Machine Learning Approach;B. Alsinglawi, F. Alnajjar, O. Mubin, M. Novoa, M. Alorjani, O. Karajeh, O. Darwish;Western Sydney University,School of Computer, Data and Mathematical Sciences,Penrith,NSW,Australia,2751, United Arab Emirates University,College of Information Technology,Al Ain,15551,UAE, Western Sydney University,School of Computer, Data and Mathematical Sciences,Penrith,NSW,Australia,2751, Western Sydney University,School of Computer, Data and Mathematical Sciences,Penrith,NSW,Australia,2751, King Abdullah University Hospital, Faculty of Medicine Jordan University of Science and Technology,Department of Pathology and Microbiology,Irbid,Jordan,22110, Virginia Polytechnic Institute and State University,Department of Computer Science,Blacksburg,VA,United States,24061, Ferrum College,Department of Computer Information Systems,Ferrum,Virginia,United States,24088;2020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC);27-aug-20;2020;;;5442;5445;Predicting Cardiovascular Length of stay based hospitalization at the time of patients' admitting to the coronary care unit (CCU) or (cardiac intensive care units CICU) is deemed as a challenging task to hospital management systems globally. Recently, few studies examined the length of stay (LOS) predictive analytics for cardiovascular inpatients in ICU. However, there are almost scarcely real attempts utilized machine learning models to predict the likelihood of heart failure patients length of stay in ICU hospitalization. This paper introduces a predictive research architecture to predict Length of Stay (LOS) for heart failure diagnoses from electronic medical records using the state-of-art- machine learning models, in particular, the ensembles regressors and deep learning regression models. Our results showed that the gradient boosting regressor (GBR) outweighed the other proposed models in this study. The GBR reported higher R-squared value followed by the proposed method in this study called Staking Regressor. Additionally, The Random forest Regressor (RFR) was the fastest model to train. Our outcomes suggested that deep learning-based regressor did not achieve better results than the traditional regression model in this study. This work contributes to the field of predictive modelling for electronic medical records for hospital management systems.;2694-0604;978-1-7281-1990-8;10.1109/EMBC44109.2020.9175889;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9175889;;Predictive models,Heart,Machine learning,Hospitals,Biological system modeling,Mathematical model,Tuning;cardiovascular system,gradient methods,health care,hospitals,learning (artificial intelligence),medical information systems,neural nets,patient care,regression analysis;coronary care unit,hospital management systems,cardiovascular inpatients,ICU hospitalization,predictive research architecture,electronic medical records,machine learning,ensembles regressors,deep learning regression models,random forest regressor,deep learning-based regressor,predictive modelling,length of stay prediction,cardiovascular hospitalizations,cardiac intensive care units,CICU,staking regressor,heart failure patients length of stay,RFR,gradient boosting regressor,GBR;Coronary Care Units,Electronic Health Records,Humans,Intensive Care Units,Length of Stay,Machine Learning;7;;25;;27-aug-20;;;IEEE;IEEE Conferences
Data Science And Its Application In Heart Disease Prediction;M. J. A. Junaid, R. Kumar;Bhagwant University,Ajmer,India, Bhagwant University,Ajmer,India;2020 International Conference on Intelligent Engineering and Management (ICIEM);6-aug-20;2020;;;396;400;This paper is the attempt to make the heart disease prediction at very early stage. As it is well known fact that most of the death causing disease all over the world is heart disease then comes cancer which is also very chronic and dangerous disease which has haunted the human being all over the globe. This disease and problem do not occur all of a sudden. Scientist and Doctors reveals that it is a continues process and is the result of being on a particular lifestyle for long time and also results after giving some basic and common symptoms being occurring all of a sudden. Eventually what does happen in the heart attacks is, the heart is not able to pump the required amount of blood to the parts of the body and more over it itself also does not get enough blood supply due to blocked arteries in the heart chambers there, for it results in heart failure and deaths. This paper brings the concepts of data science and its algorithms to make a hybrid model which can predict the disease of heart in the patient in comfortable ample of time advance. Moreover, the system must suggest useful and precautionary steps to the patient which are of globally accepted standards well in advance. The hybrid model is to predict and suggest the heart patient with world class heart solutions made with the help of data science algorithms namely Naïve Bayes, ANN, SVM and Hybrid Naïve Bayes, SVM, and ANN. The Accuracy, specificity, and sensitivity of Naïve Bayes, ANN, SVM and Hybrid Naïve Bayes, SVM, and ANN has been measured. The results nearly 2% increase in the accuracy in predicting the heart disease in hybrid model. Hybrid model also shows higher specificity and sensitivity by having 82.11% and 91.47 % respectively. This paper also considers different attributes and has shown positivity in the connections with the heart disease like genetics, physical activity, total fat consumption, stress and working conditions. This research shows new direction to the research area where these concepts can be applied to the smart devices, data science to revolutionize the heart disease diagnosis and cures. This project can be effective to the make awareness of the complexities of the heart disease.;;978-1-7281-4097-1;10.1109/ICIEM48762.2020.9160056;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9160056;Coronary artery disease (CAD),heart disease,Naïve Bayes,Artificial neural network (ANN),Support vector machine (SVM),Data science algorithms,accuracy,specificity and sensitivity;Heart,Diseases,Support vector machines,Data science,Predictive models,Prediction algorithms;blood vessels,cardiology,diseases,medical diagnostic computing,neural nets,patient diagnosis,support vector machines;heart disease prediction,heart attacks,heart chambers,heart failure,heart patient,heart disease diagnosis,hybrid Naïve Bayes,heart solutions,blood,data science algorithms,ANN,SVM,chronic disease,total fat consumption,genetics;;2;;10;;6-aug-20;;;IEEE;IEEE Conferences
Feature Selection in Pre-Diagnosis Heart Coronary Artery Disease Detection: A heuristic approach for feature selection based on Information Gain Ratio and Gini Index;F. Ghasemi, B. S. Neysiani, N. Nematbakhsh;Shahid Ashrafi Esfahani University,Department of Computer Engineering,Esfahan,Iran, Shahid Ashrafi Esfahani University,Department of Computer Engineering,Esfahan,Iran, Shahid Ashrafi Esfahani University,Department of Computer Engineering,Esfahan,Iran;2020 6th International Conference on Web Research (ICWR);22-jun-20;2020;;;27;32;Cardiovascular disease is one of the most common causes of mortality in the world. Among the different types of this disease, the coronary artery is the most important, which the correct and timely diagnosis of which is vital. Diagnostic and treatment methods of this disease have many side effects and costs. The best and most accurate diagnostic method here is angiography. Researchers seek to find economical and high-accuracy methods for this purpose. The disease-related features and different data mining techniques are described to increase the accuracy of the diagnosis through one dataset of essential and useful features. Data are collected from 303 suspected cardiovascular patients in Shahid Rajaee Hospital, Tehran. Among the samples, 87 are healthy, and 216 are sick. The features are selected through their optimal subsets of performance, speed of diagnosis, and precision in the first step to determine the severity of coronary artery disease (CAD). This feature selection can predict and promote a learning model. Then the optimal machine learning models are applied to analyze and predict CAD. The accuracy of 99.67% is found in this diagnosis, indicating the highest obtained accuracy in this field. The left anterior descending (LAD), the left circumflex (LCX), and the right coronary artery (RCA) features are diagnosed with high accuracy by using those models. It seems these three features define the CAD and are dependent on angiography. If they are eliminated for the prediagnosis situation, the accuracy of CAD will be between 83% to 86% for the new reduced subset of features proposed concerning legible performance reduction.;;978-1-7281-1051-6;10.1109/ICWR49608.2020.9122285;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9122285;component,Coronary artery disease,Data mining,Feature selection,Cross-Industry Standard Process for Data Mining methodology,Deep Learning;Solid modeling,Hospitals,Angiography,Machine learning,Predictive models,Feature extraction,Data mining;angiocardiography,blood vessels,cardiovascular system,data mining,diseases,feature selection,learning (artificial intelligence),medical diagnostic computing,patient diagnosis;optimal machine learning models,CAD,feature selection,pre-diagnosis heart coronary artery disease detection,information gain ratio,cardiovascular disease,diagnostic treatment methods,disease-related features,data mining techniques,right coronary artery features,Gini index,left circumflex,LCX,RCA,left anterior descending,LAD,angiography;;4;;22;;22-jun-20;;;IEEE;IEEE Conferences
On the Analysis of COVID19 - Novel Corona Viral Disease Pandemic Spread Data Using Machine Learning Techniques;S. S. Arun, G. Neelakanta Iyer;Coimbatore Amrita Vishwa Vidyapeetham,Department of Computer Science and Engineering,India, Coimbatore Amrita Vishwa Vidyapeetham,Department of Computer Science and Engineering,India;2020 4th International Conference on Intelligent Computing and Control Systems (ICICCS);19-jun-20;2020;;;1222;1227;Coronaviruses are a group of viruses that cause various diseases in mammals and birds. In humans, they cause a range of respiratory disorders. This paper presents the analysis of the transmission of COVID19 disease and predicts the scale of the pandemic, the recovery rate as well as the fatality rate. We have used some of the well-known machine learning techniques as well as mathematical modeling techniques such as Rough Set-Support Vector Machine (RS-SVM), Bayesian Ridge and Polynomial Regression, SIR model, and RNN.;;978-1-7281-4876-2;10.1109/ICICCS48265.2020.9121027;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9121027;COVID19,Support Vector Machine,Bayesian Ridge,Polynomial Regression,SIR Model,Coronavirus,Machine Learning,Recurrent Neural Networks,Long Short-Term Memory;COVID-19,Support vector machines,Pandemics,Computational modeling,Machine learning,Control systems,Mathematical models;Bayes methods,diseases,learning (artificial intelligence),medical computing,microorganisms,regression analysis,rough set theory,support vector machines;RS-SVM,RNN,SIR model,polynomial regression,novel corona viral disease,recovery rate,pandemic,COVID19 disease,respiratory disorders,mammals,coronaviruses,machine learning,Rough Set-Support Vector Machine,mathematical modeling,fatality rate;;8;;17;;19-jun-20;;;IEEE;IEEE Conferences
Performance Analysis of Heart Disease Classification for Computer Diagnosis System;K. Sathya, R. Karthiban;Sri Shakthi Institute of Engineering and Technology,Department of CSE,Coimbatore,India, Sri Shakthi Institute of Engineering and Technology,Department of CSE,Coimbatore,India;2020 International Conference on Computer Communication and Informatics (ICCCI);1-jun-20;2020;;;1;7;Wth the widespread increment in the heart stroke rates at adolescent ages, we have to set up a framework to have the option to distinguish the beginning side effects of a coronary illness to anticipate it. It is impractical for a economic people in developing countries to frequently undergo expensive tests like the ECG and thus there needs to be a crepitation machine learning algorithm in place which is convenient and simultaneously solid, in anticipating the odds of a coronary illness. This can be used to predict the vulnerability of a heart disease for the given symptoms like age, sex, pulse rate etc. Classification is one of the most commonly used tool analyze and classify the data. This paper analyzes the different classifier algorithms such as SVM, KNN and MLP for seer heart disease dataset using WEKA 3.8 software. The performance of the classifiers is evaluated against the parameters like classification accuracy, MCC, Precision, Recall, F-Measure, ROC and so on. SVM Classifier is superior to KNN and MLP and it achieves the highest classification accuracy of 85.9% with minimum false positive of 15.3%.;2329-7190;978-1-7281-4514-3;10.1109/ICCCI48352.2020.9104089;;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9104089;Classification,SVM,KNN,Accuracy,RMSE,Confusion matrix;;cardiovascular system,diseases,electrocardiography,learning (artificial intelligence),medical signal processing,multilayer perceptrons,nearest neighbour methods,pattern classification,sensitivity analysis,support vector machines;ROC,WEKA 3.8 software,MLP,KNN,crepitation machine learning algorithm,heart disease dataset,pulse rate,ECG,coronary illness,heart stroke rates,computer diagnosis system,heart disease classification,SVM classifier;;2;;14;;1-jun-20;;;IEEE;IEEE Conferences
Predicting COVID-19 in China Using Hybrid AI Model;N. Zheng, S. Du, J. Wang, H. Zhang, W. Cui, Z. Kang, T. Yang, B. Lou, Y. Chi, H. Long, M. Ma, Q. Yuan, S. Zhang, D. Zhang, F. Ye, J. Xin;Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China, Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China, Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China, Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China, Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China, Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China, Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China, Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China, Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China, Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China, Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China, Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China, Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China, Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China, Infectious Department, First Affiliated Hospital of Xi’an Jiaotong University, Xi’an, China, Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China;IEEE Transactions on Cybernetics;17-jun-20;2020;50;7;2891;2904;The coronavirus disease 2019 (COVID-19) breaking out in late December 2019 is gradually being controlled in China, but it is still spreading rapidly in many other countries and regions worldwide. It is urgent to conduct prediction research on the development and spread of the epidemic. In this article, a hybrid artificial-intelligence (AI) model is proposed for COVID-19 prediction. First, as traditional epidemic models treat all individuals with coronavirus as having the same infection rate, an improved susceptible–infected (ISI) model is proposed to estimate the variety of the infection rates for analyzing the transmission laws and development trend. Second, considering the effects of prevention and control measures and the increase of the public’s prevention awareness, the natural language processing (NLP) module and the long short-term memory (LSTM) network are embedded into the ISI model to build the hybrid AI model for COVID-19 prediction. The experimental results on the epidemic data of several typical provinces and cities in China show that individuals with coronavirus have a higher infection rate within the third to eighth days after they were infected, which is more in line with the actual transmission laws of the epidemic. Moreover, compared with the traditional epidemic models, the proposed hybrid AI model can significantly reduce the errors of the prediction results and obtain the mean absolute percentage errors (MAPEs) with 0.52%, 0.38%, 0.05%, and 0.86% for the next six days in Wuhan, Beijing, Shanghai, and countrywide, respectively.;2168-2275;;10.1109/TCYB.2020.2990162;National Basic Research Program of China (973 Program)(grant numbers:2016YFB1000900), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9090302;Coronavirus disease 2019 (COVID-19) prediction,epidemic model,hybrid artificial-intelligence (AI) model,natural language processing (NLP);Epidemics,COVID-19,Predictive models,Market research,Analytical models,Natural language processing;complex networks,diseases,epidemics,medical computing,microorganisms,natural language processing,neural nets;hybrid AI model,coronavirus disease 2019,late December 2019,conduct prediction research,hybrid artificial-intelligence model,COVID-19 prediction,traditional epidemic models,improved susceptible-infected model,transmission laws,control measures,ISI model,higher infection rate,natural language processing module,long short-term memory network;Artificial Intelligence,Betacoronavirus,China,Coronavirus Infections,Humans,Models, Statistical,Natural Language Processing,Pandemics,Pneumonia, Viral;100;;39;IEEE;8 May 2020;;;IEEE;IEEE Journals
A Stacking-Based Model for Non-Invasive Detection of Coronary Heart Disease;J. Wang, C. Liu, L. Li, W. Li, L. Yao, H. Li, H. Zhang;School of Control Science and Engineering, Shandong University, Jinan, China, School of Control Science and Engineering, Shandong University, Jinan, China, School of Science and Engineering, Shandong University of Traditional Chinese Medicine, Jinan, China, School of Pharmacy and Bioengineering, Chongqing University of Technology, Chongqing, China, School of Control Science and Engineering, Shandong University, Jinan, China, School of Control Science and Engineering, Shandong University, Jinan, China, School of Control Science and Engineering, Shandong University, Jinan, China;IEEE Access;28-feb-20;2020;8;;37124;37133;Coronary arteriongraphy (CAG) is an accurate invasive technique for the diagnosis of coronary heart disease (CHD). However, its invasive procedure is not appropriate for the detection of CHD in the annual physical examination. With the successful application of machine learning (ML) in various fields, our goal is to perform selective integration of multiple ML algorithms and verify the validity of feature selection methods with personal clinical information commonly seen in the annual physical examination. In this study, a two level stacking based model is designed in which level 1 is base-level and level 2 is meta-level. The predictions of base-level classifiers is selected as the input of meta-level. The pearson correlation coefficient and maximum information coefficient are first calculated to find the classifier with the lowest correlation. Then enumeration algorithm is used to find the best combining classifiers which acquire the best result in the end. The Z-Alizadeh Sani CHD dataset which we use consists of 303 cases verified by CAG. Experimental results demonstrate that the proposed model obtains an accuracy, sensitivity and specificity of 95.43%, 95.84%, 94.44%, respectively for the detection of CHD. The proposed method can effectively aid clinicians to detect those with normal coronary arteries from those with CHD.;2169-3536;;10.1109/ACCESS.2020.2975377;National Natural Science Foundation of China(grant numbers:61471223), ;https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9005221;Coronary heart disease,machine learning,feature selection,stacking;Feature extraction,Stacking,Diseases,Prediction algorithms,Heart,Data models,Correlation;cardiology,correlation methods,diseases,feature extraction,feature selection,feedforward neural nets,learning (artificial intelligence),medical diagnostic computing,patient diagnosis,pattern classification;artificial neural network,feedforward neural network,clinical cardiology,CHD diagnosis,meta-level classifier,stacking based model,enumeration algorithm,Pearson correlation coefficient,base-level classifiers,personal clinical information,feature selection,machine learning,coronary heart disease diagnosis,coronary arteriongraphy,noninvasive detection,normal coronary arteries,Z-Alizadeh Sani CHD dataset;;8;;51;CCBY;20-feb-20;;;IEEE;IEEE Journals
